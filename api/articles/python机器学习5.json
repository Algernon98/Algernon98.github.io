{"title":"【python机器学习基础教程】（五）","uid":"01c87ce279dfe7327e075971fdffa3c0","slug":"python机器学习5","date":"2022-11-03T14:38:49.000Z","updated":"2022-11-03T14:38:59.371Z","comments":true,"path":"api/articles/python机器学习5.json","keywords":null,"cover":[],"content":"<h1 id=\"模型评估与改进\"><a href=\"#模型评估与改进\" class=\"headerlink\" title=\"模型评估与改进\"></a>模型评估与改进</h1><h2 id=\"交叉验证\"><a href=\"#交叉验证\" class=\"headerlink\" title=\"交叉验证\"></a>交叉验证</h2><p>交叉验证是一种评估泛化性能的统计学方法，它比单次划分训练集和测试集的方法更加稳定、全面。在交叉验证中，数据被多次划分，并且需要训练多个模型。<br>最常用的交叉验证是k折交叉验证，其中k是由用户指定的数字，通常取5或者10。<br>在执行5折交叉验证时，首先将数据划分为（大致）相等的5部分，每一部分叫做<strong>折</strong>。<br>接下来训练一系列模型，使用第一折作为测试集、其他折（2~5）作为训练集来训练第一个模型。<br>利用2~5折中的数据来构建模型，然后在1折上评估精度。<br>之后构建另一个模型，这次使用2折 作为测试集，1、3、4、5折中的数据作为训练集。<br>利用3、4、5折作为测试集重复这一过程。<br>对于将数据划分为训练集和测试集的这五次<strong>划分</strong> ，每一次都需要计算精度。<br>最后我们得到了5个精度值。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">mglearn.plots.plot_cross_validation()</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/543d9687b0be47f8803c3eb24134c413.jpeg#pic_center\" alt=\"在这里插入图片描述\"><br>通常来说，数据的前五分之一是第1折，第二个五分之一是第2折，其此类推。</p>\n<h3 id=\"scikit-learn中的交叉验证\"><a href=\"#scikit-learn中的交叉验证\" class=\"headerlink\" title=\"scikit-learn中的交叉验证\"></a>scikit-learn中的交叉验证</h3><p>scikit-learn是利用model_selection模块中的cross_val_score函数来实现交叉验证的。<br>cross_val_score函数的参数是我们想要评估的模型、训练数据与真实标签。<br>我们在iris数据集上对LogisticRegression进行评估：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">from sklearn.model_selection import cross_val_score\nfrom sklearn.datasets import load_iris\nfrom sklearn.linear_model import LogisticRegression\n\niris&#x3D;load_iris()\nlogreg&#x3D;LogisticRegression()\n\nscores&#x3D;cross_val_score(logreg,iris.data,iris.target,cv&#x3D;5)\nprint(&quot;Cross-validation scores:&#123;&#125;&quot;.format(scores))</code></pre>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>Cross-validation scores:[0.96666667 1.         0.93333333 0.96666667 1.        ]</p></blockquote>\n<p>总结交叉验证精度的一种常用方法是计算平均值：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">print(&quot;Average cross-validation score:&#123;:.2f&#125;&quot;.format(scores.mean()))</code></pre>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>Average cross-validation score:0.97</p></blockquote>\n<h3 id=\"分层k折交叉验证和其他策略\"><a href=\"#分层k折交叉验证和其他策略\" class=\"headerlink\" title=\"分层k折交叉验证和其他策略\"></a>分层k折交叉验证和其他策略</h3><p>首先，我们康康iris数据集：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">from sklearn.datasets import load_iris\niris&#x3D;load_iris()\nprint(&quot;Iris labels:\\n&#123;&#125;&quot;.format(iris.target))</code></pre>\n<p>输出：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">Iris labels:\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n 2 2]\n</code></pre>\n<p>数据前三分之一是类别0，中间三分之一是类别1，最后三分之一是类别2。<br>简单k折策略在这里失效了，故我们使用<strong>分层k折交叉验证</strong>。<br>在分层交叉验证中，我们划分数据，使每个折中类别之间的比例与整个数据集中的比例相同。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">mglearn.plots.plot_stratified_cross_validation()</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/bbabebac4a4a40139d73711a0b6f83f2.jpeg#pic_center\" alt=\"在这里插入图片描述\"><br><strong>留一交叉验证</strong><br>另一种常用的交叉验证方法是<strong>留一法</strong>。<br>可以将留一法交叉验证看作是每折只包含单个样本的k折交叉验证。<br>对于每次划分，选择单个数据点作为测试集。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">from sklearn.model_selection import LeaveOneOut\nloo&#x3D;LeaveOneOut()\nlogreg &#x3D; LogisticRegression()\nscores&#x3D;cross_val_score(logreg,iris.data,iris.target,cv&#x3D;loo)\nprint(&quot;Number of cv iterations:&quot;,len(scores))\nprint(&quot;Mean accuracy:&#123;:.2f&#125;&quot;.format(scores.mean()))</code></pre>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>Number of cv iterations: 150<br>Mean accuracy:0.97</p></blockquote>\n<h3 id=\"打乱划分交叉验证\"><a href=\"#打乱划分交叉验证\" class=\"headerlink\" title=\"打乱划分交叉验证\"></a>打乱划分交叉验证</h3><p>在打乱划分交叉验证中，每次划分为训练集取样train_size个点，为测试集取样test_size个（不相交的）点。<br>将这一划分方法重复n_iter次。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">mglearn.plots.plot_shuffle_split()</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/6533b9729f184394afce184ab2353f31.jpeg#pic_center\" alt=\"在这里插入图片描述\"><br>下面的代码将数据集划分为50%的训练集和50%的测试集，共运行10次迭代：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">from sklearn.model_selection import ShuffleSplit\nshuffle_split &#x3D;ShuffleSplit(test_size&#x3D;.5,train_size&#x3D;.5,n_splits&#x3D;10)\nscores&#x3D;cross_val_score(logreg,iris.data,iris.target,cv&#x3D;shuffle_split)\nprint(&quot;Cross-validation scores:\\n&#123;&#125;&quot;.format(scores))</code></pre>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>Cross-validation scores:<br>[0.97333333 0.96       0.98666667 0.98666667 0.97333333 0.98666667<br> 0.92       0.97333333 0.97333333 0.93333333]</p>\n<h3 id=\"分组交叉验证\"><a href=\"#分组交叉验证\" class=\"headerlink\" title=\"分组交叉验证\"></a>分组交叉验证</h3><p>另一种交叉验证适用于数据中的分组高度相关时。</p></blockquote>\n<p>下面这个示例用到了一个由groups数组指定分组的模拟数据集。<br>这个数据集包含12个数据点，且对于每个数据点，groups指定了该点所属的分组。<br>一共分成四组，前3个样本属于第一组，接下来4个样本属于第二组，以此类推：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">from sklearn.model_selection import GroupKFold\nfrom sklearn.datasets import make_blobs\n#创建模拟数据集\nX,y&#x3D;make_blobs(n_samples&#x3D;12,random_state&#x3D;0)\n#假设前三个样本属于同一组，接下来4个样本属于同一组，以此类推\ngroups&#x3D;[0,0,0,1,1,1,1,2,2,3,3,3]\nscores&#x3D;cross_val_score(logreg,X,y,groups,cv&#x3D;GroupKFold(n_splits&#x3D;3))\nprint(&quot;Cross-validation scores:\\n&#123;&#125;&quot;.format(scores))</code></pre>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">mglearn.plots.plot_group_kfold()</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/5f7da44eb05c4fa285f52d6a4eb06dd8.jpeg#pic_center\" alt=\"在这里插入图片描述\"></p>\n<h2 id=\"网格搜索\"><a href=\"#网格搜索\" class=\"headerlink\" title=\"网格搜索\"></a>网格搜索</h2><h3 id=\"简单网格搜索\"><a href=\"#简单网格搜索\" class=\"headerlink\" title=\"简单网格搜索\"></a>简单网格搜索</h3><h3 id=\"参数过拟合的风险与验证集\"><a href=\"#参数过拟合的风险与验证集\" class=\"headerlink\" title=\"参数过拟合的风险与验证集\"></a>参数过拟合的风险与验证集</h3><pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">mglearn.plots.plot_threefold_split()</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/9ff6f561144d4713b9c2731810d1f2c2.jpeg#pic_center\" alt=\"在这里插入图片描述\"></p>\n<h3 id=\"带交叉验证的网格搜索\"><a href=\"#带交叉验证的网格搜索\" class=\"headerlink\" title=\"带交叉验证的网格搜索\"></a>带交叉验证的网格搜索</h3><pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">mglearn.plots.plot_cross_val_selection()\nmglearn.plots.plot_grid_search_overview()</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/2cfa7bc7239f4624ab20bd32b6e5344d.jpeg#pic_center\" alt=\"在这里插入图片描述\"></p>\n<h2 id=\"评估指标与评分\"><a href=\"#评估指标与评分\" class=\"headerlink\" title=\"评估指标与评分\"></a>评估指标与评分</h2><h3 id=\"二分类指标\"><a href=\"#二分类指标\" class=\"headerlink\" title=\"二分类指标\"></a>二分类指标</h3><p>对于二分类问题，我们通常会说<strong>正类</strong>和<strong>反类</strong>。<br>错误的阳性预测叫做<strong>假正例</strong>，错误的阴性预测叫做<strong>假反例</strong>。<br>在统计学中，假正例也叫做第一类错误，假反例也叫作第二类错误。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">mglearn.plots.plot_confusion_matrix_illustration()</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/ed39eb10b6214bbb81a4dbb79feb22b6.jpeg#pic_center\" alt=\"在这里插入图片描述\"><br>“9与其他”分类任务的混淆矩阵</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">mglearn.plots.plot_binary_confusion_matrix()</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/edb5a1fe694a45afb3df557d4e6cc599.jpeg#pic_center\" alt=\"在这里插入图片描述\"><br>二分类混淆矩阵</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">mglearn.plots.plot_decision_threshold()</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/6246aea20736473a93f4385a5e7f85ac.jpeg#pic_center\" alt=\"在这里插入图片描述\"></p>\n<h4 id=\"受试者工作特征（ROC）和AUC\"><a href=\"#受试者工作特征（ROC）和AUC\" class=\"headerlink\" title=\"受试者工作特征（ROC）和AUC\"></a>受试者工作特征（ROC）和AUC</h4><p>有一种常用的工具可以分析不同阈值的分类器行为：<strong>受试者工作特征曲线</strong>，简称为<strong>ROC曲线</strong>。与准确率-召回率曲线类似，ROC曲线考虑了给定分类器的所有可能的阈值，但它显示的是<strong>假正例率</strong>和<strong>真正例率</strong> ，而不是报告准确率和召回率。<br>真正例率只是召回率的另一个名称，而假正例率则是假正例占所有反类样本的比例</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">from sklearn.metrics import roc_curve\nfrom sklearn import svm\nfrom sklearn.svm import SVC\nfpr,tpr,thresholds&#x3D;roc_curve(y_test,svc.decision_function(X_test))\n\nX,y&#x3D;make_blobs(n_samples&#x3D;(4000,500),centers&#x3D;2,cluster_std&#x3D;[7.0,2],random_state&#x3D;22)\nX_train,X_test,y_train,y_test&#x3D;train_test_split(X,y,random_state&#x3D;0)\nsvc&#x3D;SVC(gamma&#x3D;.05).fit(X_train,y_train)\nprecision,recall,thresholds&#x3D;precision_recall_curve(y_test,svc.decision_function(X_test))\nplt.plot(fpr,tpr,label&#x3D;&quot;ROC Curve&quot;)\nplt.xlabel(&quot;FPR&quot;)\nplt.ylabel(&quot;TPR(recall)&quot;)\n#找到最接近于0的阈值\nclose_zero&#x3D;np.argmin(np.abs(thresholds))\nplt.plot(fpr[close_zero],tpr[close_zero],&#39;o&#39;,markersize&#x3D;10,label&#x3D;&quot;threshold zero&quot;,fillstyle&#x3D;&quot;none&quot;,c&#x3D;&#39;k&#39;,mew&#x3D;2)\nplt.legend(loc&#x3D;4)</code></pre>\n<p>未完待续</p>\n<h3 id=\"多分类指标\"><a href=\"#多分类指标\" class=\"headerlink\" title=\"多分类指标\"></a>多分类指标</h3><p>一般来说，多分类结果比二分类结果更加难以理解。<br>除了精度，常用的工具有混淆矩阵和分类报告，下面我们将这两种详细的评估方法应用于对digits数据集中10种不同的手写数字进行分类的任务：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">from sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\n\nfrom sklearn import datasets\ndigits &#x3D; datasets.load_digits()\nX_train,X_test,y_train,y_test&#x3D;train_test_split(digits.data,digits.target,random_state&#x3D;0)\nlr&#x3D;LogisticRegression().fit(X_train,y_train)\npred&#x3D;lr.predict(X_test)\nprint(&quot;Accuracy:&#123;:.3f&#125;&quot;.format(accuracy_score(y_test,pred)))\nprint(&quot;Confusion matrix:\\n&#123;&#125;&quot;.format(confusion_matrix(y_test,pred)))</code></pre>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">Accuracy:0.951\nConfusion matrix:\n[[37  0  0  0  0  0  0  0  0  0]\n [ 0 40  0  0  0  0  0  0  2  1]\n [ 0  1 40  3  0  0  0  0  0  0]\n [ 0  0  0 43  0  0  0  0  1  1]\n [ 0  0  0  0 37  0  0  1  0  0]\n [ 0  0  0  0  0 46  0  0  0  2]\n [ 0  1  0  0  0  0 51  0  0  0]\n [ 0  0  0  1  1  0  0 46  0  0]\n [ 0  3  1  0  0  0  0  0 43  1]\n [ 0  0  0  0  0  1  0  0  1 45]]</code></pre>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">scores_image&#x3D;mglearn.tools.heatmap(confusion_matrix(y_test,pred),xlabel&#x3D;&#39;predicted label&#39;,ylabel&#x3D;&#39;true label&#39;,xticklabels&#x3D;digits.target_names,yticklabels&#x3D;digits.target_names,cmap&#x3D;plt.cm.gray_r,fmt&#x3D;&quot;%d&quot;)\nplt.title(&quot;confusion matrix&quot;)\nplt.gca().invert_yaxis()</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/a71d1d4249724f9c9945aae1047a96e7.jpeg#pic_center\" alt=\"在这里插入图片描述\"><br>10个数字分类任务的混淆矩阵</p>\n<p>利用classification_report函数，我们可以计算每个类别的准确率、召回率和$f$-分数：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">from sklearn.metrics import classification_report\nprint(classification_report(y_test,pred))</code></pre>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        37\n           1       0.89      0.93      0.91        43\n           2       0.98      0.91      0.94        44\n           3       0.91      0.96      0.93        45\n           4       0.97      0.97      0.97        38\n           5       0.98      0.96      0.97        48\n           6       1.00      0.98      0.99        52\n           7       0.98      0.96      0.97        48\n           8       0.91      0.90      0.91        48\n           9       0.90      0.96      0.93        47\n\n    accuracy                           0.95       450\n   macro avg       0.95      0.95      0.95       450\nweighted avg       0.95      0.95      0.95       450</code></pre>\n<h3 id=\"回归指标\"><a href=\"#回归指标\" class=\"headerlink\" title=\"回归指标\"></a>回归指标</h3>","text":"模型评估与改进交叉验证交叉验证是一种评估泛化性能的统计学方法，它比单次划分训练集和测试集的方法更加稳定、全面。在交叉验证中，数据被多次划分，并且需要训练多个模型。最常用的交叉验证是k折交叉验证，其中k是由用户指定的数字，通常取5或者10。在执行5折交叉验证时，首先将数据划分为（大...","link":"","photos":[],"count_time":{"symbolsCount":"7k","symbolsTime":"6 mins."},"categories":[],"tags":[{"name":"机器学习","slug":"机器学习","count":5,"path":"api/tags/机器学习.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-1\"><a class=\"toc-link\" href=\"#%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E6%94%B9%E8%BF%9B\"><span class=\"toc-text\">模型评估与改进</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81\"><span class=\"toc-text\">交叉验证</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#scikit-learn%E4%B8%AD%E7%9A%84%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81\"><span class=\"toc-text\">scikit-learn中的交叉验证</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%88%86%E5%B1%82k%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E5%92%8C%E5%85%B6%E4%BB%96%E7%AD%96%E7%95%A5\"><span class=\"toc-text\">分层k折交叉验证和其他策略</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%89%93%E4%B9%B1%E5%88%92%E5%88%86%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81\"><span class=\"toc-text\">打乱划分交叉验证</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%88%86%E7%BB%84%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81\"><span class=\"toc-text\">分组交叉验证</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2\"><span class=\"toc-text\">网格搜索</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%AE%80%E5%8D%95%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2\"><span class=\"toc-text\">简单网格搜索</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%8F%82%E6%95%B0%E8%BF%87%E6%8B%9F%E5%90%88%E7%9A%84%E9%A3%8E%E9%99%A9%E4%B8%8E%E9%AA%8C%E8%AF%81%E9%9B%86\"><span class=\"toc-text\">参数过拟合的风险与验证集</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%B8%A6%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81%E7%9A%84%E7%BD%91%E6%A0%BC%E6%90%9C%E7%B4%A2\"><span class=\"toc-text\">带交叉验证的网格搜索</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E8%AF%84%E4%BC%B0%E6%8C%87%E6%A0%87%E4%B8%8E%E8%AF%84%E5%88%86\"><span class=\"toc-text\">评估指标与评分</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%BA%8C%E5%88%86%E7%B1%BB%E6%8C%87%E6%A0%87\"><span class=\"toc-text\">二分类指标</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%8F%97%E8%AF%95%E8%80%85%E5%B7%A5%E4%BD%9C%E7%89%B9%E5%BE%81%EF%BC%88ROC%EF%BC%89%E5%92%8CAUC\"><span class=\"toc-text\">受试者工作特征（ROC）和AUC</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%A4%9A%E5%88%86%E7%B1%BB%E6%8C%87%E6%A0%87\"><span class=\"toc-text\">多分类指标</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%9B%9E%E5%BD%92%E6%8C%87%E6%A0%87\"><span class=\"toc-text\">回归指标</span></a></li></ol></li></ol></li></ol>","author":{"name":"Algernon","slug":"blog-author","avatar":"https://user-images.githubusercontent.com/54904760/224857900-b2e8457c-43d2-46b7-901c-6c770f24bbad.png","link":"/","description":"谁也没见过风，更别说我和你了","socials":{"github":"https://github.com/Algernon98","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/Algernon98","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://space.bilibili.com/281724502"}}}},"mapped":true,"prev_post":{"title":"【计算与人工智能概论】（进阶）","uid":"15c6023f64ef1e6727ffc77c5b7783db","slug":"计算与人工智能概论进阶","date":"2022-11-03T14:40:49.000Z","updated":"2022-11-03T14:40:09.552Z","comments":true,"path":"api/articles/计算与人工智能概论进阶.json","keywords":null,"cover":[],"text":"算法思维方程求根二分法画图猜f(x)=0的大概范围[a,b]再缩小范围，保证f(a)f(b)&lt;0,在[a,b]上一定有实根。 中点x0=a+(b-a)/2=(a+b)/2 即两端值和的一半。若中点与右端符号相同(如左图)，则缩小到[a,x0]。若中点与左端符号相同(如右图)...","link":"","photos":[],"count_time":{"symbolsCount":"25k","symbolsTime":"23 mins."},"categories":[],"tags":[{"name":"python","slug":"python","count":9,"path":"api/tags/python.json"}],"author":{"name":"Algernon","slug":"blog-author","avatar":"https://user-images.githubusercontent.com/54904760/224857900-b2e8457c-43d2-46b7-901c-6c770f24bbad.png","link":"/","description":"谁也没见过风，更别说我和你了","socials":{"github":"https://github.com/Algernon98","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/Algernon98","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://space.bilibili.com/281724502"}}}}},"next_post":{"title":"【python机器学习基础教程】（四）","uid":"1ee3586cac227bddb968ecf686dc5d5b","slug":"python机器学习4","date":"2022-11-03T14:37:49.000Z","updated":"2022-11-03T14:37:40.370Z","comments":true,"path":"api/articles/python机器学习4.json","keywords":null,"cover":[],"text":"数据表示与特征工程到目前为止，我们一直假设数据是由浮点数组成的二维数组，其中每一列是描述数据点的连续特征。对于许多应用而言，数据的收集方式并不是这样。一种特别常见的特征类型就是分类特征，也叫离散特征。 对于某个特定应用而言，如何找到最佳数据表示，这个问题被称为特征工程。 分类变量...","link":"","photos":[],"count_time":{"symbolsCount":"9.3k","symbolsTime":"8 mins."},"categories":[],"tags":[{"name":"机器学习","slug":"机器学习","count":5,"path":"api/tags/机器学习.json"}],"author":{"name":"Algernon","slug":"blog-author","avatar":"https://user-images.githubusercontent.com/54904760/224857900-b2e8457c-43d2-46b7-901c-6c770f24bbad.png","link":"/","description":"谁也没见过风，更别说我和你了","socials":{"github":"https://github.com/Algernon98","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/Algernon98","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://space.bilibili.com/281724502"}}}}}}