{"title":"【大数据基础】分布式文件系统HDFS","uid":"9296c150b4eff59f49b0a87274d9be9a","slug":"大数据4","date":"2023-03-07T13:50:49.000Z","updated":"2023-04-04T02:35:07.720Z","comments":true,"path":"api/articles/大数据4.json","keywords":null,"cover":[],"content":"<p>来源：</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><a href=\"https://dblab.xmu.edu.cn/blog/290/\">https://dblab.xmu.edu.cn/blog/290/</a></p></blockquote>\n<p>首先回顾上一节</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><a href=\"https://blog.csdn.net/Algernon98/article/details/129232375?spm=1001.2014.3001.5501\">https://blog.csdn.net/Algernon98/article/details/129232375?spm=1001.2014.3001.5501</a></p></blockquote>\n<p>我们已经得到了如下配置：<br><img src=\"https://img-blog.csdnimg.cn/70e2d7d339764ab1850dd88d09c3af60.png\" alt=\"在这里插入图片描述\"></p>\n<h2 id=\"利用Shell命令与HDFS进行交互\"><a href=\"#利用Shell命令与HDFS进行交互\" class=\"headerlink\" title=\"利用Shell命令与HDFS进行交互\"></a>利用Shell命令与HDFS进行交互</h2><p>在学习HDFS编程实践前，我们需要启动Hadoop。执行如下命令</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">cd &#x2F;usr&#x2F;local&#x2F;hadoop\n.&#x2F;sbin&#x2F;start-dfs.sh #启动hadoop</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/c50bab28278440deaa1bee79593a2cb1.png\" alt=\"在这里插入图片描述\"></p>\n<h3 id=\"目录操作\"><a href=\"#目录操作\" class=\"headerlink\" title=\"目录操作\"></a>目录操作</h3><p>需要注意的是，Hadoop系统安装好以后，第一次使用HDFS时，需要首先在HDFS中创建用户目录。本教程全部采用hadoop用户登录Linux系统，因此，需要在HDFS中为hadoop用户创建一个用户目录，命令如下：</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">cd &#x2F;usr&#x2F;local&#x2F;hadoop\n.&#x2F;bin&#x2F;hdfs dfs –mkdir –p &#x2F;user&#x2F;hadoop</code></pre>\n<p>该命令中表示在HDFS中创建一个“/user/hadoop”目录，“–mkdir”是创建目录的操作，“-p”表示如果是多级目录，则父目录和子目录一起创建，这里“/user/hadoop”就是一个多级目录，因此必须使用参数“-p”，否则会出错。<br>“/user/hadoop”目录就成为hadoop用户对应的用户目录，可以使用如下命令显示HDFS中与当前用户hadoop对应的用户目录下的内容：<br><img src=\"https://img-blog.csdnimg.cn/4f14efa297c346a9bd95cd6e55be71d2.png\" alt=\"在这里插入图片描述\"><br>该命令中，“-ls”表示列出HDFS某个目录下的所有内容，“.”表示HDFS中的当前用户目录，也就是“/user/hadoop”目录，因此，上面的命令和下面的命令是等价的：<br><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">.&#x2F;bin&#x2F;hdfs dfs –ls &#x2F;user&#x2F;hadoop</code></pre><br><img src=\"https://img-blog.csdnimg.cn/64206b8aae1c4113aeb9c34988f8657b.png\" alt=\"在这里插入图片描述\"></p>\n<p>如果要列出HDFS上的所有目录，可以使用如下命令：</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">.&#x2F;bin&#x2F;hdfs dfs –ls</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/57d32dce89d14179ae7064ac47f3b914.png\" alt=\"在这里插入图片描述\"><br>下面，可以使用如下命令创建一个input目录：</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">.&#x2F;bin&#x2F;hdfs dfs –mkdir input</code></pre>\n<p>在创建个input目录时，采用了相对路径形式，实际上，这个input目录创建成功以后，它在HDFS中的完整路径是“/user/hadoop/input”。如果要在HDFS的根目录下创建一个名称为input的目录，则需要使用如下命令：</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">.&#x2F;bin&#x2F;hdfs dfs –mkdir &#x2F;input</code></pre>\n<p>可以使用rm命令删除一个目录，比如，可以使用如下命令删除刚才在HDFS中创建的“/input”目录（不是“/user/hadoop/input”目录）：</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">.&#x2F;bin&#x2F;hdfs dfs –rm –r &#x2F;input</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/db1f1943c38843d6a84a142620ce09b0.png\" alt=\"在这里插入图片描述\"><br>上面命令中，“-r”参数表示如果删除“/input”目录及其子目录下的所有内容，如果要删除的一个目录包含了子目录，则必须使用“-r”参数，否则会执行失败。</p>\n<h3 id=\"文件操作\"><a href=\"#文件操作\" class=\"headerlink\" title=\"文件操作\"></a>文件操作</h3><p>在实际应用中，经常需要从本地文件系统向HDFS中上传文件，或者把HDFS中的文件下载到本地文件系统中。<br>首先，使用vim编辑器，在本地Linux文件系统的“/home/hadoop/”目录下创建一个文件myLocalFile.txt，里面可以随意输入一些单词，比如，输入如下三行：</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">Hadoop\nSpark\nXMU DBLAB</code></pre>\n<p>下面的图里文本内容在左上角：<br><img src=\"https://img-blog.csdnimg.cn/4d7a74f4fd5c412e847c9a8f36603814.png\" alt=\"在这里插入图片描述\"><br>然后，可以使用如下命令把本地文件系统的“/home/hadoop/myLocalFile.txt”上传到HDFS中的当前用户目录的input目录下，也就是上传到HDFS的“/user/hadoop/input/”目录下：</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">.&#x2F;bin&#x2F;hdfs dfs -put &#x2F;home&#x2F;hadoop&#x2F;myLocalFile.txt  input</code></pre>\n<p>可以使用ls命令查看一下文件是否成功上传到HDFS中，具体如下：</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">.&#x2F;bin&#x2F;hdfs dfs –ls input</code></pre>\n<p>下面使用如下命令查看HDFS中的myLocalFile.txt这个文件的内容：</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">.&#x2F;bin&#x2F;hdfs dfs –cat input&#x2F;myLocalFile.txt</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/074739397bc94d22a5fd6be08f0a2510.png\" alt=\"在这里插入图片描述\"><br>下面把HDFS中的myLocalFile.txt文件下载到本地文件系统中的“/home/hadoop/下载/”这个目录下，命令如下：</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">.&#x2F;bin&#x2F;hdfs dfs -get input&#x2F;myLocalFile.txt  &#x2F;home&#x2F;hadoop&#x2F;下载</code></pre>\n<p>可以使用如下命令，到本地文件系统查看下载下来的文件myLocalFile.txt：</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">$ cd ~\n$ cd 下载\n$ ls\n$ cat myLocalFile.txt</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/2a7d403f09e643fa80ab498e96081aec.png\" alt=\"在这里插入图片描述\"><br>最后，了解一下如何把文件从HDFS中的一个目录拷贝到HDFS中的另外一个目录。比如，如果要把HDFS的“/user/hadoop/input/myLocalFile.txt”文件，拷贝到HDFS的另外一个目录“/input”中（注意，这个input目录位于HDFS根目录下），可以使用如下命令：</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">.&#x2F;bin&#x2F;hdfs dfs -cp input&#x2F;myLocalFile.txt  &#x2F;input</code></pre>\n<h2 id=\"利用Web界面管理HDFS\"><a href=\"#利用Web界面管理HDFS\" class=\"headerlink\" title=\"利用Web界面管理HDFS\"></a>利用Web界面管理HDFS</h2><p>打开Linux自带的Firefox浏览器，输入当初本地查看HDFS的链接（我的改成了8020，避免9000的端口占用）<br><img src=\"https://img-blog.csdnimg.cn/16516a9a187748af98325b04fe709718.png\" alt=\"在这里插入图片描述\"></p>\n<h2 id=\"利用Java-API与HDFS进行交互\"><a href=\"#利用Java-API与HDFS进行交互\" class=\"headerlink\" title=\"利用Java API与HDFS进行交互\"></a>利用Java API与HDFS进行交互</h2><p>利用Java API进行交互，需要利用软件Eclipse编写Java程序。</p>\n<h3 id=\"在Ubuntu中安装Eclipse\"><a href=\"#在Ubuntu中安装Eclipse\" class=\"headerlink\" title=\"在Ubuntu中安装Eclipse\"></a>在Ubuntu中安装Eclipse</h3><p>在ubuntu的软件中心中找到Eclipse<br><img src=\"https://img-blog.csdnimg.cn/7f8696a16b6443a79c90660f2a90d9c1.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/e8bbb942a51c497a8fbf40cb51efc9ef.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/9a54cdb5857742bcbf364cf616e1772a.png\" alt=\"在这里插入图片描述\"></p>\n<h3 id=\"在Eclipse创建项目\"><a href=\"#在Eclipse创建项目\" class=\"headerlink\" title=\"在Eclipse创建项目\"></a>在Eclipse创建项目</h3><p><img src=\"https://img-blog.csdnimg.cn/c0ba699d75814914ae238dc035a340a5.png\" alt=\"在这里插入图片描述\"><br>第一次打开Eclipse,需要填写workspace(工作空间)，用来保存程序所在的位置，这里按照默认，不需要改动，如下图<br><img src=\"https://img-blog.csdnimg.cn/1cf96b395e114f6dbe9dd348a8747263.png\" alt=\"在这里插入图片描述\"></p>\n<p>点击“OK”按钮，进入Eclipse软件。</p>\n<p>可以看出，由于当前是采用hadoop用户登录了Linux系统，因此，默认的工作空间目录位于hadoop用户目录“/home/hadoop”下。<br>Eclipse启动以后，会呈现如图所示的界面。</p>\n<p><img src=\"https://img-blog.csdnimg.cn/53f57b7b0dd24147835bf24b660c74f2.png\" alt=\"在这里插入图片描述\"></p>\n<p>选择“File-&gt;New-&gt;Java Project”菜单，开始创建一个Java工程，会弹出如图4-4所示界面。<br><img src=\"https://img-blog.csdnimg.cn/34d5da46c7cd4d0baf71f32673f22646.png\" alt=\"在这里插入图片描述\"><br>在“Project name”后面输入工程名称“HDFSExample”，选中“Use default location”，让这个Java工程的所有文件都保存到“/home/hadoop/workspace/HDFSExample”目录下。在“JRE”这个选项卡中，可以选择当前的Linux系统中已经安装好的JDK，比如java-8-openjdk-amd64。然后，点击界面底部的“Next&gt;”按钮，进入下一步的设置。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>注：我在实验过程中找到的不是这个jdk，同样，后面的版本也不是2.7.1</p></blockquote>\n<p><img src=\"https://img-blog.csdnimg.cn/dfc413ed1bea4534b48b9fc703346ac0.png\" alt=\"在这里插入图片描述\"></p>\n<p><img src=\"https://img-blog.csdnimg.cn/bef52ff1000044b8a1f7dcb2e176fb3d.png\" alt=\"在这里插入图片描述\"></p>\n<h3 id=\"为项目添加需要用到的JAR包\"><a href=\"#为项目添加需要用到的JAR包\" class=\"headerlink\" title=\"为项目添加需要用到的JAR包\"></a>为项目添加需要用到的JAR包</h3><p>进入下一步的设置以后，会弹出如图所示界面。<br><img src=\"https://img-blog.csdnimg.cn/5e2749f737a64124b71141c4506cfba4.png\" alt=\"在这里插入图片描述\"><br>需要在这个界面中加载该Java工程所需要用到的JAR包，这些JAR包中包含了可以访问HDFS的Java API。这些JAR包都位于Linux系统的Hadoop安装目录下，对于本教程而言，就是在“/usr/local/hadoop/share/hadoop”目录下。点击界面中的“Libraries”选项卡，然后，点击界面右侧的“Add External JARs…”按钮，会弹出如图所示界面。<br><img src=\"https://img-blog.csdnimg.cn/6434d646a6704b18a8fe146cba3d6406.png\" alt=\"在这里插入图片描述\"><br>在该界面中，上面的一排目录按钮（即“usr”、“local”、“hadoop”、“share”、“hadoop”、“mapreduce”和“lib”），当点击某个目录按钮时，就会在下面列出该目录的内容。<br>为了编写一个能够与HDFS交互的Java应用程序，一般需要向Java工程中添加以下JAR包：<br>（1）”/usr/local/hadoop/share/hadoop/common”目录下的hadoop-common-2.7.1.jar和haoop-nfs-2.7.1.jar；<br>（2）/usr/local/hadoop/share/hadoop/common/lib”目录下的所有JAR包；<br>（3）“/usr/local/hadoop/share/hadoop/hdfs”目录下的haoop-hdfs-2.7.1.jar和haoop-hdfs-nfs-2.7.1.jar；<br>（4）“/usr/local/hadoop/share/hadoop/hdfs/lib”目录下的所有JAR包。<br>比如，如果要把“/usr/local/hadoop/share/hadoop/common”目录下的hadoop-common-2.7.1.jar和haoop-nfs-2.7.1.jar添加到当前的Java工程中，可以在界面中点击目录按钮，进入到common目录，然后，界面会显示出common目录下的所有内容（如图4-7所示）。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>注：我的版本是3.1.3</p></blockquote>\n<p><img src=\"https://img-blog.csdnimg.cn/a78c0b26112b4e0c9ab30c7bcc20a186.png\" alt=\"在这里插入图片描述\"></p>\n<h3 id=\"编写Java应用程序代码\"><a href=\"#编写Java应用程序代码\" class=\"headerlink\" title=\"编写Java应用程序代码\"></a>编写Java应用程序代码</h3><p>下面编写一个Java应用程序，用来检测HDFS中是否存在一个文件。<br>请在Eclipse工作界面左侧的“Package Explorer”面板中（如图4-9所示），找到刚才创建好的工程名称“HDFSExample”，然后在该工程名称上点击鼠标右键，在弹出的菜单中选择“New-&gt;Class”菜单。<br>选择“New-&gt;Class”菜单以后会出现如图所示界面。<br><img src=\"https://img-blog.csdnimg.cn/f9796a94db1a4a8991ce579b1348cd79.png\" alt=\"在这里插入图片描述\"><br>在该界面中，只需要在“Name”后面输入新建的Java类文件的名称，这里采用名称“HDFSFileIfExist”，其他都可以采用默认设置，然后，点击界面右下角“Finish”按钮，出现如图所示界面。<br><img src=\"https://img-blog.csdnimg.cn/ab4b68dd46474566930d420aa697af8c.png\" alt=\"在这里插入图片描述\"><br>可以看出，Eclipse自动创建了一个名为“HDFSFileIfExist.java”的源代码文件，请在该文件中输入以下代码：</p>\n<pre class=\"line-numbers language-java\" data-language=\"java\"><code class=\"language-java\">import org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.FileSystem;\nimport org.apache.hadoop.fs.Path;\npublic class HDFSFileIfExist &#123;\n    public static void main(String[] args)&#123;\n        try&#123;\n            String fileName &#x3D; &quot;test&quot;;\n            Configuration conf &#x3D; new Configuration();\n            conf.set(&quot;fs.defaultFS&quot;, &quot;hdfs:&#x2F;&#x2F;localhost:9000&quot;);\n            conf.set(&quot;fs.hdfs.impl&quot;, &quot;org.apache.hadoop.hdfs.DistributedFileSystem&quot;);\n            FileSystem fs &#x3D; FileSystem.get(conf);\n            if(fs.exists(new Path(fileName)))&#123;\n                System.out.println(&quot;文件存在&quot;);\n            &#125;else&#123;\n                System.out.println(&quot;文件不存在&quot;);\n            &#125;\n \n        &#125;catch (Exception e)&#123;\n            e.printStackTrace();\n        &#125;\n    &#125;\n&#125;</code></pre>\n<p>该程序用来测试HDFS中是否存在一个文件，其中有一行代码：</p>\n<pre class=\"line-numbers language-java\" data-language=\"java\"><code class=\"language-java\">String fileName &#x3D; &quot;test&quot;</code></pre>\n<p>这行代码给出了需要被检测的文件名称是“test”，没有给出路径全称，表示是采用了相对路径，实际上就是测试当前登录Linux系统的用户hadoop，在HDFS中对应的用户目录下是否存在test文件，也就是测试HDFS中的“/user/hadoop/”目录下是否存在test文件。</p>\n<h3 id=\"编译运行程序\"><a href=\"#编译运行程序\" class=\"headerlink\" title=\"编译运行程序\"></a>编译运行程序</h3><p>在开始编译运行程序之前，请一定确保Hadoop已经启动运行，如果还没有启动，需要打开一个Linux终端，输入以下命令启动Hadoop：</p>\n<pre class=\"line-numbers language-java\" data-language=\"java\"><code class=\"language-java\">cd &#x2F;usr&#x2F;local&#x2F;hadoop\n.&#x2F;sbin&#x2F;start-dfs.sh</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/bbf82e0ea9724490a8cbd0fe8c4ca1f5.png\" alt=\"在这里插入图片描述\"><br>现在就可以编译运行上面编写的代码。可以直接点击Eclipse工作界面上部的运行程序的快捷按钮，当把鼠标移动到该按钮上时，在弹出的菜单中选择“Run As”，继续在弹出来的菜单中选择“Java Application”。</p>\n<p><img src=\"https://img-blog.csdnimg.cn/a78a6f52f69c48e8a078ee7f9b161e5a.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/b1b831f5de0f46d88c90b683f46d153d.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/18fd4ddbde3c4a789b1e70ca479b01f9.png\" alt=\"在这里插入图片描述\"></p>\n<h3 id=\"应用程序的部署\"><a href=\"#应用程序的部署\" class=\"headerlink\" title=\"应用程序的部署\"></a>应用程序的部署</h3><p>下面介绍如何把Java应用程序生成JAR包，部署到Hadoop平台上运行。首先，在Hadoop安装目录下新建一个名称为myapp的目录，用来存放我们自己编写的Hadoop应用程序，可以在Linux的终端中执行如下命令：</p>\n<pre class=\"line-numbers language-java\" data-language=\"java\"><code class=\"language-java\">cd &#x2F;usr&#x2F;local&#x2F;hadoop\nmkdir myapp</code></pre>\n<p>然后，请在Eclipse工作界面左侧的“Package Explorer”面板中，在工程名称“HDFSExample”上点击鼠标右键，在弹出的菜单中选择“Export”。<br><img src=\"https://img-blog.csdnimg.cn/e14ea75a9f2f4b2384f179c765216db3.png\" alt=\"在这里插入图片描述\"><br>在该界面中，选择“Runnable JAR file”，然后，点击“Next&gt;”按钮，弹出如下图所示界面。<br><img src=\"https://img-blog.csdnimg.cn/8d92c60ffe4b455ba123a3bd0114bac9.png\" alt=\"在这里插入图片描述\"><br>在该界面中，“Launch configuration”用于设置生成的JAR包被部署启动时运行的主类，需要在下拉列表中选择刚才配置的类“HDFSFileIfExist-HDFSExample”。在“Export destination”中需要设置JAR包要输出保存到哪个目录，比如，这里设置为“/usr/local/hadoop/myapp/HDFSExample.jar”。在“Library handling”下面选择“Extract required libraries into generated JAR”。然后，点击“Finish”按钮，会出现如下图所示界面。<br><img src=\"https://img-blog.csdnimg.cn/566d833369fe4c0f866ebb36df6d5f89.png\" alt=\"在这里插入图片描述\"><br>可以忽略该界面的信息，直接点击界面右下角的“OK”按钮，启动打包过程。打包过程结束后，会出现一个警告信息界面，如图所示。<br><img src=\"https://img-blog.csdnimg.cn/de86be95af134154962865f214318a20.png\" alt=\"在这里插入图片描述\"><br>可以忽略该界面的信息，直接点击界面右下角的“OK”按钮。至此，已经顺利把HDFSExample工程打包生成了HDFSExample.jar。<br><img src=\"https://img-blog.csdnimg.cn/9d8902c6e44f46519b46f955e1db7a2f.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/237ce194e38d443cb51461b8c03a0c45.png\" alt=\"在这里插入图片描述\"><br>可以到Linux系统中查看一下生成的HDFSExample.jar文件，可以在Linux的终端中执行如下命令：</p>\n<pre class=\"line-numbers language-java\" data-language=\"java\"><code class=\"language-java\">cd &#x2F;usr&#x2F;local&#x2F;hadoop&#x2F;myapp\nls</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/e858b555fe7a4be1bd7c340aece36342.png\" alt=\"在这里插入图片描述\"><br>可以看到，“/usr/local/hadoop/myapp”目录下已经存在一个HDFSExample.jar文件。现在，就可以在Linux系统中，使用hadoop jar命令运行程序，命令如下：</p>\n<pre class=\"line-numbers language-java\" data-language=\"java\"><code class=\"language-java\">cd &#x2F;usr&#x2F;local&#x2F;hadoop\n.&#x2F;bin&#x2F;hadoop jar .&#x2F;myapp&#x2F;HDFSExample.jar</code></pre>\n<p>或者也可以使用如下命令运行程序：</p>\n<pre class=\"line-numbers language-java\" data-language=\"java\"><code class=\"language-java\">cd &#x2F;usr&#x2F;local&#x2F;hadoop\njava -jar .&#x2F;myapp&#x2F;HDFSExample.jar</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/d33820b5f87b45b7bcdd971c6adc0f94.png\" alt=\"在这里插入图片描述\"></p>\n<h2 id=\"附录\"><a href=\"#附录\" class=\"headerlink\" title=\"附录\"></a>附录</h2><h3 id=\"写入文件\"><a href=\"#写入文件\" class=\"headerlink\" title=\"写入文件\"></a>写入文件</h3><pre class=\"line-numbers language-java\" data-language=\"java\"><code class=\"language-java\">import org.apache.hadoop.conf.Configuration;  \nimport org.apache.hadoop.fs.FileSystem;\nimport org.apache.hadoop.fs.FSDataOutputStream;\nimport org.apache.hadoop.fs.Path;\n \npublic class Chapter3 &#123;    \n        public static void main(String[] args) &#123; \n                try &#123;\n                        Configuration conf &#x3D; new Configuration();  \n                        conf.set(&quot;fs.defaultFS&quot;,&quot;hdfs:&#x2F;&#x2F;localhost:9000&quot;);\n                        conf.set(&quot;fs.hdfs.impl&quot;,&quot;org.apache.hadoop.hdfs.DistributedFileSystem&quot;);\n                        FileSystem fs &#x3D; FileSystem.get(conf);\n                        byte[] buff &#x3D; &quot;Hello world&quot;.getBytes(); &#x2F;&#x2F; 要写入的内容\n                        String filename &#x3D; &quot;test&quot;; &#x2F;&#x2F;要写入的文件名\n                        FSDataOutputStream os &#x3D; fs.create(new Path(filename));\n                        os.write(buff,0,buff.length);\n                        System.out.println(&quot;Create:&quot;+ filename);\n                        os.close();\n                        fs.close();\n                &#125; catch (Exception e) &#123;  \n                        e.printStackTrace();  \n                &#125;  \n        &#125;  \n&#125;</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/c45b98b75462493da568b6864c8e4ac2.png\" alt=\"在这里插入图片描述\"></p>\n<h3 id=\"判断文件是否存在\"><a href=\"#判断文件是否存在\" class=\"headerlink\" title=\"判断文件是否存在\"></a>判断文件是否存在</h3><pre class=\"line-numbers language-java\" data-language=\"java\"><code class=\"language-java\">import org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.FileSystem;\nimport org.apache.hadoop.fs.Path;\n \npublic class Chapter3 &#123;\n        public static void main(String[] args) &#123;\n                    try &#123;\n                            String filename &#x3D; &quot;test&quot;;\n \n                            Configuration conf &#x3D; new Configuration();\n                            conf.set(&quot;fs.defaultFS&quot;,&quot;hdfs:&#x2F;&#x2F;localhost:9000&quot;);\n                            conf.set(&quot;fs.hdfs.impl&quot;,&quot;org.apache.hadoop.hdfs.DistributedFileSystem&quot;);\n                            FileSystem fs &#x3D; FileSystem.get(conf);\n                            if(fs.exists(new Path(filename)))&#123;\n                                    System.out.println(&quot;文件存在&quot;);\n                            &#125;else&#123;\n                                    System.out.println(&quot;文件不存在&quot;);\n                            &#125;\n                            fs.close();\n                &#125; catch (Exception e) &#123;\n                        e.printStackTrace();\n                &#125;\n        &#125;\n&#125; </code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/28f8d73009e443979c4a3df804011bea.png\" alt=\"在这里插入图片描述\"></p>\n<h3 id=\"读取文件\"><a href=\"#读取文件\" class=\"headerlink\" title=\"读取文件\"></a>读取文件</h3><pre class=\"line-numbers language-java\" data-language=\"java\"><code class=\"language-java\">import java.io.BufferedReader;\nimport java.io.InputStreamReader;\n \nimport org.apache.hadoop.conf.Configuration;\nimport org.apache.hadoop.fs.FileSystem;\nimport org.apache.hadoop.fs.Path;\nimport org.apache.hadoop.fs.FSDataInputStream;\n \npublic class Chapter3 &#123;\n        public static void main(String[] args) &#123;\n                try &#123;\n                        Configuration conf &#x3D; new Configuration();\n                        conf.set(&quot;fs.defaultFS&quot;,&quot;hdfs:&#x2F;&#x2F;localhost:9000&quot;);\n                        conf.set(&quot;fs.hdfs.impl&quot;,&quot;org.apache.hadoop.hdfs.DistributedFileSystem&quot;);\n                        FileSystem fs &#x3D; FileSystem.get(conf);\n                        Path file &#x3D; new Path(&quot;test&quot;); \n                        FSDataInputStream getIt &#x3D; fs.open(file);\n                        BufferedReader d &#x3D; new BufferedReader(new InputStreamReader(getIt));\n                        String content &#x3D; d.readLine(); &#x2F;&#x2F;读取文件一行\n                        System.out.println(content);\n                        d.close(); &#x2F;&#x2F;关闭文件\n                        fs.close(); &#x2F;&#x2F;关闭hdfs\n                &#125; catch (Exception e) &#123;\n                        e.printStackTrace();\n                &#125;\n        &#125;\n&#125;</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/0973071997ff451eaa41339a5bb712fb.png\" alt=\"在这里插入图片描述\"></p>\n<h2 id=\"问题与处理\"><a href=\"#问题与处理\" class=\"headerlink\" title=\"问题与处理\"></a>问题与处理</h2><h3 id=\"问题1\"><a href=\"#问题1\" class=\"headerlink\" title=\"问题1\"></a>问题1</h3><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><a href=\"https://ubuntu.dovov.com/16219/ubuntu-18-04%E9%94%81%E5%B1%8F%E8%83%8C%E6%99%AF%E6%8B%92%E7%BB%9D%E6%94%B9%E5%8F%98.html\">https://ubuntu.dovov.com/16219/ubuntu-18-04%E9%94%81%E5%B1%8F%E8%83%8C%E6%99%AF%E6%8B%92%E7%BB%9D%E6%94%B9%E5%8F%98.html</a></p></blockquote>\n<h3 id=\"问题2\"><a href=\"#问题2\" class=\"headerlink\" title=\"问题2\"></a>问题2</h3><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><a href=\"https://ubuntu.dovov.com/16219/ubuntu-18-04%E9%94%81%E5%B1%8F%E8%83%8C%E6%99%AF%E6%8B%92%E7%BB%9D%E6%94%B9%E5%8F%98.html\">https://ubuntu.dovov.com/16219/ubuntu-18-04%E9%94%81%E5%B1%8F%E8%83%8C%E6%99%AF%E6%8B%92%E7%BB%9D%E6%94%B9%E5%8F%98.html</a></p>\n<h3 id=\"问题3\"><a href=\"#问题3\" class=\"headerlink\" title=\"问题3\"></a>问题3</h3><p><a href=\"https://www.cnblogs.com/DylanTam/p/9601859.html\">https://www.cnblogs.com/DylanTam/p/9601859.html</a></p>\n<h3 id=\"问题4\"><a href=\"#问题4\" class=\"headerlink\" title=\"问题4\"></a>问题4</h3><p><a href=\"https://blog.csdn.net/loulanyue_/article/details/90610109\">https://blog.csdn.net/loulanyue_/article/details/90610109</a></p></blockquote>\n","text":"来源： https://dblab.xmu.edu.cn/blog/290/ 首先回顾上一节 https://blog.csdn.net/Algernon98/article/details/129232375?spm=1001.2014.3001.5501 我们已经得到了如下配...","link":"","photos":[],"count_time":{"symbolsCount":"11k","symbolsTime":"10 mins."},"categories":[{"name":"信管","slug":"信管","count":19,"path":"api/categories/信管.json"}],"tags":[{"name":"大数据","slug":"大数据","count":7,"path":"api/tags/大数据.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%88%A9%E7%94%A8Shell%E5%91%BD%E4%BB%A4%E4%B8%8EHDFS%E8%BF%9B%E8%A1%8C%E4%BA%A4%E4%BA%92\"><span class=\"toc-text\">利用Shell命令与HDFS进行交互</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%9B%AE%E5%BD%95%E6%93%8D%E4%BD%9C\"><span class=\"toc-text\">目录操作</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%96%87%E4%BB%B6%E6%93%8D%E4%BD%9C\"><span class=\"toc-text\">文件操作</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%88%A9%E7%94%A8Web%E7%95%8C%E9%9D%A2%E7%AE%A1%E7%90%86HDFS\"><span class=\"toc-text\">利用Web界面管理HDFS</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%88%A9%E7%94%A8Java-API%E4%B8%8EHDFS%E8%BF%9B%E8%A1%8C%E4%BA%A4%E4%BA%92\"><span class=\"toc-text\">利用Java API与HDFS进行交互</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%9C%A8Ubuntu%E4%B8%AD%E5%AE%89%E8%A3%85Eclipse\"><span class=\"toc-text\">在Ubuntu中安装Eclipse</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%9C%A8Eclipse%E5%88%9B%E5%BB%BA%E9%A1%B9%E7%9B%AE\"><span class=\"toc-text\">在Eclipse创建项目</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%B8%BA%E9%A1%B9%E7%9B%AE%E6%B7%BB%E5%8A%A0%E9%9C%80%E8%A6%81%E7%94%A8%E5%88%B0%E7%9A%84JAR%E5%8C%85\"><span class=\"toc-text\">为项目添加需要用到的JAR包</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%BC%96%E5%86%99Java%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E4%BB%A3%E7%A0%81\"><span class=\"toc-text\">编写Java应用程序代码</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%BC%96%E8%AF%91%E8%BF%90%E8%A1%8C%E7%A8%8B%E5%BA%8F\"><span class=\"toc-text\">编译运行程序</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E7%9A%84%E9%83%A8%E7%BD%B2\"><span class=\"toc-text\">应用程序的部署</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E9%99%84%E5%BD%95\"><span class=\"toc-text\">附录</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%86%99%E5%85%A5%E6%96%87%E4%BB%B6\"><span class=\"toc-text\">写入文件</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%88%A4%E6%96%AD%E6%96%87%E4%BB%B6%E6%98%AF%E5%90%A6%E5%AD%98%E5%9C%A8\"><span class=\"toc-text\">判断文件是否存在</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%AF%BB%E5%8F%96%E6%96%87%E4%BB%B6\"><span class=\"toc-text\">读取文件</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E9%97%AE%E9%A2%98%E4%B8%8E%E5%A4%84%E7%90%86\"><span class=\"toc-text\">问题与处理</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E9%97%AE%E9%A2%981\"><span class=\"toc-text\">问题1</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E9%97%AE%E9%A2%982\"><span class=\"toc-text\">问题2</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E9%97%AE%E9%A2%983\"><span class=\"toc-text\">问题3</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E9%97%AE%E9%A2%984\"><span class=\"toc-text\">问题4</span></a></li></ol></li></ol>","author":{"name":"Algernon","slug":"blog-author","avatar":"https://user-images.githubusercontent.com/54904760/224857900-b2e8457c-43d2-46b7-901c-6c770f24bbad.png","link":"/","description":"谁也没见过风，更别说我和你了","socials":{"github":"https://github.com/Algernon98","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/Algernon98","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://space.bilibili.com/281724502"}}}},"mapped":true,"prev_post":{"title":"【大数据基础】HBase2.2.2安装及编程实践指南","uid":"f8ebb92f8b4529095c1c2d3c0a9053f4","slug":"大数据5","date":"2023-03-12T13:50:49.000Z","updated":"2023-04-04T02:36:23.836Z","comments":true,"path":"api/articles/大数据5.json","keywords":null,"cover":[],"text":"实验 https://dblab.xmu.edu.cn/blog/2442/ HBase2.2.2安装&gt; 解压安装包hbase-2.2.2-bin.tar.gz至路径 /usr/local，命令如下： cd ~ sudo tar -zxf ~&#x2F;下载&#x2F;hb...","link":"","photos":[],"count_time":{"symbolsCount":"12k","symbolsTime":"11 mins."},"categories":[{"name":"信管","slug":"信管","count":19,"path":"api/categories/信管.json"}],"tags":[{"name":"大数据","slug":"大数据","count":7,"path":"api/tags/大数据.json"}],"author":{"name":"Algernon","slug":"blog-author","avatar":"https://user-images.githubusercontent.com/54904760/224857900-b2e8457c-43d2-46b7-901c-6c770f24bbad.png","link":"/","description":"谁也没见过风，更别说我和你了","socials":{"github":"https://github.com/Algernon98","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/Algernon98","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://space.bilibili.com/281724502"}}}}},"next_post":{"title":"【大数据基础】Hadoop3.1.3安装教程","uid":"78b7ddde844e9e414cf17e82e5c26627","slug":"大数据3","date":"2023-02-27T13:50:49.000Z","updated":"2023-04-04T02:33:40.265Z","comments":true,"path":"api/articles/大数据3.json","keywords":null,"cover":[],"text":"来源： https://dblab.xmu.edu.cn/blog/2441/ 前言：重装解决一切bug！事实上，问题中的绝大部分衍生问题都可以通过重装解决。 实验内容创建Hadoop用户首先按 ctrl+alt+t 打开终端窗口，输入如下命令创建新用户 : sudo usera...","link":"","photos":[],"count_time":{"symbolsCount":"11k","symbolsTime":"10 mins."},"categories":[{"name":"信管","slug":"信管","count":19,"path":"api/categories/信管.json"}],"tags":[{"name":"大数据","slug":"大数据","count":7,"path":"api/tags/大数据.json"}],"author":{"name":"Algernon","slug":"blog-author","avatar":"https://user-images.githubusercontent.com/54904760/224857900-b2e8457c-43d2-46b7-901c-6c770f24bbad.png","link":"/","description":"谁也没见过风，更别说我和你了","socials":{"github":"https://github.com/Algernon98","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/Algernon98","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://space.bilibili.com/281724502"}}}}}}