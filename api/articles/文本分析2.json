{"title":"【文本分析】（二）","uid":"fe7562c539a88737236a621707cb5848","slug":"文本分析2","date":"2022-11-03T15:07:49.000Z","updated":"2022-11-03T15:04:09.635Z","comments":true,"path":"api/articles/文本分析2.json","keywords":null,"cover":[],"content":"<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import jieba\nimport jieba.posseg as psg\nfrom collections import Counter\ntext &#x3D; &#39;我现在在jupyter notebook上写文本分析的代码！&#39;\n\n\nfor w in jieba.cut(text):\n    print(w)</code></pre>\n<pre><code>Building prefix dict from the default dictionary ...\nLoading model from cache C:\\Users\\83854\\AppData\\Local\\Temp\\jieba.cache\nLoading model cost 0.417 seconds.\nPrefix dict has been built successfully.\n\n\n我\n现在\n在\njupyter\n\nnotebook\n上\n写\n文本\n分析\n的\n代码\n！\n</code></pre><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import jieba;\nseg_list &#x3D; jieba.cut(\n    &quot;甜豆腐脑和咸豆腐脑哪个更好吃呢？&quot;\n)\nfor w in seg_list:\n    print(w)</code></pre>\n<pre><code>甜\n豆腐脑\n和\n咸\n豆腐脑\n哪个\n更\n好吃\n呢\n？\n</code></pre><p>甜豆腐脑和咸豆腐脑属于常用词，我们换成专业名词，圣遗物“华馆梦醒形骸记”和“来歆余响”</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import jieba;\nseg_list &#x3D; jieba.cut(\n    &quot;华馆梦醒形骸记和来歆余响哪个更适合神里呢？&quot;\n)\nfor w in seg_list:\n    print(w)</code></pre>\n<pre><code>华馆\n梦醒\n形骸\n记和来歆\n余响\n哪个\n更\n适合\n神里\n呢\n？\n</code></pre><p>可以看出，jieba并没有成功断开，现在我们导入词库</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import jieba;\njieba.add_word(&#39;华馆梦醒形骸记&#39;)#添加词库\njieba.add_word(&#39;来歆余响&#39;)\nseg_list &#x3D; jieba.cut(\n    &quot;华馆梦醒形骸记和来歆余响哪个更适合神里呢？&quot;\n)\nfor w in seg_list:\n    print(w)</code></pre>\n<pre><code>华馆梦醒形骸记\n和\n来歆余响\n哪个\n更\n适合\n神里\n呢\n？\n</code></pre><p>现在我们可以看到，再加入特定词的词库后，jieba成功进行了分词</p>\n<p>我们可以用jieba.load_userdict(‘路径.txt’)方法一次性导入整个词库，txt文件中为每行一个特定的词</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import jieba\nimport jieba.analyse\nimport jieba\nimport jieba.posseg as psg\nfrom collections import Counter\n# 待分词的文本路径\nsourceTxt &#x3D; r&quot;C:&#x2F;&#x2F;Users&#x2F;&#x2F;83854&#x2F;&#x2F;Documents&#x2F;&#x2F;shujvji&#x2F;&#x2F;genshin.txt&quot;\n# 分好词后的文本路径\ntargetTxt &#x3D; r&quot;C:&#x2F;&#x2F;Users&#x2F;&#x2F;83854&#x2F;&#x2F;Documents&#x2F;&#x2F;shujvji&#x2F;&#x2F;fenci2.txt&quot;\n\n# 对文本进行操作\n\nwith open(sourceTxt, &#39;r&#39;, encoding &#x3D; &#39;utf-8&#39;) as sourceFile, open(targetTxt, &#39;a+&#39;, encoding &#x3D; &#39;utf-8&#39;) as targetFile:\n    for line in sourceFile:\n        seg &#x3D; jieba.cut(line.strip(), cut_all &#x3D; False)\n        # 分好词之后之间用空格隔断\n        output &#x3D; &#39; &#39;.join(seg)\n        targetFile.write(output)\n        targetFile.write(&#39;\\n&#39;)\n    print(&#39;写入成功！&#39;)\n\n# 提取关键词\nwith open(targetTxt, &#39;r&#39;, encoding &#x3D; &#39;utf-8&#39;) as file:\n    text &#x3D; file.readlines()\n    &quot;&quot;&quot;\n    几个参数解释：\n        * text : 待提取的字符串类型文本\n        * topK : 返回TF-IDF权重最大的关键词的个数，默认为20个\n        * withWeight : 是否返回关键词的权重值，默认为False\n        * allowPOS : 包含指定词性的词，默认为空\n    &quot;&quot;&quot;\n    keywords &#x3D; jieba.analyse.extract_tags(str(text), topK &#x3D; 100, withWeight&#x3D;True, allowPOS&#x3D;())\n    print(keywords)\n    print(&#39;提取完毕！&#39;)\n</code></pre>\n<pre><code>写入成功！\n[(&#39;音乐&#39;, 0.30376152967529807), (&#39;须弥&#39;, 0.1346632360175712), (&#39;原神&#39;, 0.12497199124472864), (&#39;陈老师&#39;, 0.08320263205482652), (&#39;幕后&#39;, 0.06823193339024688), (&#39;真的&#39;, 0.06515894124271353), (&#39;hoyomix&#39;, 0.06115650635380338), (&#39;原宝&#39;, 0.058497527816681494), (&#39;mix&#39;, 0.05052059220531584), (&#39;团队&#39;, 0.04872411839589858), (&#39;那契&#39;, 0.03988467805682829), (&#39;hoyo&#39;, 0.03988467805682829), (&#39;视频&#39;, 0.039425474014386126), (&#39;感谢&#39;, 0.03666087076072954), (&#39;喜欢&#39;, 0.035514340588202846), (&#39;米哈&#39;, 0.035251415848932384), (&#39;好听&#39;, 0.03470912869932385), (&#39;数列&#39;, 0.033130735337255336), (&#39;yyds&#39;, 0.029248763908340747), (&#39;大佬&#39;, 0.0274163437665347), (&#39;呜呜&#39;, 0.027097537520004447), (&#39;斐波&#39;, 0.02658978537121886), (&#39;枫丹&#39;, 0.02658978537121886), (&#39;感觉&#39;, 0.026350321191172154), (&#39;游戏&#39;, 0.02558340660825623), (&#39;期待&#39;, 0.025368599082068503), (&#39;HOYO&#39;, 0.023930806834096974), (&#39;稻妻&#39;, 0.023930806834096974), (&#39;陈致&#39;, 0.023930806834096974), (&#39;旅人&#39;, 0.023280005443727755), (&#39;前瞻&#39;, 0.023228101079139234), (&#39;曲子&#39;, 0.02311102483163701), (&#39;啊啊啊&#39;, 0.022779475735409255), (&#39;就是&#39;, 0.022408588749270462), (&#39;战斗&#39;, 0.02202536894074733), (&#39;老师&#39;, 0.021263640122108542), (&#39;节奏&#39;, 0.02124655568899911), (&#39;创作&#39;, 0.020903159805560498), (&#39;但是&#39;, 0.020422561798879003), (&#39;角色&#39;, 0.020304841056014235), (&#39;可以&#39;, 0.019490209364768682), (&#39;配乐&#39;, 0.01754026047), (&#39;摩斯&#39;, 0.017058200780604982), (&#39;出来&#39;, 0.016520537436521352), (&#39;世界&#39;, 0.016514234852021796), (&#39;虽然&#39;, 0.016161079021601424), (&#39;那兰&#39;, 0.015953871222731317), (&#39;...&#39;, 0.015953871222731317), (&#39;不够看&#39;, 0.015953871222731317), (&#39;卧槽&#39;, 0.015458938669928826), (&#39;各位&#39;, 0.015299619790215747), (&#39;永远&#39;, 0.015225989643251779), (&#39;旅行者&#39;, 0.015167384782104092), (&#39;一个&#39;, 0.015040307680409253), (&#39;冰箱&#39;, 0.015034945192900358), (&#39;每次&#39;, 0.014728756026823843), (&#39;急急&#39;, 0.014410247823131671), (&#39;时候&#39;, 0.014308539813523131), (&#39;沙漠&#39;, 0.014100965526338969), (&#39;音乐会&#39;, 0.014064057475676158), (&#39;听到&#39;, 0.014041888104221531), (&#39;加油&#39;, 0.013711853238031585), (&#39;语言&#39;, 0.013708846917571176), (&#39;原石&#39;, 0.01329489268560943), (&#39;bgm&#39;, 0.01329489268560943), (&#39;MiX&#39;, 0.01329489268560943), (&#39;遐想&#39;, 0.013227349117540038), (&#39;一直&#39;, 0.013174950427226424), (&#39;雨林&#39;, 0.0131551953525), (&#39;审美&#39;, 0.013021219682989324), (&#39;钢琴&#39;, 0.012852894857720195), (&#39;落水&#39;, 0.012637714661650356), (&#39;不同&#39;, 0.012618082724641905), (&#39;太棒了&#39;, 0.012606459402246441), (&#39;现在&#39;, 0.012311491455160141), (&#39;带来&#39;, 0.012270374586959518), (&#39;故事&#39;, 0.012251639474339411), (&#39;剧情&#39;, 0.01219551207808719), (&#39;花絮&#39;, 0.012184429129003558), (&#39;已经&#39;, 0.012172770980925268), (&#39;玩家&#39;, 0.012024459773687721), (&#39;这个&#39;, 0.011901662937644573), (&#39;拍子&#39;, 0.011879228010564945), (&#39;还是&#39;, 0.011520793034270465), (&#39;一次&#39;, 0.011412670121385676), (&#39;小草&#39;, 0.011153777403358541), (&#39;什么&#39;, 0.011106902198087187), (&#39;国度&#39;, 0.010924310729615215), (&#39;看到&#39;, 0.010820306320840748), (&#39;中式&#39;, 0.010799625122275355), (&#39;用心&#39;, 0.010760160860511566), (&#39;演奏&#39;, 0.01064112761478203), (&#39;锁屏&#39;, 0.010635914148487545), (&#39;我要&#39;, 0.010635914148487545), (&#39;哔哩&#39;, 0.010635914148487545), (&#39;妮露&#39;, 0.010635914148487545), (&#39;吐槽&#39;, 0.010635914148487545), (&#39;死域&#39;, 0.010635914148487545), (&#39;太牛&#39;, 0.010635914148487545), (&#39;Mix&#39;, 0.010635914148487545)]\n提取完毕！\n</code></pre><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import jieba.analyse\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud,STOPWORDS,ImageColorGenerator</code></pre>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">content &#x3D; open(r&quot;C:\\Users\\83854\\Documents\\shujvji\\fenci2.txt&quot;, encoding &#x3D; &#39;UTF-8&#39;).read()\ntags &#x3D; jieba.analyse.extract_tags(content,topK&#x3D;200,withWeight&#x3D;False)\ntext &#x3D; &#39; &#39;.join(tags)\nwc &#x3D; WordCloud(font_path&#x3D;r&quot;C:\\Users\\83854\\Documents\\shujvji\\华文行楷.ttf&quot;,\n              background_color&#x3D;&#39;white&#39;,max_words&#x3D;100,\n              max_font_size&#x3D;120,min_font_size&#x3D;10,\n              random_state&#x3D;42,width&#x3D;1200,height&#x3D;900)\nwc.generate(text)\nplt.imshow(wc)\nplt.axis(&#39;off&#39;)\nplt.show()</code></pre>\n<p>​<br><img src=\"https://img-blog.csdnimg.cn/05ac085a27824bdd8a2cdcdbfd2176ea.png\" alt=\"在这里插入图片描述\"></p>\n<p>​    </p>\n<p>我们改成前20个词语，并对参数做一些修改</p>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">content &#x3D; open(r&quot;C:\\Users\\83854\\Documents\\shujvji\\fenci2.txt&quot;, encoding &#x3D; &#39;UTF-8&#39;).read()\ntags &#x3D; jieba.analyse.extract_tags(content,topK&#x3D;20,withWeight&#x3D;False)\ntext &#x3D; &#39; &#39;.join(tags)\nwc &#x3D; WordCloud(font_path&#x3D;r&quot;C:\\Users\\83854\\Documents\\shujvji\\华文行楷.ttf&quot;,\n              background_color&#x3D;&#39;white&#39;,max_words&#x3D;100,\n              max_font_size&#x3D;1000,min_font_size&#x3D;10,\n              random_state&#x3D;42,width&#x3D;1200,height&#x3D;900)\nwc.generate(text)\nplt.imshow(wc)\nplt.axis(&#39;off&#39;)\nplt.show()</code></pre>\n<p>​    </p>\n<pre><code>![在这里插入图片描述](https://img-blog.csdnimg.cn/c65a7fe1fe574ec495f3da8101012c58.png)\n</code></pre><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">import pandas as pd\nfrom snownlp import SnowNLP\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.rcParams[&#39;font.sans-serif&#39;]&#x3D;[&#39;SimHei&#39;]\nplt.rcParams[&#39;axes.unicode_minus&#39;]&#x3D;False\nsns.set_style(&#39;whitegrid&#39;,&#123;&#39;font.sans-serif&#39;:[&#39;simhei&#39;,&#39;Arial&#39;]&#125;)\n</code></pre>\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\">comments &#x3D; pd.read_csv(&quot;C:&#x2F;&#x2F;Users&#x2F;&#x2F;83854&#x2F;&#x2F;Documents&#x2F;&#x2F;shujvji&#x2F;&#x2F;genshinmusic.csv&quot;,&#39;gbk&#39;,index_col&#x3D;0)\ncomments.head()\n</code></pre>\n<pre><code>C:\\Users\\83854\\AppData\\Local\\Temp\\ipykernel_53740\\1497606228.py:1: FutureWarning: In a future version of pandas all arguments of read_csv except for the argument &#39;filepath_or_buffer&#39; will be keyword-only.\n  comments = pd.read_csv(&quot;C://Users//83854//Documents//shujvji//genshinmusic.csv&quot;,&#39;gbk&#39;,index_col=0)\nC:\\Users\\83854\\AppData\\Local\\Temp\\ipykernel_53740\\1497606228.py:1: ParserWarning: Falling back to the &#39;python&#39; engine because the &#39;c&#39; engine does not support regex separators (separators &gt; 1 char and different from &#39;\\s+&#39; are interpreted as regex); you can avoid this warning by specifying engine=&#39;python&#39;.\n  comments = pd.read_csv(&quot;C://Users//83854//Documents//shujvji//genshinmusic.csv&quot;,&#39;gbk&#39;,index_col=0)\n</code></pre><div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n\n</style>\n\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n    </tr>\n    <tr>\n      <th>评论</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>超爱看幕后纪录有不一样的感动</th>\n    </tr>\n    <tr>\n      <th>\"科普一下音乐知识，</th>\n    </tr>\n    <tr>\n      <th>“主题”：一段可以辨认的旋律，是作品的核心，可以由音乐动机组成，可以用来象征某物某人</th>\n    </tr>\n    <tr>\n      <th>“模进”：类似把同样一句话轮流交给不同的人去说</th>\n    </tr>\n    <tr>\n      <th>“非均分律动”：把句子重音节奏等等进行不规则划分。假如简单理解唐诗是“均分律动”，那么宋词就是“非均分律动”\"</th>\n    </tr>\n  </tbody>\n</table>\n\n</div>\n\n\n\n\n<pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 读如数据并显示数据的前五条\nimport pandas as pd\ncomments &#x3D; pd.read_csv(r&quot;C:\\Users\\83854\\Documents\\shujvji\\genshinmusic.csv&quot;)    #去掉一些特殊符号，只留下纯文本评论,去掉无\ncomments.head()\nprint(len(comments))</code></pre>\n<pre><code>390\n</code></pre><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"># 使用SnowNLP计算对每条标题的文字评估情绪得分\n# 新建“情绪”一列\n\ncomments[&#39;情绪&#39;]&#x3D;None\n#comments.iloc[i,1]&#x3D;None\n# 所有文本长度\nlenOrig&#x3D;len(comments)\n\n\ni&#x3D;0\n# 计算情绪得分SnowNLP(数据二维表.iloc[行，列]).sentiments\nwhile(i&lt;lenOrig):\n    s&#x3D;SnowNLP(comments.iloc[i,0]).sentiments\n    comments.iloc[i,1]&#x3D;s\n    i&#x3D;i+1\n \n# 输出每行的情绪得分\nprint(&#39;情绪得分：&#39;)\n# 前五行\nprint(comments.head())\nprint(comments)\n</code></pre>\n<pre><code>情绪得分：\n                                                  评论        情绪\n0                                     超爱看幕后纪录有不一样的感动  0.942552\n1  科普一下音乐知识，\\n“主题”：一段可以辨认的旋律，是作品的核心，可以由音乐动机组成，可以用...       1.0\n2  虽然一直很喜欢HOYO-MIX的音乐，但此前专心欣赏这些配乐仅限于在游戏外，而须弥的配乐，是...       1.0\n3                             感觉这次不止是侧重陈老师，介绍了更多团队人员  0.995487\n4         直播间别刷兑换码了你但凡加个原神群都会有人贴出来，每次前瞻都会给，不用老是刷屏直播间  0.003928\n                                                    评论        情绪\n0                                       超爱看幕后纪录有不一样的感动  0.942552\n1    科普一下音乐知识，\\n“主题”：一段可以辨认的旋律，是作品的核心，可以由音乐动机组成，可以用...       1.0\n2    虽然一直很喜欢HOYO-MIX的音乐，但此前专心欣赏这些配乐仅限于在游戏外，而须弥的配乐，是...       1.0\n3                               感觉这次不止是侧重陈老师，介绍了更多团队人员  0.995487\n4           直播间别刷兑换码了你但凡加个原神群都会有人贴出来，每次前瞻都会给，不用老是刷屏直播间  0.003928\n..                                                 ...       ...\n385                                            幕后故事超有趣  0.966248\n386              流金疾驰已经难到，这么专业的队伍都得分段完成了么？！真想有朝一日能看现场啊  0.482386\n387                                           快把前瞻端上来罢  0.829795\n388                                               原宝贴贴  0.462915\n389                                      牛牛牛，整多点这样的，爱看  0.846666\n\n[390 rows x 2 columns]\n</code></pre><pre class=\"line-numbers language-python\" data-language=\"python\"><code class=\"language-python\"></code></pre>\n","text":"import jieba import jieba.posseg as psg from collections import Counter text &#x3D; &#39;我现在在jupyter notebook上写文本分析的代码！&#39; for w in jieba....","link":"","photos":[],"count_time":{"symbolsCount":"11k","symbolsTime":"10 mins."},"categories":[],"tags":[{"name":"文本分析","slug":"文本分析","count":3,"path":"api/tags/文本分析.json"}],"toc":"","author":{"name":"Algernon","slug":"blog-author","avatar":"https://user-images.githubusercontent.com/54904760/224857900-b2e8457c-43d2-46b7-901c-6c770f24bbad.png","link":"/","description":"谁也没见过风，更别说我和你了","socials":{"github":"https://github.com/Algernon98","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/Algernon98","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://space.bilibili.com/281724502"}}}},"mapped":true,"prev_post":{"title":"【区块链技术与应用】（四）","uid":"c4d0eb90791df525d4565abe42524ee7","slug":"区块链4","date":"2022-11-03T15:10:49.000Z","updated":"2022-11-03T15:06:48.279Z","comments":true,"path":"api/articles/区块链4.json","keywords":null,"cover":[],"text":"视频8 https://pkg.go.dev/github.com/hyperledger/fabric-chaincode-go/shim#section-sourcefiles 简单资产链码我们的应用程序是一个基本的示例链码，用来在账本上创建资产（键-值对）。 选择一个位置存...","link":"","photos":[],"count_time":{"symbolsCount":"18k","symbolsTime":"17 mins."},"categories":[],"tags":[{"name":"区块链","slug":"区块链","count":10,"path":"api/tags/区块链.json"}],"author":{"name":"Algernon","slug":"blog-author","avatar":"https://user-images.githubusercontent.com/54904760/224857900-b2e8457c-43d2-46b7-901c-6c770f24bbad.png","link":"/","description":"谁也没见过风，更别说我和你了","socials":{"github":"https://github.com/Algernon98","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/Algernon98","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://space.bilibili.com/281724502"}}}}},"next_post":{"title":"【PYTHON程序设计】期中准备","uid":"f7d616ea92a89a59048707721827725d","slug":"python期中准备","date":"2022-11-03T15:05:49.000Z","updated":"2022-11-03T15:05:43.981Z","comments":true,"path":"api/articles/python期中准备.json","keywords":null,"cover":[],"text":"期中测试主要要求 熟练掌握文件的读写操作 掌握csv文件二维数据的读写操作 熟练掌握List的操作 文件的读写用文本编辑器生成一个包含“今古诸事，激荡中流，宏图待看新秀”的txt格式文本文件，命名为jingu.txt。分别用文本文件方式和二进制文件方式读入，并打印输出效果。需要把...","link":"","photos":[],"count_time":{"symbolsCount":"44k","symbolsTime":"40 mins."},"categories":[],"tags":[{"name":"信管","slug":"信管","count":5,"path":"api/tags/信管.json"}],"author":{"name":"Algernon","slug":"blog-author","avatar":"https://user-images.githubusercontent.com/54904760/224857900-b2e8457c-43d2-46b7-901c-6c770f24bbad.png","link":"/","description":"谁也没见过风，更别说我和你了","socials":{"github":"https://github.com/Algernon98","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/Algernon98","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://space.bilibili.com/281724502"}}}}}}