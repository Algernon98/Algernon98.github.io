{"title":"【电子羊的奇妙冒险】初试深度学习（2）","uid":"bfaff7f2eff3b6451015614e9ceb60e7","slug":"电子羊2","date":"2022-11-03T13:59:49.000Z","updated":"2022-11-03T15:58:01.929Z","comments":true,"path":"api/articles/电子羊2.json","keywords":null,"cover":[],"content":"<p>这一期内容有些杂，有基础知识，也有代码实战。</p>\n<h2 id=\"卷积神经网络\"><a href=\"#卷积神经网络\" class=\"headerlink\" title=\"卷积神经网络\"></a>卷积神经网络</h2><p><img src=\"https://img-blog.csdnimg.cn/e737f7b9c7614b9bb5f0828f8c0ec8bc.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Lu_55Sf56iL5bqP5ZGY5Lya5qKm6KeB55S15a2Q576K5ZCX,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p>\n<p>该部分图片及资料来源：</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><a href=\"http://www.huaxiaozhuan.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapters/5_CNN.html\">http://www.huaxiaozhuan.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapters/5_CNN.html</a></p></blockquote>\n<h3 id=\"卷积定义\"><a href=\"#卷积定义\" class=\"headerlink\" title=\"卷积定义\"></a>卷积定义</h3><p>许多神经网络库会实现一个与卷积有关的函数，称作互相关函数cross-correlation。它类似于卷积：</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><div contenteditable=\"false\" spellcheck=\"false\" class=\"mathjax-block md-end-block\" id=\"mathjax-n1906\" cid=\"n1906\" mdtype=\"math_block\"><span class=\"MathJax_Preview\"></span><span class=\"MathJax_SVG_Display\" style=\"text-align: center;\"><span class=\"MathJax_SVG\" id=\"MathJax-Element-406-Frame\" tabindex=\"-1\" style=\"font-size: 100%; display: inline-block;\"><svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"54.549ex\" height=\"5.262ex\" viewBox=\"0 -1007.2 23486.4 2265.7\" role=\"img\" focusable=\"false\" style=\"vertical-align: -2.923ex;\"><defs><path stroke-width=\"0\" id=\"E406-MJMAINB-53\" d=\"M64 493Q64 582 120 636T264 696H272Q280 697 285 697Q380 697 454 645L480 669Q484 672 488 676T495 683T500 688T504 691T508 693T511 695T514 696T517 697T522 697Q536 697 539 691T542 652V577Q542 557 542 532T543 500Q543 472 540 465T524 458H511H505Q489 458 485 461T479 478Q472 529 449 564T393 614T336 634T287 639Q228 639 203 610T177 544Q177 517 195 493T247 457Q253 454 343 436T475 391Q574 326 574 207V200Q574 163 559 120Q517 12 389 -9Q380 -10 346 -10Q308 -10 275 -5T221 7T184 22T160 35T151 40L126 17Q122 14 118 10T111 3T106 -2T102 -5T98 -7T95 -9T92 -10T89 -11T84 -11Q70 -11 67 -4T64 35V108Q64 128 64 153T63 185Q63 203 63 211T69 223T77 227T94 228H100Q118 228 122 225T126 205Q130 125 193 88T345 51Q408 51 434 82T460 157Q460 196 439 221T388 257Q384 259 305 276T221 295Q155 313 110 366T64 493Z\"></path><path stroke-width=\"0\" id=\"E406-MJMAIN-28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path><path stroke-width=\"0\" id=\"E406-MJMATHI-69\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path><path stroke-width=\"0\" id=\"E406-MJMAIN-2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path><path stroke-width=\"0\" id=\"E406-MJMATHI-6A\" d=\"M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z\"></path><path stroke-width=\"0\" id=\"E406-MJMAIN-29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path><path stroke-width=\"0\" id=\"E406-MJMAIN-3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path><path stroke-width=\"0\" id=\"E406-MJMAINB-49\" d=\"M397 0Q370 3 218 3Q65 3 38 0H25V62H139V624H25V686H38Q65 683 218 683Q370 683 397 686H410V624H296V62H410V0H397Z\"></path><path stroke-width=\"0\" id=\"E406-MJMAIN-2217\" d=\"M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z\"></path><path stroke-width=\"0\" id=\"E406-MJMAINB-4B\" d=\"M400 0Q376 3 226 3Q75 3 51 0H39V62H147V624H39V686H51Q75 683 226 683Q376 683 400 686H412V624H304V338L472 483L634 624H565V686H576Q597 683 728 683Q814 683 829 686H836V624H730L614 524Q507 432 497 422Q496 422 498 418T514 395T553 342T627 241L759 63L805 62H852V0H842Q830 3 701 3Q550 3 526 0H513V62H549Q584 62 584 63Q583 65 486 196T388 328L304 256V62H412V0H400Z\"></path><path stroke-width=\"0\" id=\"E406-MJSZ2-2211\" d=\"M60 948Q63 950 665 950H1267L1325 815Q1384 677 1388 669H1348L1341 683Q1320 724 1285 761Q1235 809 1174 838T1033 881T882 898T699 902H574H543H251L259 891Q722 258 724 252Q725 250 724 246Q721 243 460 -56L196 -356Q196 -357 407 -357Q459 -357 548 -357T676 -358Q812 -358 896 -353T1063 -332T1204 -283T1307 -196Q1328 -170 1348 -124H1388Q1388 -125 1381 -145T1356 -210T1325 -294L1267 -449L666 -450Q64 -450 61 -448Q55 -446 55 -439Q55 -437 57 -433L590 177Q590 178 557 222T452 366T322 544L56 909L55 924Q55 945 60 948Z\"></path><path stroke-width=\"0\" id=\"E406-MJMATHI-6D\" d=\"M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path><path stroke-width=\"0\" id=\"E406-MJMATHI-6E\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path><path stroke-width=\"0\" id=\"E406-MJMAIN-2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></defs><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"matrix(1 0 0 -1 0 0)\"><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMAINB-53\" x=\"0\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMAIN-28\" x=\"639\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMATHI-69\" x=\"1028\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMAIN-2C\" x=\"1373\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMATHI-6A\" x=\"1817\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMAIN-29\" x=\"2229\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMAIN-3D\" x=\"2896\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMAIN-28\" x=\"3952\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMAINB-49\" x=\"4341\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMAIN-2217\" x=\"4999\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMAINB-4B\" x=\"5721\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMAIN-29\" x=\"6622\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMAIN-28\" x=\"7011\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMATHI-69\" x=\"7400\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMAIN-2C\" x=\"7745\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMATHI-6A\" x=\"8190\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMAIN-29\" x=\"8602\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMAIN-3D\" x=\"9269\" y=\"0\"></use><g transform=\"translate(10324,0)\"><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJSZ2-2211\" x=\"0\" y=\"0\"></use><use transform=\"scale(0.707)\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMATHI-6D\" x=\"582\" y=\"-1485\"></use></g><g transform=\"translate(11935,0)\"><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJSZ2-2211\" x=\"0\" y=\"0\"></use><use transform=\"scale(0.707)\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMATHI-6E\" x=\"721\" y=\"-1485\"></use></g><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMAINB-49\" x=\"13546\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMAIN-28\" x=\"13982\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMATHI-69\" x=\"14371\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMAIN-2B\" x=\"14938\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMATHI-6D\" x=\"15938\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMAIN-2C\" x=\"16816\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMATHI-6A\" x=\"17261\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMAIN-2B\" x=\"17895\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMATHI-6E\" x=\"18895\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMAIN-29\" x=\"19495\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMAINB-4B\" x=\"19884\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMAIN-28\" x=\"20785\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMATHI-6D\" x=\"21174\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMAIN-2C\" x=\"22052\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMATHI-6E\" x=\"22497\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E406-MJMAIN-29\" x=\"23097\" y=\"0\"></use></g></svg></span></span><script type=\"math/tex; mode=display\" id=\"MathJax-Element-406\">\\mathbf S(i,j)=(\\mathbf I*\\mathbf K)(i,j)=\\sum_m\\sum_n\\mathbf I(i+m,j+n)\\mathbf K(m,n)</script></div>\n\n</blockquote>\n<p>有些机器学习库将它称作卷积。事实上在神经网络中，卷积指的就是这个函数（而不是数学意义上的卷积函数）。<br><img src=\"https://img-blog.csdnimg.cn/img_convert/99334390187957e8bf432a0f2f39821d.gif#pic_center\" alt=\"在这里插入图片描述\"></p>\n<p>神经网络的2维卷积的示例：<br><img src=\"https://img-blog.csdnimg.cn/img_convert/ef18b22d4a40e1257802d417ad8926e2.png#pic_center\" alt=\"在这里插入图片描述\"></p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>这里采用的是神经网络中卷积的定义：<span class=\"MathJax_Preview\"></span><span class=\"MathJax_SVG\" id=\"MathJax-Element-96-Frame\" tabindex=\"-1\" style=\"font-size: 100%; display: inline-block;\"><svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"59.837ex\" height=\"3.161ex\" viewBox=\"0 -1007.2 25762.9 1361\" role=\"img\" focusable=\"false\" style=\"vertical-align: -0.822ex;\"><defs><path stroke-width=\"0\" id=\"E96-MJMAINB-53\" d=\"M64 493Q64 582 120 636T264 696H272Q280 697 285 697Q380 697 454 645L480 669Q484 672 488 676T495 683T500 688T504 691T508 693T511 695T514 696T517 697T522 697Q536 697 539 691T542 652V577Q542 557 542 532T543 500Q543 472 540 465T524 458H511H505Q489 458 485 461T479 478Q472 529 449 564T393 614T336 634T287 639Q228 639 203 610T177 544Q177 517 195 493T247 457Q253 454 343 436T475 391Q574 326 574 207V200Q574 163 559 120Q517 12 389 -9Q380 -10 346 -10Q308 -10 275 -5T221 7T184 22T160 35T151 40L126 17Q122 14 118 10T111 3T106 -2T102 -5T98 -7T95 -9T92 -10T89 -11T84 -11Q70 -11 67 -4T64 35V108Q64 128 64 153T63 185Q63 203 63 211T69 223T77 227T94 228H100Q118 228 122 225T126 205Q130 125 193 88T345 51Q408 51 434 82T460 157Q460 196 439 221T388 257Q384 259 305 276T221 295Q155 313 110 366T64 493Z\"></path><path stroke-width=\"0\" id=\"E96-MJMAIN-28\" d=\"M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z\"></path><path stroke-width=\"0\" id=\"E96-MJMATHI-69\" d=\"M184 600Q184 624 203 642T247 661Q265 661 277 649T290 619Q290 596 270 577T226 557Q211 557 198 567T184 600ZM21 287Q21 295 30 318T54 369T98 420T158 442Q197 442 223 419T250 357Q250 340 236 301T196 196T154 83Q149 61 149 51Q149 26 166 26Q175 26 185 29T208 43T235 78T260 137Q263 149 265 151T282 153Q302 153 302 143Q302 135 293 112T268 61T223 11T161 -11Q129 -11 102 10T74 74Q74 91 79 106T122 220Q160 321 166 341T173 380Q173 404 156 404H154Q124 404 99 371T61 287Q60 286 59 284T58 281T56 279T53 278T49 278T41 278H27Q21 284 21 287Z\"></path><path stroke-width=\"0\" id=\"E96-MJMAIN-2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path><path stroke-width=\"0\" id=\"E96-MJMATHI-6A\" d=\"M297 596Q297 627 318 644T361 661Q378 661 389 651T403 623Q403 595 384 576T340 557Q322 557 310 567T297 596ZM288 376Q288 405 262 405Q240 405 220 393T185 362T161 325T144 293L137 279Q135 278 121 278H107Q101 284 101 286T105 299Q126 348 164 391T252 441Q253 441 260 441T272 442Q296 441 316 432Q341 418 354 401T367 348V332L318 133Q267 -67 264 -75Q246 -125 194 -164T75 -204Q25 -204 7 -183T-12 -137Q-12 -110 7 -91T53 -71Q70 -71 82 -81T95 -112Q95 -148 63 -167Q69 -168 77 -168Q111 -168 139 -140T182 -74L193 -32Q204 11 219 72T251 197T278 308T289 365Q289 372 288 376Z\"></path><path stroke-width=\"0\" id=\"E96-MJMAIN-29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path><path stroke-width=\"0\" id=\"E96-MJMAIN-3D\" d=\"M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z\"></path><path stroke-width=\"0\" id=\"E96-MJMAINB-49\" d=\"M397 0Q370 3 218 3Q65 3 38 0H25V62H139V624H25V686H38Q65 683 218 683Q370 683 397 686H410V624H296V62H410V0H397Z\"></path><path stroke-width=\"0\" id=\"E96-MJMAIN-2217\" d=\"M229 286Q216 420 216 436Q216 454 240 464Q241 464 245 464T251 465Q263 464 273 456T283 436Q283 419 277 356T270 286L328 328Q384 369 389 372T399 375Q412 375 423 365T435 338Q435 325 425 315Q420 312 357 282T289 250L355 219L425 184Q434 175 434 161Q434 146 425 136T401 125Q393 125 383 131T328 171L270 213Q283 79 283 63Q283 53 276 44T250 35Q231 35 224 44T216 63Q216 80 222 143T229 213L171 171Q115 130 110 127Q106 124 100 124Q87 124 76 134T64 161Q64 166 64 169T67 175T72 181T81 188T94 195T113 204T138 215T170 230T210 250L74 315Q65 324 65 338Q65 353 74 363T98 374Q106 374 116 368T171 328L229 286Z\"></path><path stroke-width=\"0\" id=\"E96-MJMAINB-4B\" d=\"M400 0Q376 3 226 3Q75 3 51 0H39V62H147V624H39V686H51Q75 683 226 683Q376 683 400 686H412V624H304V338L472 483L634 624H565V686H576Q597 683 728 683Q814 683 829 686H836V624H730L614 524Q507 432 497 422Q496 422 498 418T514 395T553 342T627 241L759 63L805 62H852V0H842Q830 3 701 3Q550 3 526 0H513V62H549Q584 62 584 63Q583 65 486 196T388 328L304 256V62H412V0H400Z\"></path><path stroke-width=\"0\" id=\"E96-MJSZ1-2211\" d=\"M61 748Q64 750 489 750H913L954 640Q965 609 976 579T993 533T999 516H979L959 517Q936 579 886 621T777 682Q724 700 655 705T436 710H319Q183 710 183 709Q186 706 348 484T511 259Q517 250 513 244L490 216Q466 188 420 134T330 27L149 -187Q149 -188 362 -188Q388 -188 436 -188T506 -189Q679 -189 778 -162T936 -43Q946 -27 959 6H999L913 -249L489 -250Q65 -250 62 -248Q56 -246 56 -239Q56 -234 118 -161Q186 -81 245 -11L428 206Q428 207 242 462L57 717L56 728Q56 744 61 748Z\"></path><path stroke-width=\"0\" id=\"E96-MJMAIN-31\" d=\"M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z\"></path><path stroke-width=\"0\" id=\"E96-MJMATHI-6D\" d=\"M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path><path stroke-width=\"0\" id=\"E96-MJMAIN-30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path><path stroke-width=\"0\" id=\"E96-MJMATHI-6E\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path><path stroke-width=\"0\" id=\"E96-MJMAIN-2B\" d=\"M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z\"></path></defs><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"matrix(1 0 0 -1 0 0)\"><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAINB-53\" x=\"0\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAIN-28\" x=\"639\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMATHI-69\" x=\"1028\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAIN-2C\" x=\"1373\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMATHI-6A\" x=\"1817\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAIN-29\" x=\"2229\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAIN-3D\" x=\"2896\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAIN-28\" x=\"3952\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAINB-49\" x=\"4341\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAIN-2217\" x=\"4999\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAINB-4B\" x=\"5721\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAIN-29\" x=\"6622\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAIN-28\" x=\"7011\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMATHI-69\" x=\"7400\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAIN-2C\" x=\"7745\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMATHI-6A\" x=\"8190\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAIN-29\" x=\"8602\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAIN-3D\" x=\"9269\" y=\"0\"></use><g transform=\"translate(10324,0)\"><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJSZ1-2211\" x=\"0\" y=\"0\"></use><use transform=\"scale(0.707)\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAIN-31\" x=\"1493\" y=\"674\"></use><g transform=\"translate(1056,-286)\"><use transform=\"scale(0.707)\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMATHI-6D\" x=\"0\" y=\"0\"></use><use transform=\"scale(0.707)\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAIN-3D\" x=\"878\" y=\"0\"></use><use transform=\"scale(0.707)\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAIN-30\" x=\"1655\" y=\"0\"></use></g></g><g transform=\"translate(13172,0)\"><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJSZ1-2211\" x=\"0\" y=\"0\"></use><use transform=\"scale(0.707)\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAIN-31\" x=\"1493\" y=\"674\"></use><g transform=\"translate(1056,-286)\"><use transform=\"scale(0.707)\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMATHI-6E\" x=\"0\" y=\"0\"></use><use transform=\"scale(0.707)\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAIN-3D\" x=\"600\" y=\"0\"></use><use transform=\"scale(0.707)\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAIN-30\" x=\"1378\" y=\"0\"></use></g></g><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAINB-49\" x=\"15822\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAIN-28\" x=\"16258\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMATHI-69\" x=\"16647\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAIN-2B\" x=\"17214\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMATHI-6D\" x=\"18215\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAIN-2C\" x=\"19093\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMATHI-6A\" x=\"19537\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAIN-2B\" x=\"20172\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMATHI-6E\" x=\"21172\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAIN-29\" x=\"21772\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAINB-4B\" x=\"22161\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAIN-28\" x=\"23062\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMATHI-6D\" x=\"23451\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAIN-2C\" x=\"24329\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMATHI-6E\" x=\"24773\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E96-MJMAIN-29\" x=\"25373\" y=\"0\"></use></g></svg></span><script type=\"math/tex\" id=\"MathJax-Element-96\">\\mathbf S(i,j)=(\\mathbf I*\\mathbf K)(i,j)=\\sum_{m=0}^{1}\\sum_{n=0}^{1}\\mathbf I(i+m,j+n)\\mathbf K(m,n)</script>  。其中，<span class=\"MathJax_Preview\"></span><span class=\"MathJax_SVG\" id=\"MathJax-Element-117-Frame\" tabindex=\"-1\" style=\"font-size: 100%; display: inline-block;\"><svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"2.039ex\" height=\"1.41ex\" viewBox=\"0 -504.6 878 607.1\" role=\"img\" focusable=\"false\" style=\"vertical-align: -0.238ex;\"><defs><path stroke-width=\"0\" id=\"E117-MJMATHI-6D\" d=\"M21 287Q22 293 24 303T36 341T56 388T88 425T132 442T175 435T205 417T221 395T229 376L231 369Q231 367 232 367L243 378Q303 442 384 442Q401 442 415 440T441 433T460 423T475 411T485 398T493 385T497 373T500 364T502 357L510 367Q573 442 659 442Q713 442 746 415T780 336Q780 285 742 178T704 50Q705 36 709 31T724 26Q752 26 776 56T815 138Q818 149 821 151T837 153Q857 153 857 145Q857 144 853 130Q845 101 831 73T785 17T716 -10Q669 -10 648 17T627 73Q627 92 663 193T700 345Q700 404 656 404H651Q565 404 506 303L499 291L466 157Q433 26 428 16Q415 -11 385 -11Q372 -11 364 -4T353 8T350 18Q350 29 384 161L420 307Q423 322 423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 181Q151 335 151 342Q154 357 154 369Q154 405 129 405Q107 405 92 377T69 316T57 280Q55 278 41 278H27Q21 284 21 287Z\"></path></defs><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"matrix(1 0 0 -1 0 0)\"><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E117-MJMATHI-6D\" x=\"0\" y=\"0\"></use></g></svg></span><script type=\"math/tex\" id=\"MathJax-Element-117\">m</script> 和 <span class=\"MathJax_Preview\"></span><span class=\"MathJax_SVG\" id=\"MathJax-Element-266-Frame\" tabindex=\"-1\" style=\"font-size: 100%; display: inline-block;\"><svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"1.394ex\" height=\"1.41ex\" viewBox=\"0 -504.6 600 607.1\" role=\"img\" focusable=\"false\" style=\"vertical-align: -0.238ex;\"><defs><path stroke-width=\"0\" id=\"E266-MJMATHI-6E\" d=\"M21 287Q22 293 24 303T36 341T56 388T89 425T135 442Q171 442 195 424T225 390T231 369Q231 367 232 367L243 378Q304 442 382 442Q436 442 469 415T503 336T465 179T427 52Q427 26 444 26Q450 26 453 27Q482 32 505 65T540 145Q542 153 560 153Q580 153 580 145Q580 144 576 130Q568 101 554 73T508 17T439 -10Q392 -10 371 17T350 73Q350 92 386 193T423 345Q423 404 379 404H374Q288 404 229 303L222 291L189 157Q156 26 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 112 180T152 343Q153 348 153 366Q153 405 129 405Q91 405 66 305Q60 285 60 284Q58 278 41 278H27Q21 284 21 287Z\"></path></defs><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"matrix(1 0 0 -1 0 0)\"><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E266-MJMATHI-6E\" x=\"0\" y=\"0\"></use></g></svg></span><script type=\"math/tex\" id=\"MathJax-Element-266\">n</script> 由核函数决定。因为 <span class=\"MathJax_Preview\"></span><span class=\"MathJax_SVG\" id=\"MathJax-Element-99-Frame\" tabindex=\"-1\" style=\"font-size: 100%; display: inline-block;\"><svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"9.761ex\" height=\"2.461ex\" viewBox=\"0 -956.9 4202.8 1059.4\" role=\"img\" focusable=\"false\" style=\"vertical-align: -0.238ex;\"><defs><path stroke-width=\"0\" id=\"E99-MJMAINB-4B\" d=\"M400 0Q376 3 226 3Q75 3 51 0H39V62H147V624H39V686H51Q75 683 226 683Q376 683 400 686H412V624H304V338L472 483L634 624H565V686H576Q597 683 728 683Q814 683 829 686H836V624H730L614 524Q507 432 497 422Q496 422 498 418T514 395T553 342T627 241L759 63L805 62H852V0H842Q830 3 701 3Q550 3 526 0H513V62H549Q584 62 584 63Q583 65 486 196T388 328L304 256V62H412V0H400Z\"></path><path stroke-width=\"0\" id=\"E99-MJMAIN-2208\" d=\"M84 250Q84 372 166 450T360 539Q361 539 377 539T419 540T469 540H568Q583 532 583 520Q583 511 570 501L466 500Q355 499 329 494Q280 482 242 458T183 409T147 354T129 306T124 272V270H568Q583 262 583 250T568 230H124V228Q124 207 134 177T167 112T231 48T328 7Q355 1 466 0H570Q583 -10 583 -20Q583 -32 568 -40H471Q464 -40 446 -40T417 -41Q262 -41 172 45Q84 127 84 250Z\"></path><path stroke-width=\"0\" id=\"E99-MJAMS-52\" d=\"M17 665Q17 672 28 683H221Q415 681 439 677Q461 673 481 667T516 654T544 639T566 623T584 607T597 592T607 578T614 565T618 554L621 548Q626 530 626 497Q626 447 613 419Q578 348 473 326L455 321Q462 310 473 292T517 226T578 141T637 72T686 35Q705 30 705 16Q705 7 693 -1H510Q503 6 404 159L306 310H268V183Q270 67 271 59Q274 42 291 38Q295 37 319 35Q344 35 353 28Q362 17 353 3L346 -1H28Q16 5 16 16Q16 35 55 35Q96 38 101 52Q106 60 106 341T101 632Q95 645 55 648Q17 648 17 665ZM241 35Q238 42 237 45T235 78T233 163T233 337V621L237 635L244 648H133Q136 641 137 638T139 603T141 517T141 341Q141 131 140 89T134 37Q133 36 133 35H241ZM457 496Q457 540 449 570T425 615T400 634T377 643Q374 643 339 648Q300 648 281 635Q271 628 270 610T268 481V346H284Q327 346 375 352Q421 364 439 392T457 496ZM492 537T492 496T488 427T478 389T469 371T464 361Q464 360 465 360Q469 360 497 370Q593 400 593 495Q593 592 477 630L457 637L461 626Q474 611 488 561Q492 537 492 496ZM464 243Q411 317 410 317Q404 317 401 315Q384 315 370 312H346L526 35H619L606 50Q553 109 464 243Z\"></path><path stroke-width=\"0\" id=\"E99-MJMAIN-32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path><path stroke-width=\"0\" id=\"E99-MJMAIN-D7\" d=\"M630 29Q630 9 609 9Q604 9 587 25T493 118L389 222L284 117Q178 13 175 11Q171 9 168 9Q160 9 154 15T147 29Q147 36 161 51T255 146L359 250L255 354Q174 435 161 449T147 471Q147 480 153 485T168 490Q173 490 175 489Q178 487 284 383L389 278L493 382Q570 459 587 475T609 491Q630 491 630 471Q630 464 620 453T522 355L418 250L522 145Q606 61 618 48T630 29Z\"></path></defs><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"matrix(1 0 0 -1 0 0)\"><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E99-MJMAINB-4B\" x=\"0\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E99-MJMAIN-2208\" x=\"1178\" y=\"0\"></use><g transform=\"translate(2123,0)\"><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E99-MJAMS-52\" x=\"0\" y=\"0\"></use><g transform=\"translate(722,409)\"><use transform=\"scale(0.707)\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E99-MJMAIN-32\" x=\"0\" y=\"0\"></use><use transform=\"scale(0.707)\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E99-MJMAIN-D7\" x=\"500\" y=\"0\"></use><use transform=\"scale(0.707)\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E99-MJMAIN-32\" x=\"1278\" y=\"0\"></use></g></g></g></svg></span><script type=\"math/tex\" id=\"MathJax-Element-99\">\\mathbf K\\in \\mathbb R^{2\\times 2}</script>，所以他们的取值范围是 <span class=\"MathJax_Preview\"></span><span class=\"MathJax_SVG\" id=\"MathJax-Element-100-Frame\" tabindex=\"-1\" style=\"font-size: 100%; display: inline-block;\"><svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"13.164ex\" height=\"2.577ex\" viewBox=\"0 -806.1 5668 1109.7\" role=\"img\" focusable=\"false\" style=\"vertical-align: -0.705ex;\"><defs><path stroke-width=\"0\" id=\"E100-MJMAIN-5B\" d=\"M118 -250V750H255V710H158V-210H255V-250H118Z\"></path><path stroke-width=\"0\" id=\"E100-MJMAIN-30\" d=\"M96 585Q152 666 249 666Q297 666 345 640T423 548Q460 465 460 320Q460 165 417 83Q397 41 362 16T301 -15T250 -22Q224 -22 198 -16T137 16T82 83Q39 165 39 320Q39 494 96 585ZM321 597Q291 629 250 629Q208 629 178 597Q153 571 145 525T137 333Q137 175 145 125T181 46Q209 16 250 16Q290 16 318 46Q347 76 354 130T362 333Q362 478 354 524T321 597Z\"></path><path stroke-width=\"0\" id=\"E100-MJMAIN-2C\" d=\"M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z\"></path><path stroke-width=\"0\" id=\"E100-MJMAIN-32\" d=\"M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z\"></path><path stroke-width=\"0\" id=\"E100-MJMAIN-29\" d=\"M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z\"></path></defs><g stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" transform=\"matrix(1 0 0 -1 0 0)\"><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E100-MJMAIN-5B\" x=\"0\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E100-MJMAIN-30\" x=\"278\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E100-MJMAIN-2C\" x=\"778\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E100-MJMAIN-32\" x=\"1222\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E100-MJMAIN-29\" x=\"1722\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E100-MJMAIN-2C\" x=\"2111\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E100-MJMAIN-5B\" x=\"3556\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E100-MJMAIN-30\" x=\"3834\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E100-MJMAIN-2C\" x=\"4334\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E100-MJMAIN-32\" x=\"4779\" y=\"0\"></use><use xmlns:xlink=\"http://www.w3.org/1999/xlink\" xlink:href=\"#E100-MJMAIN-29\" x=\"5279\" y=\"0\"></use></g></svg></span><script type=\"math/tex\" id=\"MathJax-Element-100\">[0,2),\\quad [0,2)</script> 。</p>\n</blockquote>\n<p>单个卷积核只能提取一种类型的特征。</p>\n<p>如果希望卷积层能够提取多个特征，则可以并行使用多个卷积核，每个卷积核提取一种特征。我们称输出的feature map 具有多个通道channel 。</p>\n<p>feature map 特征图是卷积层的输出的别名，它由多个通道组成，每个通道代表通过卷积提取的某种特征。</p>\n<p>事实上，当输入为图片或者feature map 时，池化层、非线性激活层、Batch Normalization 等层的输出也可以称作feature map 。卷积神经网络中，非全连接层、输出层以外的几乎所有层的输出都可以称作feature map 。<br><img src=\"https://img-blog.csdnimg.cn/img_convert/658a8ff52b0e2a12feb88b01cb3f07f0.png#pic_center\" alt=\"在这里插入图片描述\"></p>\n<p>剩余内容待补充。<br><img src=\"https://img-blog.csdnimg.cn/4027dcf2d16b4348b28670b461e62517.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Lu_55Sf56iL5bqP5ZGY5Lya5qKm6KeB55S15a2Q576K5ZCX,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/40f60bdb034e407091806d244c327956.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Lu_55Sf56iL5bqP5ZGY5Lya5qKm6KeB55S15a2Q576K5ZCX,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/2059241064f8411cb7e88056e8362eb5.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Lu_55Sf56iL5bqP5ZGY5Lya5qKm6KeB55S15a2Q576K5ZCX,size_20,color_FFFFFF,t_70,g_se,x_16\" alt=\"在这里插入图片描述\"></p>\n<h2 id=\"深度学习实战：mnist手写数字识别\"><a href=\"#深度学习实战：mnist手写数字识别\" class=\"headerlink\" title=\"深度学习实战：mnist手写数字识别\"></a>深度学习实战：mnist手写数字识别</h2><p>github地址：</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><a href=\"https://github.com/pytorch/examples/tree/main/mnist\">https://github.com/pytorch/examples/tree/main/mnist</a></p></blockquote>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">from __future__ import print_function\nimport argparse\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom torch.optim.lr_scheduler import StepLR\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 &#x3D; nn.Conv2d(1, 32, 3, 1)\n        self.conv2 &#x3D; nn.Conv2d(32, 64, 3, 1)\n        self.dropout1 &#x3D; nn.Dropout(0.25)\n        self.dropout2 &#x3D; nn.Dropout(0.5)\n        self.fc1 &#x3D; nn.Linear(9216, 128)\n        self.fc2 &#x3D; nn.Linear(128, 10)\n\n    def forward(self, x):\n        x &#x3D; self.conv1(x)\n        x &#x3D; F.relu(x)\n        x &#x3D; self.conv2(x)\n        x &#x3D; F.relu(x)\n        x &#x3D; F.max_pool2d(x, 2)\n        x &#x3D; self.dropout1(x)\n        x &#x3D; torch.flatten(x, 1)\n        x &#x3D; self.fc1(x)\n        x &#x3D; F.relu(x)\n        x &#x3D; self.dropout2(x)\n        x &#x3D; self.fc2(x)\n        output &#x3D; F.log_softmax(x, dim&#x3D;1)\n        return output\n\n\ndef train(args, model, device, train_loader, optimizer, epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target &#x3D; data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output &#x3D; model(data)\n        loss &#x3D; F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval &#x3D;&#x3D; 0:\n            print(&#39;Train Epoch: &#123;&#125; [&#123;&#125;&#x2F;&#123;&#125; (&#123;:.0f&#125;%)]\\tLoss: &#123;:.6f&#125;&#39;.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx &#x2F; len(train_loader), loss.item()))\n            if args.dry_run:\n                break\n\n\ndef test(model, device, test_loader):\n    model.eval()\n    test_loss &#x3D; 0\n    correct &#x3D; 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target &#x3D; data.to(device), target.to(device)\n            output &#x3D; model(data)\n            test_loss +&#x3D; F.nll_loss(output, target, reduction&#x3D;&#39;sum&#39;).item()  # sum up batch loss\n            pred &#x3D; output.argmax(dim&#x3D;1, keepdim&#x3D;True)  # get the index of the max log-probability\n            correct +&#x3D; pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss &#x2F;&#x3D; len(test_loader.dataset)\n\n    print(&#39;\\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;&#x2F;&#123;&#125; (&#123;:.0f&#125;%)\\n&#39;.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct &#x2F; len(test_loader.dataset)))\n\n\ndef main():\n    # Training settings\n    parser &#x3D; argparse.ArgumentParser(description&#x3D;&#39;PyTorch MNIST Example&#39;)\n    parser.add_argument(&#39;--batch-size&#39;, type&#x3D;int, default&#x3D;64, metavar&#x3D;&#39;N&#39;,\n                        help&#x3D;&#39;input batch size for training (default: 64)&#39;)\n    parser.add_argument(&#39;--test-batch-size&#39;, type&#x3D;int, default&#x3D;1000, metavar&#x3D;&#39;N&#39;,\n                        help&#x3D;&#39;input batch size for testing (default: 1000)&#39;)\n    parser.add_argument(&#39;--epochs&#39;, type&#x3D;int, default&#x3D;14, metavar&#x3D;&#39;N&#39;,\n                        help&#x3D;&#39;number of epochs to train (default: 14)&#39;)\n    parser.add_argument(&#39;--lr&#39;, type&#x3D;float, default&#x3D;1.0, metavar&#x3D;&#39;LR&#39;,\n                        help&#x3D;&#39;learning rate (default: 1.0)&#39;)\n    parser.add_argument(&#39;--gamma&#39;, type&#x3D;float, default&#x3D;0.7, metavar&#x3D;&#39;M&#39;,\n                        help&#x3D;&#39;Learning rate step gamma (default: 0.7)&#39;)\n    parser.add_argument(&#39;--no-cuda&#39;, action&#x3D;&#39;store_true&#39;, default&#x3D;False,\n                        help&#x3D;&#39;disables CUDA training&#39;)\n    parser.add_argument(&#39;--dry-run&#39;, action&#x3D;&#39;store_true&#39;, default&#x3D;False,\n                        help&#x3D;&#39;quickly check a single pass&#39;)\n    parser.add_argument(&#39;--seed&#39;, type&#x3D;int, default&#x3D;1, metavar&#x3D;&#39;S&#39;,\n                        help&#x3D;&#39;random seed (default: 1)&#39;)\n    parser.add_argument(&#39;--log-interval&#39;, type&#x3D;int, default&#x3D;10, metavar&#x3D;&#39;N&#39;,\n                        help&#x3D;&#39;how many batches to wait before logging training status&#39;)\n    parser.add_argument(&#39;--save-model&#39;, action&#x3D;&#39;store_true&#39;, default&#x3D;False,\n                        help&#x3D;&#39;For Saving the current Model&#39;)\n    args &#x3D; parser.parse_args()\n    use_cuda &#x3D; not args.no_cuda and torch.cuda.is_available()\n\n    torch.manual_seed(args.seed)\n\n    device &#x3D; torch.device(&quot;cuda&quot; if use_cuda else &quot;cpu&quot;)\n\n    train_kwargs &#x3D; &#123;&#39;batch_size&#39;: args.batch_size&#125;\n    test_kwargs &#x3D; &#123;&#39;batch_size&#39;: args.test_batch_size&#125;\n    if use_cuda:\n        cuda_kwargs &#x3D; &#123;&#39;num_workers&#39;: 1,\n                       &#39;pin_memory&#39;: True,\n                       &#39;shuffle&#39;: True&#125;\n        train_kwargs.update(cuda_kwargs)\n        test_kwargs.update(cuda_kwargs)\n\n    transform&#x3D;transforms.Compose([\n        transforms.ToTensor(),\n        transforms.Normalize((0.1307,), (0.3081,))\n        ])\n    dataset1 &#x3D; datasets.MNIST(&#39;..&#x2F;data&#39;, train&#x3D;True, download&#x3D;True,\n                       transform&#x3D;transform)\n    dataset2 &#x3D; datasets.MNIST(&#39;..&#x2F;data&#39;, train&#x3D;False,\n                       transform&#x3D;transform)\n    train_loader &#x3D; torch.utils.data.DataLoader(dataset1,**train_kwargs)\n    test_loader &#x3D; torch.utils.data.DataLoader(dataset2, **test_kwargs)\n\n    model &#x3D; Net().to(device)\n    optimizer &#x3D; optim.Adadelta(model.parameters(), lr&#x3D;args.lr)\n\n    scheduler &#x3D; StepLR(optimizer, step_size&#x3D;1, gamma&#x3D;args.gamma)\n    for epoch in range(1, args.epochs + 1):\n        train(args, model, device, train_loader, optimizer, epoch)\n        test(model, device, test_loader)\n        scheduler.step()\n\n    if args.save_model:\n        torch.save(model.state_dict(), &quot;mnist_cnn.pt&quot;)\n\n\nif __name__ &#x3D;&#x3D; &#39;__main__&#39;:\n    main()</code></pre>\n<p><strong>Basic MNIST Example</strong><br><pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">pip install -r requirements.txt\npython main.py\n# CUDA_VISIBLE_DEVICES&#x3D;2 python main.py  # to specify GPU id to ex. 2</code></pre></p>\n<p>输出：<br><img src=\"https://img-blog.csdnimg.cn/a6bdbcce5573442dbbb6cc5452bc74f2.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAQWxnZXJub245OA==,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/dd328cd6942247189a12db0c59fe9da0.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAQWxnZXJub245OA==,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center\" alt=\"在这里插入图片描述\"></p>\n<h2 id=\"深度学习基础\"><a href=\"#深度学习基础\" class=\"headerlink\" title=\"深度学习基础\"></a>深度学习基础</h2><h3 id=\"CUDA使用GPU加速\"><a href=\"#CUDA使用GPU加速\" class=\"headerlink\" title=\"CUDA使用GPU加速\"></a>CUDA使用GPU加速</h3><ul>\n<li>CPU：擅长流程控制和逻辑处理，不规则数据结构，不可预测存储结构，单线程程序，分支密集型算法</li>\n<li><p>GPU：擅长数据并行计算，规则数据结构，可预测存储模式。</p>\n<p>关于CUDA代码入门可参见：</p>\n</li>\n</ul>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><a href=\"https://blog.csdn.net/sru_alo/article/details/93539633\">https://blog.csdn.net/sru_alo/article/details/93539633</a></p></blockquote>\n<p>编写一个程序，查看我们GPU的一些硬件配置情况：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">#include &quot;device_launch_parameters.h&quot;\n#include &lt;iostream&gt;\n \nint main()\n&#123;\n    int deviceCount;\n    cudaGetDeviceCount(&amp;deviceCount);\n    for(int i&#x3D;0;i&lt;deviceCount;i++)\n    &#123;\n        cudaDeviceProp devProp;\n        cudaGetDeviceProperties(&amp;devProp, i);\n        std::cout &lt;&lt; &quot;使用GPU device &quot; &lt;&lt; i &lt;&lt; &quot;: &quot; &lt;&lt; devProp.name &lt;&lt; std::endl;\n        std::cout &lt;&lt; &quot;设备全局内存总量： &quot; &lt;&lt; devProp.totalGlobalMem &#x2F; 1024 &#x2F; 1024 &lt;&lt; &quot;MB&quot; &lt;&lt; std::endl;\n        std::cout &lt;&lt; &quot;SM的数量：&quot; &lt;&lt; devProp.multiProcessorCount &lt;&lt; std::endl;\n        std::cout &lt;&lt; &quot;每个线程块的共享内存大小：&quot; &lt;&lt; devProp.sharedMemPerBlock &#x2F; 1024.0 &lt;&lt; &quot; KB&quot; &lt;&lt; std::endl;\n        std::cout &lt;&lt; &quot;每个线程块的最大线程数：&quot; &lt;&lt; devProp.maxThreadsPerBlock &lt;&lt; std::endl;\n        std::cout &lt;&lt; &quot;设备上一个线程块（Block）种可用的32位寄存器数量： &quot; &lt;&lt; devProp.regsPerBlock &lt;&lt; std::endl;\n        std::cout &lt;&lt; &quot;每个EM的最大线程数：&quot; &lt;&lt; devProp.maxThreadsPerMultiProcessor &lt;&lt; std::endl;\n        std::cout &lt;&lt; &quot;每个EM的最大线程束数：&quot; &lt;&lt; devProp.maxThreadsPerMultiProcessor &#x2F; 32 &lt;&lt; std::endl;\n        std::cout &lt;&lt; &quot;设备上多处理器的数量： &quot; &lt;&lt; devProp.multiProcessorCount &lt;&lt; std::endl;\n        std::cout &lt;&lt; &quot;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot; &lt;&lt; std::endl;     \n        \n    &#125;\n    return 0;\n&#125;\n </code></pre>\n<p>利用nvcc来编译程序。<br><pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">nvcc test1.cu -o test1</code></pre></p>\n<h2 id=\"基于神经网络求一元高次方程近似解\"><a href=\"#基于神经网络求一元高次方程近似解\" class=\"headerlink\" title=\"基于神经网络求一元高次方程近似解\"></a>基于神经网络求一元高次方程近似解</h2><p>神经网络模型来源于：</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><a href=\"https://taylanbil.github.io/polysolver\">https://taylanbil.github.io/polysolver</a><br><a href=\"https://blog.csdn.net/Algernon98/article/details/123980735?spm=1001.2014.3001.5501\">基于神经网络解一元高次方程</a></p></blockquote>\n<p><strong>将数学问题公式化为机器学习问题，并编写一个学习解决多项式的神经网络</strong></p>\n<p>关于模型训练次数调整与拟合结果的初探：</p>\n<h3 id=\"低次——5次多项式\"><a href=\"#低次——5次多项式\" class=\"headerlink\" title=\"低次——5次多项式\"></a>低次——5次多项式</h3><p>训练 3次：<br><img src=\"https://img-blog.csdnimg.cn/e6e18d895f784133a7a97db9af567c83.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Lu_55Sf56iL5bqP5ZGY5Lya5qKm6KeB55S15a2Q576K5ZCX,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center\" alt=\"在这里插入图片描述\"></p>\n<p>训练5次：<br><img src=\"https://img-blog.csdnimg.cn/0b188a019cbe4871bb693b8ed68c2312.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Lu_55Sf56iL5bqP5ZGY5Lya5qKm6KeB55S15a2Q576K5ZCX,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center\" alt=\"在这里插入图片描述\"><br>训练10次：<br><img src=\"https://img-blog.csdnimg.cn/a8337698f12840c39b73cd8886f5d5fe.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Lu_55Sf56iL5bqP5ZGY5Lya5qKm6KeB55S15a2Q576K5ZCX,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center\" alt=\"在这里插入图片描述\"></p>\n<h3 id=\"高次——（4-16次）\"><a href=\"#高次——（4-16次）\" class=\"headerlink\" title=\"高次——（4~16次）\"></a>高次——（4~16次）</h3><p>训练3次：<br><img src=\"https://img-blog.csdnimg.cn/5b36364ce7714bbc9644242b3405cc97.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Lu_55Sf56iL5bqP5ZGY5Lya5qKm6KeB55S15a2Q576K5ZCX,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center\" alt=\"在这里插入图片描述\"></p>\n<p>训练5次：<br><img src=\"https://img-blog.csdnimg.cn/95e601b3e3fd43c09c88c74eed07971b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Lu_55Sf56iL5bqP5ZGY5Lya5qKm6KeB55S15a2Q576K5ZCX,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center\" alt=\"在这里插入图片描述\"><br>高-10次：<br><img src=\"https://img-blog.csdnimg.cn/583aaaba9df04220800b94ce1c38d10f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Lu_55Sf56iL5bqP5ZGY5Lya5qKm6KeB55S15a2Q576K5ZCX,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center\" alt=\"在这里插入图片描述\"></p>\n<p>此时，可以看出在较高训练次数之后<br>核密度图出现较明显变化。<br>保留训练十次得到的模型，控制变量调整测试数据</p>\n<h3 id=\"调参\"><a href=\"#调参\" class=\"headerlink\" title=\"调参\"></a>调参</h3><p>(reshape(X[100:150])<br><img src=\"https://img-blog.csdnimg.cn/c80f024fe6dc4b7dbf5c7065936cd1ae.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Lu_55Sf56iL5bqP5ZGY5Lya5qKm6KeB55S15a2Q576K5ZCX,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center\" alt=\"在这里插入图片描述\"><br>(reshape(X[100:110])<br><img src=\"https://img-blog.csdnimg.cn/54af566605b849b0ad28c1373c3ed5f2.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Lu_55Sf56iL5bqP5ZGY5Lya5qKm6KeB55S15a2Q576K5ZCX,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center\" alt=\"在这里插入图片描述\"><br>(reshape(X[100:102])<br><img src=\"https://img-blog.csdnimg.cn/3c7475a4b7fc495bb3dda6356cb42822.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBA5Lu_55Sf56iL5bqP5ZGY5Lya5qKm6KeB55S15a2Q576K5ZCX,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center\" alt=\"在这里插入图片描述\"></p>\n<pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">import torch\n\ndevice &#x3D; torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)\n\n#inputs,target &#x3D; inputs.to(device),target.to(device)\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nMIN_ROOT &#x3D; -1\nMAX_ROOT &#x3D; 1\n\ndef make(n_samples, n_degree):\n    global MIN_ROOT, MAX_ROOT\n    y &#x3D; np.random.uniform(MIN_ROOT, MAX_ROOT, (n_samples, n_degree))\n    y.sort(axis&#x3D;1)\n    X &#x3D; np.array([np.poly(_) for _ in y])\n    return X, y\n\n# toy case\nX, y &#x3D; make(1, 2)\n\n\nN_SAMPLES &#x3D; 100000\nDEGREE &#x3D; 5\nX_train, y_train &#x3D; make(int(N_SAMPLES*0.8), DEGREE)\nX_test, y_test &#x3D; make(int(N_SAMPLES*0.2), DEGREE)\n\nimport os\nos.environ[&#39;TF_CPP_MIN_LOG_LEVEL&#39;]&#x3D;&#39;2&#39;\n\ndef reshape(array):\n    return np.expand_dims(array, -1)\n\n\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, RepeatVector, Dense, TimeDistributed\n\n\nhidden_size &#x3D; 128\n\nmodel &#x3D; Sequential()\n\n# ENCODER PART OF SEQ2SEQ\nmodel.add(LSTM(hidden_size, input_shape&#x3D;(DEGREE+1, 1)))\n\n# DECODER PART OF SEQ2SEQ\nmodel.add(RepeatVector(DEGREE))  # this determines the length of the output sequence\nmodel.add((LSTM(hidden_size, return_sequences&#x3D;True)))\nmodel.add(TimeDistributed(Dense(1)))\n\nmodel.compile(loss&#x3D;&#39;mean_absolute_error&#39;,\n              optimizer&#x3D;&#39;adam&#39;,\n              metrics&#x3D;[&#39;mae&#39;])\n#model.to(device)\n#print(model.summary())\n&#39;&#39;&#39;\nBATCH_SIZE &#x3D; 128\nmodel.fit(reshape(X_train),\n          reshape(y_train),\n          batch_size&#x3D;BATCH_SIZE,\n          epochs&#x3D;3,\n          verbose&#x3D;1,\n          validation_data&#x3D;(reshape(X_test),\n                           reshape(y_test)))\n\n\ny_pred &#x3D; model.predict(reshape(X_test))\ny_pred &#x3D; np.squeeze(y_pred)\n\n\n#% matplotlib inline\n\n\ndef get_evals(polynomials, roots):\n    evals &#x3D; [\n        [np.polyval(poly, r) for r in root_row]\n        for (root_row, poly) in zip(roots, polynomials)\n    ]\n    evals &#x3D; np.array(evals).ravel()\n    return evals\n\n\ndef compare_to_random(y_pred, y_test, polynomials):\n    y_random &#x3D; np.random.uniform(MIN_ROOT, MAX_ROOT, y_test.shape)\n    y_random.sort(axis&#x3D;1)\n\n    fig, axes &#x3D; plt.subplots(1, 2, figsize&#x3D;(12, 6))\n    ax &#x3D; axes[0]\n    ax.hist(np.abs((y_random - y_test).ravel()),\n            alpha&#x3D;.4, label&#x3D;&#39;random guessing&#39;)\n    ax.hist(np.abs((y_pred - y_test).ravel()),\n            color&#x3D;&#39;r&#39;, alpha&#x3D;.4, label&#x3D;&#39;model predictions&#39;)\n    ax.set(title&#x3D;&#39;Histogram of absolute errors&#39;,\n           ylabel&#x3D;&#39;count&#39;, xlabel&#x3D;&#39;absolute error&#39;)\n    ax.legend(loc&#x3D;&#39;best&#39;)\n\n    ax &#x3D; axes[1]\n    random_evals &#x3D; get_evals(polynomials, y_random)\n    predicted_evals &#x3D; get_evals(polynomials, y_pred)\n    pd.Series(random_evals).plot.kde(ax&#x3D;ax, label&#x3D;&#39;random guessing kde&#39;)\n    pd.Series(predicted_evals).plot.kde(ax&#x3D;ax, color&#x3D;&#39;r&#39;, label&#x3D;&#39;model prediction kde&#39;)\n    title &#x3D; &#39;Kernel Density Estimate plot\\n&#39; \\\n            &#39;for polynomial evaluation of (predicted) roots&#39;\n    ax.set(xlim&#x3D;[-.5, .5], title&#x3D;title)\n    ax.legend(loc&#x3D;&#39;best&#39;)\n\n    fig.tight_layout()\n\ncompare_to_random(y_pred, y_test, X_test)\nplt.show()\n\n&#39;&#39;&#39;\n\nMAX_DEGREE &#x3D; 15\nMIN_DEGREE &#x3D; 5\nMAX_ROOT &#x3D; 1\nMIN_ROOT &#x3D; -1\nN_SAMPLES &#x3D; 10000 * (MAX_DEGREE - MIN_DEGREE + 1)\n\n\ndef make(n_samples, max_degree, min_degree, min_root, max_root):\n    samples_per_degree &#x3D; n_samples &#x2F;&#x2F; (max_degree - min_degree + 1)\n    n_samples &#x3D; samples_per_degree * (max_degree - min_degree + 1)\n    X &#x3D; np.zeros((n_samples, max_degree + 1))\n    # XXX: filling the truth labels with ZERO??? EOS character would be nice\n    y &#x3D; np.zeros((n_samples, max_degree, 2))\n    for i, degree in enumerate(range(min_degree, max_degree + 1)):\n        y_tmp &#x3D; np.random.uniform(min_root, max_root, (samples_per_degree, degree))\n        y_tmp.sort(axis&#x3D;1)\n        X_tmp &#x3D; np.array([np.poly(_) for _ in y_tmp])\n\n        root_slice_y &#x3D; np.s_[\n                       i * samples_per_degree:(i + 1) * samples_per_degree,\n                       :degree,\n                       0]\n        pad_slice_y &#x3D; np.s_[\n                      i * samples_per_degree:(i + 1) * samples_per_degree,\n                      degree:,\n                      1]\n        this_slice_X &#x3D; np.s_[\n                       i * samples_per_degree:(i + 1) * samples_per_degree,\n                       -degree - 1:]\n\n        y[root_slice_y] &#x3D; y_tmp\n        y[pad_slice_y] &#x3D; 1\n        X[this_slice_X] &#x3D; X_tmp\n    return X, y\n\n\ndef make_this():\n    global MAX_DEGREE, MIN_DEGREE, MAX_ROOT, MIN_ROOT, N_SAMPLES\n    return make(N_SAMPLES, MAX_DEGREE, MIN_DEGREE, MIN_ROOT, MAX_ROOT)\n\n\nfrom sklearn.model_selection import train_test_split\n\nX, y &#x3D; make_this()\nX_train, X_test, y_train, y_test &#x3D; train_test_split(X, y, test_size&#x3D;0.25)\n&#39;&#39;&#39;\nprint(&#39;X shapes&#39;, X.shape, X_train.shape, X_test.shape)\nprint(&#39;y shapes&#39;, y.shape, y_train.shape, y_test.shape)\nprint(&#39;-&#39; * 80)\nprint(&#39;This is an example root sequence&#39;)\nprint(y[0])\n&#39;&#39;&#39;\nhidden_size &#x3D; 128\nmodel &#x3D; Sequential()\n\nmodel.add(LSTM(hidden_size, input_shape&#x3D;(MAX_DEGREE+1, 1)))\nmodel.add(RepeatVector(MAX_DEGREE))\nmodel.add((LSTM(hidden_size, return_sequences&#x3D;True)))\nmodel.add(TimeDistributed(Dense(2)))\n\nmodel.compile(loss&#x3D;&#39;mean_absolute_error&#39;,\n              optimizer&#x3D;&#39;adam&#39;,\n              metrics&#x3D;[&#39;mae&#39;])\n\n#print(model.summary())\n\nmodel.predict(reshape(X_test));  # this last semi-column will suppress the output.\n&#39;&#39;&#39;\nBATCH_SIZE &#x3D; 40\nmodel.fit(reshape(X_train), y_train,\n          batch_size&#x3D;BATCH_SIZE,\n          epochs&#x3D;10,\n          verbose&#x3D;1,\n          validation_data&#x3D;(reshape(X_test), y_test))\n&#39;&#39;&#39;\nmodel.predict(reshape(X[100:102]))\n\ny_pred &#x3D; model.predict(reshape(X_test))\npad_or_not &#x3D; y_pred[:, :, 1].ravel()\nfig, ax &#x3D; plt.subplots()\nax.set(title&#x3D;&#39;histogram for predicting PAD&#39;,\n       xlabel&#x3D;&#39;predicted value&#39;,\n       ylabel&#x3D;&#39;count&#39;)\nax.hist(pad_or_not, bins&#x3D;5);\n\nthr &#x3D; 0.5\n\n\ndef how_many_roots(predicted):\n    global thr\n    return np.sum(predicted[:, 1] &lt; thr)\n\n\ntrue_root_count &#x3D; np.array(list(map(how_many_roots, y_test)))\npred_root_count &#x3D; np.array(list(map(how_many_roots, y_pred)))\nfrom collections import Counter\nfor key, val in Counter(true_root_count - pred_root_count).items():\n    print(&#39;off by &#123;&#125;: &#123;&#125; times&#39;.format(key, val))\n\nindex &#x3D; np.where(true_root_count &#x3D;&#x3D; pred_root_count)[0]\nindex &#x3D; np.random.choice(index, 1000, replace&#x3D;False)\n\npredicted_evals, random_evals &#x3D; [], []\nrandom_roots_list &#x3D; []\npredicted_roots_list &#x3D; []\ntrue_roots_list &#x3D; []\nfor i in index:\n    predicted_roots &#x3D; [row[0] for row in y_pred[i] if row[1] &lt; thr]\n    true_roots &#x3D; [row[0] for row in y_test[i] if row[1] &#x3D;&#x3D; 0]\n    random_roots &#x3D; np.random.uniform(MIN_ROOT, MAX_ROOT, len(predicted_roots))\n    random_roots &#x3D; sorted(random_roots)\n    random_roots_list.extend(random_roots)\n    predicted_roots_list.extend(predicted_roots)\n    true_roots_list.extend(true_roots)\n    for predicted_root, random_root in zip(predicted_roots, random_roots):\n        predicted_evals.append(\n            np.polyval(X_test[i], predicted_root))\n        random_evals.append(\n            np.polyval(X_test[i], random_root))\n\nassert len(true_roots_list) &#x3D;&#x3D; len(predicted_roots_list)\nassert len(random_roots_list) &#x3D;&#x3D; len(predicted_roots_list)\ntrue_roots_list &#x3D; np.array(true_roots_list)\nrandom_roots_list &#x3D; np.array(random_roots_list)\npredicted_roots_list &#x3D; np.array(predicted_roots_list)\nfig, axes &#x3D; plt.subplots(1, 2, figsize&#x3D;(12, 6))\nax &#x3D; axes[0]\nax.hist(np.abs(random_roots_list - true_roots_list),\n        alpha&#x3D;.4, label&#x3D;&#39;random guessing&#39;)\nax.hist(np.abs(predicted_roots_list - true_roots_list),\n        color&#x3D;&#39;r&#39;, alpha&#x3D;.4, label&#x3D;&#39;model predictions&#39;)\nax.set(title&#x3D;&#39;Histogram of absolute errors&#39;,\n       ylabel&#x3D;&#39;count&#39;, xlabel&#x3D;&#39;absolute error&#39;)\nax.legend(loc&#x3D;&#39;best&#39;)\n\nax &#x3D; axes[1]\npd.Series(random_evals).plot.kde(ax&#x3D;ax, label&#x3D;&#39;random guessing kde&#39;)\npd.Series(predicted_evals).plot.kde(ax&#x3D;ax, color&#x3D;&#39;r&#39;, label&#x3D;&#39;model prediction kde&#39;)\ntitle &#x3D; &#39;Kernel Density Estimate plot\\n&#39; \\\n        &#39;for polynomial evaluation of (predicted) roots&#39;\nax.set(xlim&#x3D;[-.5, .5], title&#x3D;title)\nax.legend(loc&#x3D;&#39;best&#39;)\n\nfig.tight_layout()\n\nplt.show()</code></pre>\n<p>ML3</p>\n<h2 id=\"CNN实战\"><a href=\"#CNN实战\" class=\"headerlink\" title=\"CNN实战\"></a>CNN实战</h2><p>google colab</p>\n<pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">\n# Download the dataset\n# You may choose where to download the data.\n\n# Google Drive\n!gdown --id &#39;1awF7pZ9Dz7X1jn1_QAiKN-_v56veCEKy&#39; --output food-11.zip\n\n# Dropbox\n# !wget https:&#x2F;&#x2F;www.dropbox.com&#x2F;s&#x2F;m9q6273jl3djall&#x2F;food-11.zip -O food-11.zip\n\n# MEGA\n# !sudo apt install megatools\n# !megadl &quot;https:&#x2F;&#x2F;mega.nz&#x2F;#!zt1TTIhK!ZuMbg5ZjGWzWX1I6nEUbfjMZgCmAgeqJlwDkqdIryfg&quot;\n\n# Unzip the dataset.\n# This may take some time.\n!unzip -q food-11.zip\n\n# Import necessary packages.\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\nfrom PIL import Image\n# &quot;ConcatDataset&quot; and &quot;Subset&quot; are possibly useful when doing semi-supervised learning.\nfrom torch.utils.data import ConcatDataset, DataLoader, Subset\nfrom torchvision.datasets import DatasetFolder\n\n# This is for the progress bar.\nfrom tqdm.auto import tqdm\n\n\n# It is important to do data augmentation in training.\n# However, not every augmentation is useful.\n# Please think about what kind of augmentation is helpful for food recognition.\ntrain_tfm &#x3D; transforms.Compose([\n    # Resize the image into a fixed shape (height &#x3D; width &#x3D; 128)\n    transforms.Resize((128, 128)),\n    # You may add some transforms here.\n    # ToTensor() should be the last one of the transforms.\n    transforms.ToTensor(),\n])\n\n# We don&#39;t need augmentations in testing and validation.\n# All we need here is to resize the PIL image and transform it into Tensor.\ntest_tfm &#x3D; transforms.Compose([\n    transforms.Resize((128, 128)),\n    transforms.ToTensor(),\n])\n\n\n# Batch size for training, validation, and testing.\n# A greater batch size usually gives a more stable gradient.\n# But the GPU memory is limited, so please adjust it carefully.\nbatch_size &#x3D; 128\n\n# Construct datasets.\n# The argument &quot;loader&quot; tells how torchvision reads the data.\ntrain_set &#x3D; DatasetFolder(&quot;food-11&#x2F;training&#x2F;labeled&quot;, loader&#x3D;lambda x: Image.open(x), extensions&#x3D;&quot;jpg&quot;, transform&#x3D;train_tfm)\nvalid_set &#x3D; DatasetFolder(&quot;food-11&#x2F;validation&quot;, loader&#x3D;lambda x: Image.open(x), extensions&#x3D;&quot;jpg&quot;, transform&#x3D;test_tfm)\nunlabeled_set &#x3D; DatasetFolder(&quot;food-11&#x2F;training&#x2F;unlabeled&quot;, loader&#x3D;lambda x: Image.open(x), extensions&#x3D;&quot;jpg&quot;, transform&#x3D;train_tfm)\ntest_set &#x3D; DatasetFolder(&quot;food-11&#x2F;testing&quot;, loader&#x3D;lambda x: Image.open(x), extensions&#x3D;&quot;jpg&quot;, transform&#x3D;test_tfm)\n\n# Construct data loaders.\ntrain_loader &#x3D; DataLoader(train_set, batch_size&#x3D;batch_size, shuffle&#x3D;True, num_workers&#x3D;8, pin_memory&#x3D;True)\nvalid_loader &#x3D; DataLoader(valid_set, batch_size&#x3D;batch_size, shuffle&#x3D;True, num_workers&#x3D;8, pin_memory&#x3D;True)\ntest_loader &#x3D; DataLoader(test_set, batch_size&#x3D;batch_size, shuffle&#x3D;False)\n\n\n\nclass Classifier(nn.Module):\n    def __init__(self):\n        super(Classifier, self).__init__()\n        # The arguments for commonly used modules:\n        # torch.nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n        # torch.nn.MaxPool2d(kernel_size, stride, padding)\n\n        # input image size: [3, 128, 128]\n        self.cnn_layers &#x3D; nn.Sequential(\n            nn.Conv2d(3, 64, 3, 1, 1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0),\n\n            nn.Conv2d(64, 128, 3, 1, 1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(),\n            nn.MaxPool2d(2, 2, 0),\n\n            nn.Conv2d(128, 256, 3, 1, 1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(),\n            nn.MaxPool2d(4, 4, 0),\n        )\n        self.fc_layers &#x3D; nn.Sequential(\n            nn.Linear(256 * 8 * 8, 256),\n            nn.ReLU(),\n            nn.Linear(256, 256),\n            nn.ReLU(),\n            nn.Linear(256, 11)\n        )\n\ndef forward(self, x):\n        # input (x): [batch_size, 3, 128, 128]\n        # output: [batch_size, 11]\n\n        # Extract features by convolutional layers.\n        x &#x3D; self.cnn_layers(x)\n\n        # The extracted feature map must be flatten before going to fully-connected layers.\n        x &#x3D; x.flatten(1)\n\n        # The features are transformed by fully-connected layers to obtain the final logits.\n        x &#x3D; self.fc_layers(x)\n        return x\n\n\ndef get_pseudo_labels(dataset, model, threshold&#x3D;0.65):\n    # This functions generates pseudo-labels of a dataset using given model.\n    # It returns an instance of DatasetFolder containing images whose prediction confidences exceed a given threshold.\n    # You are NOT allowed to use any models trained on external data for pseudo-labeling.\n    device &#x3D; &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;\n\n    # Construct a data loader.\n    data_loader &#x3D; DataLoader(dataset, batch_size&#x3D;batch_size, shuffle&#x3D;False)\n\n    # Make sure the model is in eval mode.\n    model.eval()\n    # Define softmax function.\n    softmax &#x3D; nn.Softmax(dim&#x3D;-1)\n\n    # Iterate over the dataset by batches.\n    for batch in tqdm(data_loader):\n        img, _ &#x3D; batch\n\n        # Forward the data\n        # Using torch.no_grad() accelerates the forward process.\n        with torch.no_grad():\n            logits &#x3D; model(img.to(device))\n\n        # Obtain the probability distributions by applying softmax on logits.\n        probs &#x3D; softmax(logits)\n\n        # ---------- TODO ----------\n        # Filter the data and construct a new dataset.\n\n    # # Turn off the eval mode.\n    model.train()\n    return dataset\n\n\n\n# &quot;cuda&quot; only when GPUs are available.\ndevice &#x3D; &quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;\n\n# Initialize a model, and put it on the device specified.\nmodel &#x3D; Classifier().to(device)\nmodel.device &#x3D; device\n\n# For the classification task, we use cross-entropy as the measurement of performance.\ncriterion &#x3D; nn.CrossEntropyLoss()\n\n# Initialize optimizer, you may fine-tune some hyperparameters such as learning rate on your own.\noptimizer &#x3D; torch.optim.Adam(model.parameters(), lr&#x3D;0.0003, weight_decay&#x3D;1e-5)\n\n# The number of training epochs.\nn_epochs &#x3D; 80\n\n# Whether to do semi-supervised learning.\ndo_semi &#x3D; False\n\nfor epoch in range(n_epochs):\n    # ---------- TODO ----------\n    # In each epoch, relabel the unlabeled dataset for semi-supervised learning.\n    # Then you can combine the labeled dataset and pseudo-labeled dataset for the training.\n    if do_semi:\n        # Obtain pseudo-labels for unlabeled data using trained model.\n        pseudo_set &#x3D; get_pseudo_labels(unlabeled_set, model)\n\n        # Construct a new dataset and a data loader for training.\n        # This is used in semi-supervised learning only.\n        concat_dataset &#x3D; ConcatDataset([train_set, pseudo_set])\n        train_loader &#x3D; DataLoader(concat_dataset, batch_size&#x3D;batch_size, shuffle&#x3D;True, num_workers&#x3D;8, pin_memory&#x3D;True)\n\n    # ---------- Training ----------\n    # Make sure the model is in train mode before training.\n    model.train()\n\n    # These are used to record information in training.\n    train_loss &#x3D; []\n    train_accs &#x3D; []\n\n    # Iterate the training set by batches.\n    for batch in tqdm(train_loader):\n\n        # A batch consists of image data and corresponding labels.\n        imgs, labels &#x3D; batch\n\n        # Forward the data. (Make sure data and model are on the same device.)\n        logits &#x3D; model(imgs.to(device))\n\n        # Calculate the cross-entropy loss.\n        # We don&#39;t need to apply softmax before computing cross-entropy as it is done automatically.\n        loss &#x3D; criterion(logits, labels.to(device))\n\n        # Gradients stored in the parameters in the previous step should be cleared out first.\n        optimizer.zero_grad()\n\n        # Compute the gradients for parameters.\n        loss.backward()\n\n        # Clip the gradient norms for stable training.\n        grad_norm &#x3D; nn.utils.clip_grad_norm_(model.parameters(), max_norm&#x3D;10)\n\n        # Update the parameters with computed gradients.\n        optimizer.step()\n\n        # Compute the accuracy for current batch.\n        acc &#x3D; (logits.argmax(dim&#x3D;-1) &#x3D;&#x3D; labels.to(device)).float().mean()\n\n        # Record the loss and accuracy.\n        train_loss.append(loss.item())\n        train_accs.append(acc)\n\n    # The average loss and accuracy of the training set is the average of the recorded values.\n    train_loss &#x3D; sum(train_loss) &#x2F; len(train_loss)\n    train_acc &#x3D; sum(train_accs) &#x2F; len(train_accs)\n\n    # Print the information.\n    print(f&quot;[ Train | &#123;epoch + 1:03d&#125;&#x2F;&#123;n_epochs:03d&#125; ] loss &#x3D; &#123;train_loss:.5f&#125;, acc &#x3D; &#123;train_acc:.5f&#125;&quot;)\n\n    # ---------- Validation ----------\n    # Make sure the model is in eval mode so that some modules like dropout are disabled and work normally.\n    model.eval()\n\n    # These are used to record information in validation.\n    valid_loss &#x3D; []\n    valid_accs &#x3D; []\n\n    # Iterate the validation set by batches.\n    for batch in tqdm(valid_loader):\n\n        # A batch consists of image data and corresponding labels.\n        imgs, labels &#x3D; batch\n\n        # We don&#39;t need gradient in validation.\n        # Using torch.no_grad() accelerates the forward process.\n        with torch.no_grad():\n          logits &#x3D; model(imgs.to(device))\n\n        # We can still compute the loss (but not the gradient).\n        loss &#x3D; criterion(logits, labels.to(device))\n\n        # Compute the accuracy for current batch.\n        acc &#x3D; (logits.argmax(dim&#x3D;-1) &#x3D;&#x3D; labels.to(device)).float().mean()\n\n        # Record the loss and accuracy.\n        valid_loss.append(loss.item())\n        valid_accs.append(acc)\n\n    # The average loss and accuracy for entire validation set is the average of the recorded values.\n    valid_loss &#x3D; sum(valid_loss) &#x2F; len(valid_loss)\n    valid_acc &#x3D; sum(valid_accs) &#x2F; len(valid_accs)\n\n    # Print the information.\n    print(f&quot;[ Valid | &#123;epoch + 1:03d&#125;&#x2F;&#123;n_epochs:03d&#125; ] loss &#x3D; &#123;valid_loss:.5f&#125;, acc &#x3D; &#123;valid_acc:.5f&#125;&quot;)\n\n</code></pre>\n<h2 id=\"tensorflow基础\"><a href=\"#tensorflow基础\" class=\"headerlink\" title=\"tensorflow基础\"></a>tensorflow基础</h2><p>官方教程</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><a href=\"https://www.tensorflow.org/guide/keras/sequential_model?hl=zh-cn\">https://www.tensorflow.org/guide/keras/sequential_model?hl=zh-cn</a></p></blockquote>\n<h3 id=\"keras\"><a href=\"#keras\" class=\"headerlink\" title=\"keras\"></a>keras</h3><p>设置</p>\n<pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers</code></pre>\n<h4 id=\"Sequential\"><a href=\"#Sequential\" class=\"headerlink\" title=\"Sequential\"></a>Sequential</h4><p>Sequential模型适用于层的普通堆栈，其中每层正好有一个输入张量和一个输出张量。</p>\n<pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\"># Define Sequential model with 3 layers\nmodel &#x3D; keras.Sequential(\n    [\n        layers.Dense(2, activation&#x3D;&quot;relu&quot;, name&#x3D;&quot;layer1&quot;),\n        layers.Dense(3, activation&#x3D;&quot;relu&quot;, name&#x3D;&quot;layer2&quot;),\n        layers.Dense(4, name&#x3D;&quot;layer3&quot;),\n    ]\n)\n# Call model on a test input\nx &#x3D; tf.ones((3, 3))\ny &#x3D; model(x)</code></pre>\n<p>顺序模型在以下情况下不合适：</p>\n<ul>\n<li>模型具有多个输入或多个输出 </li>\n<li>任何图层都有多个输入或多个输出 </li>\n<li>您需要执行图层共享 </li>\n<li>您需要非线性拓扑（例如残差连接、多分支模型）</li>\n</ul>\n<p><strong>常见的调试工作流：add() + summary()</strong><br>构建新的顺序体系结构时，以增量方式堆叠图层并频繁打印模型摘要非常有用。例如，这使您能够监视堆栈和图层如何缩减像素采样图像特征映射：add()Conv2DMaxPooling2D</p>\n<pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">model &#x3D; keras.Sequential()\nmodel.add(keras.Input(shape&#x3D;(250, 250, 3)))  # 250x250 RGB images\nmodel.add(layers.Conv2D(32, 5, strides&#x3D;2, activation&#x3D;&quot;relu&quot;))\nmodel.add(layers.Conv2D(32, 3, activation&#x3D;&quot;relu&quot;))\nmodel.add(layers.MaxPooling2D(3))\n\n# Can you guess what the current output shape is at this point? Probably not.\n# Let&#39;s just print it:\nmodel.summary()\n\n# The answer was: (40, 40, 32), so we can keep downsampling...\n\nmodel.add(layers.Conv2D(32, 3, activation&#x3D;&quot;relu&quot;))\nmodel.add(layers.Conv2D(32, 3, activation&#x3D;&quot;relu&quot;))\nmodel.add(layers.MaxPooling2D(3))\nmodel.add(layers.Conv2D(32, 3, activation&#x3D;&quot;relu&quot;))\nmodel.add(layers.Conv2D(32, 3, activation&#x3D;&quot;relu&quot;))\nmodel.add(layers.MaxPooling2D(2))\n\n# And now?\nmodel.summary()\n\n# Now that we have 4x4 feature maps, time to apply global max pooling.\nmodel.add(layers.GlobalMaxPooling2D())\n\n# Finally, we add a classification layer.\nmodel.add(layers.Dense(10))</code></pre>\n<h3 id=\"Eager-Execution\"><a href=\"#Eager-Execution\" class=\"headerlink\" title=\"Eager Execution\"></a>Eager Execution</h3><p>TensorFlow 的 Eager Execution 是一种命令式编程环境，可立即评估运算，无需构建计算图：运算会返回具体的值，而非构建供稍后运行的计算图。这样能使您轻松入门 TensorFlow 并调试模型，同时也减少了样板代码。要跟随本指南进行学习，请在交互式 python 解释器中运行以下代码示例。</p>\n<p>Eager Execution 是用于研究和实验的灵活机器学习平台，具备以下特性：</p>\n<ul>\n<li>直观的界面 - 自然地组织代码结构并使用 Python 数据结构。快速迭代小模型和小数据。</li>\n<li>更方便的调试功能 -直接调用运算以检查正在运行的模型并测试更改。使用标准 Python 调试工具立即报告错误。</li>\n<li>自然的控制流 - 使用 Python而非计算图控制流，简化了动态模型的规范。</li>\n</ul>\n<p>Eager Execution 支持大部分 TensorFlow 运算和 GPU 加速。</p>\n<p>设置和基本用法</p>\n<pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">import os\n\nimport tensorflow as tf\n\nimport cProfile</code></pre>\n<h4 id=\"Eager-训练\"><a href=\"#Eager-训练\" class=\"headerlink\" title=\"Eager 训练\"></a>Eager 训练</h4><p>计算梯度</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>自动微分对实现机器学习算法（例如用于训练神经网络的反向传播）十分有用。在 Eager Execution 期间，请使用 tf.GradientTape 跟踪运算以便稍后计算梯度。</p></blockquote>\n<p>您可以在 Eager Execution 中使用 tf.GradientTape 来训练和/或计算梯度。这对复杂的训练循环特别有用。</p>\n<p>由于在每次调用期间都可能进行不同运算，所有前向传递的运算都会记录到“条带”中。要计算梯度，请反向播放条带，然后丢弃。特定 tf.GradientTape 只能计算一个梯度；后续调用会引发运行时错误。</p>\n<pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">w &#x3D; tf.Variable([[1.0]])\nwith tf.GradientTape() as tape:\n  loss &#x3D; w * w\n\ngrad &#x3D; tape.gradient(loss, w)\nprint(grad)  # &#x3D;&gt; tf.Tensor([[ 2.]], shape&#x3D;(1, 1), dtype&#x3D;float32)</code></pre>\n<p>训练模型<br>以下示例创建了一个多层模型，该模型会对标准 MNIST 手写数字进行分类。示例演示了在 Eager Execution 环境中构建可训练计算图的优化器和层 API。</p>\n<pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\"># Fetch and format the mnist data\n(mnist_images, mnist_labels), _ &#x3D; tf.keras.datasets.mnist.load_data()\n\ndataset &#x3D; tf.data.Dataset.from_tensor_slices(\n  (tf.cast(mnist_images[...,tf.newaxis]&#x2F;255, tf.float32),\n   tf.cast(mnist_labels,tf.int64)))\ndataset &#x3D; dataset.shuffle(1000).batch(32)</code></pre>\n<pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\"># Build the model\nmnist_model &#x3D; tf.keras.Sequential([\n  tf.keras.layers.Conv2D(16,[3,3], activation&#x3D;&#39;relu&#39;,\n                         input_shape&#x3D;(None, None, 1)),\n  tf.keras.layers.Conv2D(16,[3,3], activation&#x3D;&#39;relu&#39;),\n  tf.keras.layers.GlobalAveragePooling2D(),\n  tf.keras.layers.Dense(10)\n])</code></pre>\n","text":"这一期内容有些杂，有基础知识，也有代码实战。 卷积神经网络 该部分图片及资料来源： http://www.huaxiaozhuan.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapters/5_CNN.html 卷积定义许多神经网络库会实...","link":"","photos":[],"count_time":{"symbolsCount":"33k","symbolsTime":"30 mins."},"categories":[],"tags":[{"name":"深度学习","slug":"深度学习","count":9,"path":"api/tags/深度学习.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C\"><span class=\"toc-text\">卷积神经网络</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%8D%B7%E7%A7%AF%E5%AE%9A%E4%B9%89\"><span class=\"toc-text\">卷积定义</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98%EF%BC%9Amnist%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E8%AF%86%E5%88%AB\"><span class=\"toc-text\">深度学习实战：mnist手写数字识别</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80\"><span class=\"toc-text\">深度学习基础</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#CUDA%E4%BD%BF%E7%94%A8GPU%E5%8A%A0%E9%80%9F\"><span class=\"toc-text\">CUDA使用GPU加速</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%9F%BA%E4%BA%8E%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E6%B1%82%E4%B8%80%E5%85%83%E9%AB%98%E6%AC%A1%E6%96%B9%E7%A8%8B%E8%BF%91%E4%BC%BC%E8%A7%A3\"><span class=\"toc-text\">基于神经网络求一元高次方程近似解</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%BD%8E%E6%AC%A1%E2%80%94%E2%80%945%E6%AC%A1%E5%A4%9A%E9%A1%B9%E5%BC%8F\"><span class=\"toc-text\">低次——5次多项式</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E9%AB%98%E6%AC%A1%E2%80%94%E2%80%94%EF%BC%884-16%E6%AC%A1%EF%BC%89\"><span class=\"toc-text\">高次——（4~16次）</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%B0%83%E5%8F%82\"><span class=\"toc-text\">调参</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#CNN%E5%AE%9E%E6%88%98\"><span class=\"toc-text\">CNN实战</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#tensorflow%E5%9F%BA%E7%A1%80\"><span class=\"toc-text\">tensorflow基础</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#keras\"><span class=\"toc-text\">keras</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#Sequential\"><span class=\"toc-text\">Sequential</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Eager-Execution\"><span class=\"toc-text\">Eager Execution</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#Eager-%E8%AE%AD%E7%BB%83\"><span class=\"toc-text\">Eager 训练</span></a></li></ol></li></ol></li></ol>","author":{"name":"Algernon","slug":"blog-author","avatar":"https://user-images.githubusercontent.com/54904760/224857900-b2e8457c-43d2-46b7-901c-6c770f24bbad.png","link":"/","description":"谁也没见过风，更别说我和你了","socials":{"github":"https://github.com/Algernon98","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/Algernon98","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://space.bilibili.com/281724502"}}}},"mapped":true,"prev_post":{"title":"python学习基础","uid":"f7d5b366240b7b48d4ee1a1a176f024a","slug":"python学习基础","date":"2022-11-03T14:02:49.000Z","updated":"2022-11-03T14:02:35.498Z","comments":true,"path":"api/articles/python学习基础.json","keywords":null,"cover":[],"text":"《计算与人工智能概论》字符串和列表基础\\t 制表符字符串与数字相乘：字符串重复几次3‘un’字符串和字符串相加：字符串连接起来‘un’+’ium’*字符串索引下标，第一个字符索引是0 word = ‘Python’word[0]‘P’word[5]‘n’ 索引也可以用负数，这种会...","link":"","photos":[],"count_time":{"symbolsCount":"12k","symbolsTime":"11 mins."},"categories":[],"tags":[{"name":"python","slug":"python","count":9,"path":"api/tags/python.json"}],"author":{"name":"Algernon","slug":"blog-author","avatar":"https://user-images.githubusercontent.com/54904760/224857900-b2e8457c-43d2-46b7-901c-6c770f24bbad.png","link":"/","description":"谁也没见过风，更别说我和你了","socials":{"github":"https://github.com/Algernon98","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/Algernon98","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://space.bilibili.com/281724502"}}}}},"next_post":{"title":"【电子羊的奇妙冒险】初试深度学习（1）","uid":"7cd45e73325ddad87a2769240b2106a6","slug":"电子羊1","date":"2022-11-03T13:58:49.000Z","updated":"2022-11-03T15:57:53.959Z","comments":true,"path":"api/articles/电子羊1.json","keywords":null,"cover":[],"text":"最近忙于浩繁的学习任务，深感知识体系庞大，而面向百度学习又免不了亦步亦趋的情况，于是特开一个板块用于记录学习历程，也顺便作为笔记，适时阶段性总结。 环境配置配置清单 硬件：联想拯救者（GTX 1050ti） 系统：Ubuntu 20.04 64位 首先，因为《优雅的使用Matla...","link":"","photos":[],"count_time":{"symbolsCount":"17k","symbolsTime":"15 mins."},"categories":[],"tags":[{"name":"深度学习","slug":"深度学习","count":9,"path":"api/tags/深度学习.json"}],"author":{"name":"Algernon","slug":"blog-author","avatar":"https://user-images.githubusercontent.com/54904760/224857900-b2e8457c-43d2-46b7-901c-6c770f24bbad.png","link":"/","description":"谁也没见过风，更别说我和你了","socials":{"github":"https://github.com/Algernon98","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/Algernon98","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://space.bilibili.com/281724502"}}}}}}