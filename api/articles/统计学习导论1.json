{"title":"统计学习导论 学习笔记（1）","uid":"2c79875937ce4f2b27d6f5db2a33f4e1","slug":"统计学习导论1","date":"2022-11-03T13:28:49.000Z","updated":"2022-11-08T16:31:32.232Z","comments":true,"path":"api/articles/统计学习导论1.json","keywords":null,"cover":null,"content":"<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>   大部分统计学习问题分为以下两种类型：指导学习和无指导学习。对每一个预测变量$x_i$(i=1,…,n)都有相应变量的观测$y_i$。建模的目标是通过建立预测变量与响应变量的关系，精准预测响应变量或更好理解响应变量与预测变量的关系。<br>    许多传统的统计学习方法，比如线性回归和逻辑斯谛回归，以及诸如广义可加模型、提升方法和支持向量机等比较现代的方法，都属于指导学习范畴。<br>   对于无指导学习，只有预测变量的观测向量，这些向量没有相应的响应向量与之对应。聚类分析可以用到无指导学习。<br>   半指导学习不提及。</p>\n<p>   我们习惯于将响应变量为定量的问题称为回归分析问题，而将具有定性响应变量的问题定义为分类问题。</p>\n<ul>\n<li>贝叶斯分类器</li>\n<li><p>贝叶斯决策边界</p>\n<p>贝叶斯分类器将产生最低的测试错误率，称为贝叶斯错误率。</p>\n</li>\n<li><p>K最近邻方法</p>\n</li>\n<li>K最近邻分类器</li>\n</ul>\n<h2 id=\"线性回归\"><a href=\"#线性回归\" class=\"headerlink\" title=\"线性回归\"></a>线性回归</h2><p>1.简单线性回归<br>假定X和Y之间存在线性关系，在数学上，又可以将这种线性关系记为：</p>\n<p>   <em>Y</em> $\\approx$  $\\beta_0$ + $\\beta_1$<em>X</em><br>有时会将公式称为Y对X的回归。$\\beta_0$和$\\beta_1$被称为模型的系数或参数。<br><strong>最小二乘估计</strong></p>\n<p>总体回归直线<br><em>Y</em> $\\approx$  $\\beta_0$ + $\\beta_1$<em>X</em> + $\\epsilon$</p>\n<p>2.多元线性回归<br>假设有p个不同的观测变量，则多元线性回归模型的形式为：<br><em>Y</em> $\\approx$  $\\beta_0$ + $\\beta_1X _1$+ $\\beta_2X_2$+ ···+$\\beta_pX_p$+ $\\epsilon$</p>\n<p>最小二乘平面只是对真实总体回归平面的一个估计。我们可以计算<strong>置信区间</strong>以确定到$\\hat{y}$与<em>f</em>(X)的接近程度。                                                         </p>\n<p>数据的非线性——残差图</p>\n<ul>\n<li>离群点</li>\n<li>高杠杆点</li>\n<li>共线性</li>\n</ul>\n<h2 id=\"分类\"><a href=\"#分类\" class=\"headerlink\" title=\"分类\"></a>分类</h2><p>逻辑斯谛回归<br><em>p</em>(X)  =  $\\beta_0$ + $\\beta_0$<em>X</em></p>\n<p>使用逻辑斯谛函数     </p>\n<p><em>p</em>(X)  = $\\cfrac{e^{\\beta_0+\\beta_1X}}{1+e^{\\beta_0+\\beta_1X}}$</p>\n<p>二次判别分析</p>\n<h2 id=\"线性模型选择与正则化\"><a href=\"#线性模型选择与正则化\" class=\"headerlink\" title=\"线性模型选择与正则化\"></a>线性模型选择与正则化</h2><ul>\n<li>子集选择</li>\n<li>压缩估计</li>\n<li>降维法</li>\n</ul>\n<p>1.子集选择<br><strong>最优子集选择</strong>，即对p个预测变量的所有组合分别使用最小二乘回归进行拟合。<br><strong>逐步选择</strong></p>\n<ol>\n<li>向前逐步选择</li>\n</ol>\n<p>向前逐步选择以一个不包含任何预测变量的零模型为起点，依次往模型中添加变量，直至所有的预测变量都包含在模型中。特别之处在于，每次只将能够最大限度提升模型效果的变量加入模型中。</p>\n<ol>\n<li>向后逐步选择<br>以包含全部p个变量的全模型为起点，逐次迭代，每次移除一个对模型拟合结果最不利的变量。</li>\n</ol>\n<p><strong>选择最优模型</strong></p>\n<ul>\n<li>$C_p$</li>\n<li>赤池信息量准则</li>\n<li><p>贝叶斯信息准则（BIC）与调整$R^2$</p>\n<p>2.压缩估计方法<br>使用对系数进行约束或加罚的技巧对包含p个预测变量的模型进行拟合，将系数估计值往零的方向压缩。</p>\n</li>\n</ul>\n<p><strong>岭回归</strong></p>\n<p><strong>lasso</strong><br>lasso建立的模型与岭回归建立的模型相比更易于解释。lasso得到了一个<strong>稀疏模型</strong>———只包含所有变量的一个子集的模型。 </p>\n<p>3.降维方法<br>将预测变量进行变换，然后用转换之后的变量拟合最小二乘模型。</p>\n<ul>\n<li>主成分</li>\n<li><p>偏最小二乘</p>\n<p><strong>主成分分析</strong>是一种可以从多个变量中得到低维变量的有效方法。<br><a href=\"https://www.bilibili.com/video/BV1uv4y1w7Vr/?spm_id_from=333.999.0.0&amp;vd_source=11bfc591eb1189ab7412b09ee29e1dcd\">https://www.bilibili.com/video/BV1uv4y1w7Vr/?spm_id_from=333.999.0.0&amp;vd_source=11bfc591eb1189ab7412b09ee29e1dcd</a>)</p>\n</li>\n</ul></blockquote>\n","text":" 大部分统计学习问题分为以下两种类型：指导学习和无指导学习。对每一个预测变量$x_i$(i=1,…,n)都有相应变量的观测$y_i$。建模的目标是通过建立预测变量与响应变量的关系，精准预测响应变量或更好理解响应变量与预测变量的关系。 许多传统的统计学习方法，比如线性回归和逻辑斯谛...","link":"","photos":[],"count_time":{"symbolsCount":"1.5k","symbolsTime":"1 mins."},"categories":[{"name":"学习笔记","slug":"学习笔记","count":3,"path":"api/categories/学习笔记.json"}],"tags":[{"name":"算法","slug":"算法","count":4,"path":"api/tags/算法.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92\"><span class=\"toc-text\">线性回归</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%88%86%E7%B1%BB\"><span class=\"toc-text\">分类</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8B%E9%80%89%E6%8B%A9%E4%B8%8E%E6%AD%A3%E5%88%99%E5%8C%96\"><span class=\"toc-text\">线性模型选择与正则化</span></a></li></ol>","author":{"name":"Algernon","slug":"blog-author","avatar":"https://user-images.githubusercontent.com/54904760/224857900-b2e8457c-43d2-46b7-901c-6c770f24bbad.png","link":"/","description":"谁也没见过风，更别说我和你了","socials":{"github":"https://github.com/Algernon98","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/Algernon98","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://space.bilibili.com/281724502"}}}},"mapped":true,"prev_post":{"title":"摩尔钓鱼","uid":"6a6d5f1226605e232622dbe9c9907bfc","slug":"moerdiaoyu","date":"2022-11-03T13:44:49.000Z","updated":"2022-11-08T15:52:53.637Z","comments":true,"path":"api/articles/moerdiaoyu.json","keywords":null,"cover":[],"text":" 编辑 题目描述： 2021年的暑假到了，小摩尔们看着手游版波光粼粼的小河，觉得钓鱼会是一个很完美的夏日活动。可是参加活动的摩尔数量太多了，本着爱与和平的原则，为了不让小摩尔们为了争夺场地而吵架，几只聪明的小摩尔决定从一条有着各种各样小鱼的大河修建一个主水道引河水，再通过修建小水...","link":"","photos":[],"count_time":{"symbolsCount":"5.1k","symbolsTime":"5 mins."},"categories":[{"name":"算法","slug":"算法","count":2,"path":"api/categories/算法.json"}],"tags":[{"name":"算法","slug":"算法","count":4,"path":"api/tags/算法.json"}],"author":{"name":"Algernon","slug":"blog-author","avatar":"https://user-images.githubusercontent.com/54904760/224857900-b2e8457c-43d2-46b7-901c-6c770f24bbad.png","link":"/","description":"谁也没见过风，更别说我和你了","socials":{"github":"https://github.com/Algernon98","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/Algernon98","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://space.bilibili.com/281724502"}}}}},"next_post":{"title":"【Python机器学习基础教程】（三）","uid":"8239787d32df6c476a6ebbc5a4594a62","slug":"python机器学习3","date":"2022-11-03T13:17:49.000Z","updated":"2022-11-03T15:57:25.209Z","comments":true,"path":"api/articles/python机器学习3.json","keywords":null,"cover":[],"text":"无监督学习与预处理无监督学习的预处理本章研究两类无监督学习：数据集变换与聚类 数据集的无监督变换是创建数据新的表示的算法。 无监督变换的一个常见应用是降维，它接受包含许多特征的数据的高维表示，并找到表示该数据的一种新方法，用较少的特征就可以概括其特性。降维的一个常见应用是为了可视...","link":"","photos":[],"count_time":{"symbolsCount":"12k","symbolsTime":"11 mins."},"categories":[],"tags":[{"name":"机器学习","slug":"机器学习","count":5,"path":"api/tags/机器学习.json"}],"author":{"name":"Algernon","slug":"blog-author","avatar":"https://user-images.githubusercontent.com/54904760/224857900-b2e8457c-43d2-46b7-901c-6c770f24bbad.png","link":"/","description":"谁也没见过风，更别说我和你了","socials":{"github":"https://github.com/Algernon98","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/Algernon98","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://space.bilibili.com/281724502"}}}}}}