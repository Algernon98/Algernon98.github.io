{"title":"【电子羊的奇妙冒险】初试深度学习（1）","uid":"7cd45e73325ddad87a2769240b2106a6","slug":"电子羊1","date":"2022-11-03T13:58:49.000Z","updated":"2022-11-03T15:57:53.959Z","comments":true,"path":"api/articles/电子羊1.json","keywords":null,"cover":[],"content":"<p>最近忙于浩繁的学习任务，深感知识体系庞大，而面向百度学习又免不了亦步亦趋的情况，于是特开一个板块用于记录学习历程，也顺便作为笔记，适时阶段性总结。</p>\n<h2 id=\"环境配置\"><a href=\"#环境配置\" class=\"headerlink\" title=\"环境配置\"></a>环境配置</h2><p><strong>配置清单</strong></p>\n<ul>\n<li>硬件：联想拯救者（GTX 1050ti）</li>\n<li><p>系统：Ubuntu 20.04 64位</p>\n<p>首先，因为《优雅的使用Matlab进行机器学习》这门课需要在课堂上使用Matlab且连上三节，我的小小游戏本是无法实现开着Matlab再续航三小时的，于是入手了小新14pro，承担上课、写代码以及部分稿件写作的功能。于是拯救者闲置在寝室，为了物尽其用，同时也为了更好地适配pytorch和cuda，重装系统，并安装了双系统（windows10+Ubuntu20.04），让linux从虚拟机中解放。<br>总之，经过一系列操作，我的学习主力逐渐由win向linux转移。</p>\n<p>OK，现在是软件部分。<br>主要安装的程序如下：</p>\n</li>\n<li>nvidia</li>\n<li>cuda</li>\n<li>pytorch</li>\n</ul>\n<p><strong>！！注意：cuda和tensorflow都对软件适配版本有要求，也就是说，经常出现一方软件更新版本而另一方还未适配的情况。如果软件安装好了却一直无法调用，很有可能是通过不同路径下载安装的软件版本不适配，这种情况下最好删掉重新找路径安装，以免之后出现问题。</strong></p>\n<h3 id=\"nvidia驱动安装\"><a href=\"#nvidia驱动安装\" class=\"headerlink\" title=\"nvidia驱动安装\"></a>nvidia驱动安装</h3><p>cuda的环境配置主要来源于这位博主的博客：<a href=\"https://blog.csdn.net/victoryaoyu/article/details/70034569?spm=1001.2014.3001.5506\">https://blog.csdn.net/victoryaoyu/article/details/70034569?spm=1001.2014.3001.5506</a><br>也可参见官方文档</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><a href=\"https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#axzz4dqv9aEUn\">https://docs.nvidia.com/cuda/cuda-installation-guide-linux/index.html#axzz4dqv9aEUn</a></p></blockquote>\n<p>对于版本适配的问题，我的建议是：</p>\n<ol>\n<li>根据硬件（显卡）确定nvidia版本</li>\n<li>依据系统版本（ubuntu）和nvidia版本确定cuda版本</li>\n<li><p>最后按照pytorch官网的配置建议下载pytorch</p>\n<p><img src=\"https://img-blog.csdnimg.cn/65ed99b2828a4e619c87e1c383ef5991.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAQWxnZXJub245OA==,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center\" alt=\"在这里插入图片描述\"><br>验证GPU是否支持CUDA：</p>\n</li>\n</ol>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>$ lspci | grep -i nvidia</p></blockquote>\n<p>验证linux支持：</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>$ uname -m &amp;&amp; cat /etc/*release</p></blockquote>\n<p> 验证gcc：</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>$ gcc —version</p></blockquote>\n<p>若未安装则使用一下命令：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">sudo apt-get  install  build-essential\n</code></pre>\n<p>验证系统已经安装了正确的 Kernel Headers和Development Packages：</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>$ uname -r<br>$ sudo apt-get install linux-headers-$(uname -r)</p></blockquote>\n<p>nvidia驱动我的建议是换源从官网下，可以选择对应版本。</p>\n<p>安装好后重启，终端输入</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>nvidia -smi</p></blockquote>\n<p>查看显卡版本信息</p>\n<h3 id=\"cuda安装\"><a href=\"#cuda安装\" class=\"headerlink\" title=\"cuda安装\"></a>cuda安装</h3><p>这个同样建议在官网对着版本一个一个下</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><a href=\"https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;target_arch=x86_64&amp;Distribution=Ubuntu&amp;target_version=20.04&amp;target_type=deb_network\">https://developer.nvidia.com/cuda-downloads?target_os=Linux&amp;target_arch=x86_64&amp;Distribution=Ubuntu&amp;target_version=20.04&amp;target_type=deb_network</a></p></blockquote>\n<p><img src=\"https://img-blog.csdnimg.cn/8252f2fdccfa4f898b8cf342940df844.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAQWxnZXJub245OA==,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center\" alt=\"在这里插入图片描述\"><br>我的版本如上图，所以终端输入命令行如下：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">wget https:&#x2F;&#x2F;developer.download.nvidia.com&#x2F;compute&#x2F;cuda&#x2F;repos&#x2F;ubuntu2004&#x2F;x86_64&#x2F;cuda-ubuntu2004.pin\nsudo mv cuda-ubuntu2004.pin &#x2F;etc&#x2F;apt&#x2F;preferences.d&#x2F;cuda-repository-pin-600\nsudo apt-key adv --fetch-keys https:&#x2F;&#x2F;developer.download.nvidia.com&#x2F;compute&#x2F;cuda&#x2F;repos&#x2F;ubuntu2004&#x2F;x86_64&#x2F;7fa2af80.pub\nsudo add-apt-repository &quot;deb https:&#x2F;&#x2F;developer.download.nvidia.com&#x2F;compute&#x2F;cuda&#x2F;repos&#x2F;ubuntu2004&#x2F;x86_64&#x2F; &#x2F;&quot;\nsudo apt-get update\nsudo apt-get -y install cuda</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/1505f37355b943b8935f77f61e84735b.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAQWxnZXJub245OA==,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center\" alt=\"在这里插入图片描述\"></p>\n<p>验证CUDA Toolkit，在终端中输入以下命令：</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>$ nvcc -V       </p></blockquote>\n<h3 id=\"pytorch\"><a href=\"#pytorch\" class=\"headerlink\" title=\"pytorch\"></a>pytorch</h3><p>官网链接如下：</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><a href=\"https://pytorch.org/get-started/locally/\">https://pytorch.org/get-started/locally/</a></p></blockquote>\n<p>我用的命令行是：</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>conda install pytorch torchvision torchaudio cudatoolkit=10.2 -c pytorch</p></blockquote>\n<p>安装后，输入下列命令：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">from __future__ import print_function\nimport torch\nx &#x3D; torch.rand(5, 3)\nprint(x)</code></pre>\n<p>输出结果类似下面的结果即安装成功：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">tensor([[0.3380, 0.3845, 0.3217],\n        [0.8337, 0.9050, 0.2650],\n        [0.2979, 0.7141, 0.9069],\n        [0.1449, 0.1132, 0.1375],\n        [0.4675, 0.3947, 0.1426]])</code></pre>\n<p>验证能否正确运行在 GPU 上：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">import torch\ntorch.cuda.is_available()</code></pre>\n<p>如果返回 True，就可以运行，否则就不能。<br>如果不能正常运行，首先检测版本是否对应一致，若不一致，优先考虑将不适配版本彻底删除重装，省心（血泪教训）。</p>\n<h2 id=\"pytorch小试\"><a href=\"#pytorch小试\" class=\"headerlink\" title=\"pytorch小试\"></a>pytorch小试</h2><p>我用的是pycharm，因此有的库需要提前导入，这个好办，运行的时候会提醒你导入哪些，按照提示做就行了。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">from __future__ import print_function\nimport torch</code></pre>\n<p>以下内容来源于pytorch官方文档：</p>\n<h3 id=\"声明和定义\"><a href=\"#声明和定义\" class=\"headerlink\" title=\"声明和定义\"></a>声明和定义</h3><p>torch.empty(): 声明一个未初始化的矩阵</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"># 创建一个 5*3 的矩阵\nx &#x3D; torch.empty(5, 3)\nprint(x)</code></pre>\n<p>输出如下：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">tensor([[9.2737e-41, 8.9074e-01, 1.9286e-37],\n        [1.7228e-34, 5.7064e+01, 9.2737e-41],\n        [2.2803e+02, 1.9288e-37, 1.7228e-34],\n        [1.4609e+04, 9.2737e-41, 5.8375e+04],\n        [1.9290e-37, 1.7228e-34, 3.7402e+06]])</code></pre>\n<p>长得差不多就行了，检验torch基本功能。<br>torch.rand()：随机初始化一个矩阵</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"># 创建一个随机初始化的 5*3 矩阵\nrand_x &#x3D; torch.rand(5, 3)\nprint(rand_x)</code></pre>\n<p>torch.zeros()：创建数值皆为 0 的矩阵</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"># 创建一个数值皆是 0，类型为 long 的矩阵\nzero_x &#x3D; torch.zeros(5, 3, dtype&#x3D;torch.long)\nprint(zero_x)</code></pre>\n<p>输出：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">tensor([[0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0]])</code></pre>\n<p>torch.tensor()：直接传递 tensor 数值来创建</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"># tensor 数值是 [5.5, 3]\ntensor1 &#x3D; torch.tensor([5.5, 3])\nprint(tensor1)</code></pre>\n<p>输出：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">tensor([5.5000, 3.0000])</code></pre>\n<h3 id=\"操作-Operations\"><a href=\"#操作-Operations\" class=\"headerlink\" title=\"操作(Operations)\"></a>操作(Operations)</h3><p>详见官方文档：</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><a href=\"https://pytorch.org/docs/stable/torch.html\">https://pytorch.org/docs/stable/torch.html</a></p></blockquote>\n<ul>\n<li>运算符<br>torch.add(tensor1, tensor2, [out=tensor3])<br>tensor1.add_(tensor2)：直接修改 tensor 变量</li>\n</ul>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">tensor4 &#x3D; torch.rand(5, 3)\nprint(&#39;tensor3 + tensor4&#x3D; &#39;, tensor3 + tensor4)\nprint(&#39;tensor3 + tensor4&#x3D; &#39;, torch.add(tensor3, tensor4))\n# 新声明一个 tensor 变量保存加法操作的结果\nresult &#x3D; torch.empty(5, 3)\ntorch.add(tensor3, tensor4, out&#x3D;result)\nprint(&#39;add result&#x3D; &#39;, result)\n# 直接修改变量\ntensor3.add_(tensor4)\nprint(&#39;tensor3&#x3D; &#39;, tensor3)</code></pre>\n<p>输出：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">tensor3 + tensor4&#x3D;  tensor([[ 0.1000,  0.1325,  0.0461],\n        [ 0.4731,  0.4523, -0.7517],\n        [ 0.2995, -0.9576,  1.4906],\n        [ 1.0461,  0.7557, -0.0187],\n        [ 2.2446, -0.3473, -1.0873]])\n\ntensor3 + tensor4&#x3D;  tensor([[ 0.1000,  0.1325,  0.0461],\n        [ 0.4731,  0.4523, -0.7517],\n        [ 0.2995, -0.9576,  1.4906],\n        [ 1.0461,  0.7557, -0.0187],\n        [ 2.2446, -0.3473, -1.0873]])\n\nadd result&#x3D;  tensor([[ 0.1000,  0.1325,  0.0461],\n        [ 0.4731,  0.4523, -0.7517],\n        [ 0.2995, -0.9576,  1.4906],\n        [ 1.0461,  0.7557, -0.0187],\n        [ 2.2446, -0.3473, -1.0873]])\n\ntensor3&#x3D;  tensor([[ 0.1000,  0.1325,  0.0461],\n        [ 0.4731,  0.4523, -0.7517],\n        [ 0.2995, -0.9576,  1.4906],\n        [ 1.0461,  0.7557, -0.0187],\n        [ 2.2446, -0.3473, -1.0873]])</code></pre>\n<h3 id=\"和-Numpy-数组的转换\"><a href=\"#和-Numpy-数组的转换\" class=\"headerlink\" title=\"和 Numpy 数组的转换\"></a>和 Numpy 数组的转换</h3><p>Tensor 转换为 Numpy 数组：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">a &#x3D; torch.ones(5)\nprint(a)\nb &#x3D; a.numpy()\nprint(b)</code></pre>\n<p>输出：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">tensor([1., 1., 1., 1., 1.])\n[1. 1. 1. 1. 1.]</code></pre>\n<p>Numpy 数组转换为 Tensor<br>转换的操作是调用 torch.from_numpy(numpy_array) 方法。例子如下所示：<br><pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">import numpy as np\na &#x3D; np.ones(5)\nb &#x3D; torch.from_numpy(a)\nnp.add(a, 1, out&#x3D;a)\nprint(a)\nprint(b)</code></pre><br>输出：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">[2. 2. 2. 2. 2.]\ntensor([2., 2., 2., 2., 2.], dtype&#x3D;torch.float64)</code></pre>\n<h3 id=\"CUDA-张量\"><a href=\"#CUDA-张量\" class=\"headerlink\" title=\"CUDA 张量\"></a>CUDA 张量</h3><p><strong>！！！很重要！！！</strong><br>Tensors 可以通过 .to 方法转换到不同的设备上，即 CPU 或者 GPU 上。例子如下所示：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"># 当 CUDA 可用的时候，可用运行下方这段代码，采用 torch.device() 方法来改变 tensors 是否在 GPU 上进行计算操作\nif torch.cuda.is_available():\n    device &#x3D; torch.device(&quot;cuda&quot;)          # 定义一个 CUDA 设备对象\n    y &#x3D; torch.ones_like(x, device&#x3D;device)  # 显示创建在 GPU 上的一个 tensor\n    x &#x3D; x.to(device)                       # 也可以采用 .to(&quot;cuda&quot;) \n    z &#x3D; x + y\n    print(z)\n    print(z.to(&quot;cpu&quot;, torch.double))       # .to() 方法也可以改变数值类型</code></pre>\n<p>输出结果，第一个结果就是在 GPU 上的结果，打印变量的时候会带有 device=’cuda:0’，而第二个是在 CPU 上的变量。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">tensor([1.4549], device&#x3D;&#39;cuda:0&#39;)\ntensor([1.4549], dtype&#x3D;torch.float64)</code></pre>\n<p>详见文档</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><a href=\"https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html\">https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html</a></p></blockquote>\n<h3 id=\"神经网络\"><a href=\"#神经网络\" class=\"headerlink\" title=\"神经网络\"></a>神经网络</h3><p>本节文档：</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><a href=\"https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py\">https://pytorch.org/tutorials/beginner/blitz/neural_networks_tutorial.html#sphx-glr-beginner-blitz-neural-networks-tutorial-py</a></p></blockquote>\n<p>在 PyTorch 中 torch.nn 专门用于实现神经网络。其中 nn.Module 包含了网络层的搭建，以及一个方法— forward(input) ，并返回网络的输出 outptu .</p>\n<p>下面是一个经典的 LeNet 网络，用于对字符进行分类。<br><img src=\"https://img-blog.csdnimg.cn/img_convert/10ef7afb362bd72308310d269a67d814.png#pic_center\" alt=\"在这里插入图片描述\"><br>对于神经网络来说，一个标准的训练流程是这样的：</p>\n<ul>\n<li>定义一个多层的神经网络</li>\n<li>对数据集的预处理并准备作为网络的输入</li>\n<li>将数据输入到网络</li>\n<li>计算网络的损失</li>\n<li>反向传播，计算梯度</li>\n<li>更新网络的梯度，一个简单的更新规则是 weight = weight - learning_rate * gradient</li>\n</ul>\n<h4 id=\"定义网络\"><a href=\"#定义网络\" class=\"headerlink\" title=\"定义网络\"></a>定义网络</h4><p>首先定义一个神经网络，下面是一个 5 层的卷积神经网络，包含两层卷积层和三层全连接层：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nclass Net(nn.Module):\n\n    def __init__(self):\n        super(Net, self).__init__()\n        # 输入图像是单通道，conv1 kenrnel size&#x3D;5*5，输出通道 6\n        self.conv1 &#x3D; nn.Conv2d(1, 6, 5)\n        # conv2 kernel size&#x3D;5*5, 输出通道 16\n        self.conv2 &#x3D; nn.Conv2d(6, 16, 5)\n        # 全连接层\n        self.fc1 &#x3D; nn.Linear(16*5*5, 120)\n        self.fc2 &#x3D; nn.Linear(120, 84)\n        self.fc3 &#x3D; nn.Linear(84, 10)\n\n    def forward(self, x):\n        # max-pooling 采用一个 (2,2) 的滑动窗口\n        x &#x3D; F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n        # 核(kernel)大小是方形的话，可仅定义一个数字，如 (2,2) 用 2 即可\n        x &#x3D; F.max_pool2d(F.relu(self.conv2(x)), 2)\n        x &#x3D; x.view(-1, self.num_flat_features(x))\n        x &#x3D; F.relu(self.fc1(x))\n        x &#x3D; F.relu(self.fc2(x))\n        x &#x3D; self.fc3(x)\n        return x\n\n    def num_flat_features(self, x):\n        # 除了 batch 维度外的所有维度\n        size &#x3D; x.size()[1:]\n        num_features &#x3D; 1\n        for s in size:\n            num_features *&#x3D; s\n        return num_features\n\nnet &#x3D; Net()\nprint(net)</code></pre>\n<p>打印网络结构：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">Net(\n  (conv1): Conv2d(1, 6, kernel_size&#x3D;(5, 5), stride&#x3D;(1, 1))\n  (conv2): Conv2d(6, 16, kernel_size&#x3D;(5, 5), stride&#x3D;(1, 1))\n  (fc1): Linear(in_features&#x3D;400, out_features&#x3D;120, bias&#x3D;True)\n  (fc2): Linear(in_features&#x3D;120, out_features&#x3D;84, bias&#x3D;True)\n  (fc3): Linear(in_features&#x3D;84, out_features&#x3D;10, bias&#x3D;True)\n)</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/257d850c071741fdac77edd1e1d33da1.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAQWxnZXJub245OA==,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center\" alt=\"在这里插入图片描述\"></p>\n<p>这里必须实现 forward 函数，而 backward 函数在采用 autograd 时就自动定义好了，在 forward 方法可以采用任何的张量操作。</p>\n<p>net.parameters() 可以返回网络的训练参数，使用例子如下：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">params &#x3D; list(net.parameters())\nprint(&#39;参数数量: &#39;, len(params))\n# conv1.weight\nprint(&#39;第一个参数大小: &#39;, params[0].size())</code></pre>\n<p>输出：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">参数数量:  10\n第一个参数大小:  torch.Size([6, 1, 5, 5])</code></pre>\n<p>然后简单测试下这个网络，随机生成一个 32*32 的输入：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"># 随机定义一个变量输入网络\ninput &#x3D; torch.randn(1, 1, 32, 32)\nout &#x3D; net(input)\nprint(out)</code></pre>\n<p>输出结果：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">tensor([[ 0.1005,  0.0263,  0.0013, -0.1157, -0.1197, -0.0141,  0.1425, -0.0521,\n          0.0689,  0.0220]], grad_fn&#x3D;&lt;ThAddmmBackward&gt;)</code></pre>\n<h4 id=\"训练分类器\"><a href=\"#训练分类器\" class=\"headerlink\" title=\"训练分类器\"></a>训练分类器</h4><h5 id=\"标题训练数据\"><a href=\"#标题训练数据\" class=\"headerlink\" title=\"标题训练数据\"></a>标题训练数据</h5><p>在训练分类器前，当然需要考虑数据的问题。通常在处理如图片、文本、语音或者视频数据的时候，一般都采用标准的 Python 库将其加载并转成 Numpy 数组，然后再转回为 PyTorch 的张量。</p>\n<p>对于图像，可以采用 Pillow, OpenCV 库；<br>对于语音，有 scipy 和 librosa;<br>对于文本，可以选择原生 Python 或者 Cython 进行加载数据，或者使用 NLTK 和 SpaCy 。<br>PyTorch 对于计算机视觉，特别创建了一个 torchvision 的库，它包含一个数据加载器(data loader)，可以加载比较常见的数据集，比如 Imagenet, CIFAR10, MNIST 等等，然后还有一个用于图像的数据转换器(data transformers)，调用的库是 torchvision.datasets 和 torch.utils.data.DataLoader 。</p>\n<p>在本教程中，将采用 CIFAR10 数据集，它包含 10 个类别，分别是飞机、汽车、鸟、猫、鹿、狗、青蛙、马、船和卡车。数据集中的图片都是 3x32x32。一些例子如下所示：<img src=\"https://img-blog.csdnimg.cn/img_convert/dc9915d9d881889412ea0228c3465965.png#pic_center\" alt=\"在这里插入图片描述\"></p>\n<h5 id=\"训练图片分类器\"><a href=\"#训练图片分类器\" class=\"headerlink\" title=\"训练图片分类器\"></a>训练图片分类器</h5><p>训练流程如下：</p>\n<ol>\n<li>通过调用 torchvision 加载和归一化 CIFAR10 训练集和测试集；</li>\n<li>构建一个卷积神经网络；</li>\n<li>定义一个损失函数；</li>\n<li>在训练集上训练网络；</li>\n<li>在测试集上测试网络性能。</li>\n</ol>\n<p><strong>加载和归一化 CIFAR10</strong><br>首先导入必须的包</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">import torch\nimport torchvision\nimport torchvision.transforms as transforms</code></pre>\n<p>torchvision 的数据集输出的图片都是 PILImage ，即取值范围是 [0, 1] ，这里需要做一个转换，变成取值范围是 [-1, 1] , 代码如下所示：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"># 将图片数据从 [0,1] 归一化为 [-1, 1] 的取值范围\ntransform &#x3D; transforms.Compose(\n    [transforms.ToTensor(),\n     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrainset &#x3D; torchvision.datasets.CIFAR10(root&#x3D;&#39;.&#x2F;data&#39;, train&#x3D;True,\n                                        download&#x3D;True, transform&#x3D;transform)\ntrainloader &#x3D; torch.utils.data.DataLoader(trainset, batch_size&#x3D;4,\n                                          shuffle&#x3D;True, num_workers&#x3D;2)\n\ntestset &#x3D; torchvision.datasets.CIFAR10(root&#x3D;&#39;.&#x2F;data&#39;, train&#x3D;False,\n                                       download&#x3D;True, transform&#x3D;transform)\ntestloader &#x3D; torch.utils.data.DataLoader(testset, batch_size&#x3D;4,\n                                         shuffle&#x3D;False, num_workers&#x3D;2)\n\nclasses &#x3D; (&#39;plane&#39;, &#39;car&#39;, &#39;bird&#39;, &#39;cat&#39;,\n           &#39;deer&#39;, &#39;dog&#39;, &#39;frog&#39;, &#39;horse&#39;, &#39;ship&#39;, &#39;truck&#39;)</code></pre>\n<p>这里下载好数据后，可以可视化部分训练图片，代码如下：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">import matplotlib.pyplot as plt\nimport numpy as np\n\n# 展示图片的函数\ndef imshow(img):\n    img &#x3D; img &#x2F; 2 + 0.5     # 非归一化\n    npimg &#x3D; img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n    plt.show()\n\n\n\n# 随机获取训练集图片\ndataiter &#x3D; iter(trainloader)\nimages, labels &#x3D; dataiter.next()\n\n# 展示图片\nimshow(torchvision.utils.make_grid(images))\n# 打印图片类别标签\nprint(&#39; &#39;.join(&#39;%5s&#39; % classes[labels[j]] for j in range(4)))</code></pre>\n<p>展示图片如下所示：<br><img src=\"https://img-blog.csdnimg.cn/img_convert/8fade468b9a18cab98c2c879ea772245.png#pic_center\" alt=\"在这里插入图片描述\"><br>其类别标签为：</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p> frog plane   dog  ship</p></blockquote>\n<p>实战：<br><img src=\"https://img-blog.csdnimg.cn/1d3384322f054556a4df184c5666a1e2.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAQWxnZXJub245OA==,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center\" alt=\"在这里插入图片描述\"></p>\n<h4 id=\"构建一个卷积神经网络\"><a href=\"#构建一个卷积神经网络\" class=\"headerlink\" title=\"构建一个卷积神经网络\"></a>构建一个卷积神经网络</h4><p>这部分内容其实直接采用上一节定义的网络即可，除了修改 conv1 的输入通道，从 1 变为 3，因为这次接收的是 3 通道的彩色图片。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">import torch.nn as nn\nimport torch.nn.functional as F\n\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 &#x3D; nn.Conv2d(3, 6, 5)\n        self.pool &#x3D; nn.MaxPool2d(2, 2)\n        self.conv2 &#x3D; nn.Conv2d(6, 16, 5)\n        self.fc1 &#x3D; nn.Linear(16 * 5 * 5, 120)\n        self.fc2 &#x3D; nn.Linear(120, 84)\n        self.fc3 &#x3D; nn.Linear(84, 10)\n\n    def forward(self, x):\n        x &#x3D; self.pool(F.relu(self.conv1(x)))\n        x &#x3D; self.pool(F.relu(self.conv2(x)))\n        x &#x3D; x.view(-1, 16 * 5 * 5)\n        x &#x3D; F.relu(self.fc1(x))\n        x &#x3D; F.relu(self.fc2(x))\n        x &#x3D; self.fc3(x)\n        return x\n\n\nnet &#x3D; Net()</code></pre>\n<h5 id=\"定义损失函数和优化器\"><a href=\"#定义损失函数和优化器\" class=\"headerlink\" title=\"定义损失函数和优化器\"></a>定义损失函数和优化器</h5><p>这里采用类别交叉熵函数和带有动量的 SGD 优化方法：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">import torch.optim as optim\n\ncriterion &#x3D; nn.CrossEntropyLoss()\noptimizer &#x3D; optim.SGD(net.parameters(), lr&#x3D;0.001, momentum&#x3D;0.9)</code></pre>\n<h5 id=\"训练网络\"><a href=\"#训练网络\" class=\"headerlink\" title=\"训练网络\"></a>训练网络</h5><p>指定需要迭代的 epoch，然后输入数据，指定次数打印当前网络的信息，比如 loss 或者准确率等性能评价标准。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">import time\nstart &#x3D; time.time()\nfor epoch in range(2):\n\n    running_loss &#x3D; 0.0\n    for i, data in enumerate(trainloader, 0):\n        # 获取输入数据\n        inputs, labels &#x3D; data\n        # 清空梯度缓存\n        optimizer.zero_grad()\n\n        outputs &#x3D; net(inputs)\n        loss &#x3D; criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # 打印统计信息\n        running_loss +&#x3D; loss.item()\n        if i % 2000 &#x3D;&#x3D; 1999:\n            # 每 2000 次迭代打印一次信息\n            print(&#39;[%d, %5d] loss: %.3f&#39; % (epoch + 1, i+1, running_loss &#x2F; 2000))\n            running_loss &#x3D; 0.0\nprint(&#39;Finished Training! Total cost time: &#39;, time.time()-start)</code></pre>\n<p>这里定义训练总共 2 个 epoch，训练信息如下，大概耗时为 77s</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">[1,  2000] loss: 2.226\n[1,  4000] loss: 1.897\n[1,  6000] loss: 1.725\n[1,  8000] loss: 1.617\n[1, 10000] loss: 1.524\n[1, 12000] loss: 1.489\n[2,  2000] loss: 1.407\n[2,  4000] loss: 1.376\n[2,  6000] loss: 1.354\n[2,  8000] loss: 1.347\n[2, 10000] loss: 1.324\n[2, 12000] loss: 1.311\n\nFinished Training! Total cost time:  77.24696755409241</code></pre>\n<p>实战：<br><img src=\"https://img-blog.csdnimg.cn/b5854f59516d425fa4bd7a62c424e360.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAQWxnZXJub245OA==,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center\" alt=\"在这里插入图片描述\"></p>\n<h5 id=\"测试模型性能\"><a href=\"#测试模型性能\" class=\"headerlink\" title=\"测试模型性能\"></a>测试模型性能</h5><p>训练好一个网络模型后，就需要用测试集进行测试，检验网络模型的泛化能力。对于图像分类任务来说，一般就是用准确率作为评价标准。</p>\n<p>首先，我们先用一个 batch 的图片进行小小测试，这里 batch=4 ，也就是 4 张图片，代码如下：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">dataiter &#x3D; iter(testloader)\nimages, labels &#x3D; dataiter.next()\n\n# 打印图片\nimshow(torchvision.utils.make_grid(images))\nprint(&#39;GroundTruth: &#39;, &#39; &#39;.join(&#39;%5s&#39; % classes[labels[j]] for j in range(4)))</code></pre>\n<p>图片和标签分别如下所示：<br><img src=\"https://img-blog.csdnimg.cn/img_convert/78dd8b6f989bdcab4eca50425c708ef0.png#pic_center\" alt=\"在这里插入图片描述\"></p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>GroundTruth:    cat  ship  ship plane</p></blockquote>\n<p>然后用这四张图片输入网络，看看网络的预测结果</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"># 网络输出\noutputs &#x3D; net(images)\n\n# 预测结果\n_, predicted &#x3D; torch.max(outputs, 1)\nprint(&#39;Predicted: &#39;, &#39; &#39;.join(&#39;%5s&#39; % classes[predicted[j]] for j in range(4)))</code></pre>\n<p>输出为：</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>Predicted:    cat  ship  ship  ship</p></blockquote>\n<p><img src=\"https://img-blog.csdnimg.cn/d51da0019131464d956a279e214455b6.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAQWxnZXJub245OA==,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center\" alt=\"在这里插入图片描述\"></p>\n<p>前面三张图片都预测正确了，第四张图片错误预测飞机为船<br>在整个测试集上的准确率：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">correct &#x3D; 0\ntotal &#x3D; 0\nwith torch.no_grad():\n    for data in testloader:\n        images, labels &#x3D; data\n        outputs &#x3D; net(images)\n        _, predicted &#x3D; torch.max(outputs.data, 1)\n        total +&#x3D; labels.size(0)\n        correct +&#x3D; (predicted &#x3D;&#x3D; labels).sum().item()\n\nprint(&#39;Accuracy of the network on the 10000 test images: %d %%&#39; % (100 * correct &#x2F; total))</code></pre>\n<p>输出结果如下</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>Accuracy of the network on the 10000 test images: 55 %</p></blockquote>\n<p>这里可能准确率并不一定一样，教程中的结果是 51% ，因为权重初始化问题，可能多少有些浮动，相比随机猜测 10 个类别的准确率(即 10%)，这个结果是不错的，当然实际上是非常不好，不过我们仅仅采用 5 层网络，而且仅仅作为教程的一个示例代码。</p>\n<p>然后，还可以再进一步，查看每个类别的分类准确率，跟上述代码有所不同的是，计算准确率部分是 c = (predicted == labels).squeeze()，这段代码其实会根据预测和真实标签是否相等，输出 1 或者 0，表示真或者假，因此在计算当前类别正确预测数量时候直接相加，预测正确自然就是加 1，错误就是加 0，也就是没有变化。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">class_correct &#x3D; list(0. for i in range(10))\nclass_total &#x3D; list(0. for i in range(10))\nwith torch.no_grad():\n    for data in testloader:\n        images, labels &#x3D; data\n        outputs &#x3D; net(images)\n        _, predicted &#x3D; torch.max(outputs, 1)\n        c &#x3D; (predicted &#x3D;&#x3D; labels).squeeze()\n        for i in range(4):\n            label &#x3D; labels[i]\n            class_correct[label] +&#x3D; c[i].item()\n            class_total[label] +&#x3D; 1\n\n\nfor i in range(10):\n    print(&#39;Accuracy of %5s : %2d %%&#39; % (classes[i], 100 * class_correct[i] &#x2F; class_total[i]))</code></pre>\n<p>输出结果，可以看到猫、鸟、鹿是错误率前三，即预测最不准确的三个类别，反倒是船和卡车最准确。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>Accuracy of plane : 58 %<br>Accuracy of   car : 59 %<br>Accuracy of  bird : 40 %<br>Accuracy of   cat : 33 %<br>Accuracy of  deer : 39 %<br>Accuracy of   dog : 60 %<br>Accuracy of  frog : 54 %<br>Accuracy of horse : 66 %<br>Accuracy of  ship : 70 %<br>Accuracy of truck : 72 %</p></blockquote>\n<p>实战：<br><img src=\"https://img-blog.csdnimg.cn/366906e931e64ba19137bf4996a91d7f.png?x-oss-process=image/watermark,type_d3F5LXplbmhlaQ,shadow_50,text_Q1NETiBAQWxnZXJub245OA==,size_20,color_FFFFFF,t_70,g_se,x_16#pic_center\" alt=\"在这里插入图片描述\"></p>\n<h3 id=\"在-GPU-上训练\"><a href=\"#在-GPU-上训练\" class=\"headerlink\" title=\"在 GPU 上训练\"></a>在 GPU 上训练</h3><p>深度学习自然需要 GPU 来加快训练速度的。所以接下来介绍如果是在 GPU 上训练，应该如何实现。</p>\n<p>首先，需要检查是否有可用的 GPU 来训练，代码如下：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">device &#x3D; torch.device(&quot;cuda:0&quot; if torch.cuda.is_available() else &quot;cpu&quot;)\nprint(device)</code></pre>\n<p>输出结果如下，这表明你的第一块 GPU 显卡或者唯一的 GPU 显卡是空闲可用状态，否则会打印 cpu 。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>cuda:0</p></blockquote>\n<p>既然有可用的 GPU ，接下来就是在 GPU 上进行训练了，其中需要修改的代码如下，分别是需要将网络参数和数据都转移到 GPU 上：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">net.to(device)\ninputs, labels &#x3D; inputs.to(device), labels.to(device)</code></pre>\n<p>修改后的训练部分代码：</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">import time\n# 在 GPU 上训练注意需要将网络和数据放到 GPU 上\nnet.to(device)\ncriterion &#x3D; nn.CrossEntropyLoss()\noptimizer &#x3D; optim.SGD(net.parameters(), lr&#x3D;0.001, momentum&#x3D;0.9)\n\nstart &#x3D; time.time()\nfor epoch in range(2):\n\n    running_loss &#x3D; 0.0\n    for i, data in enumerate(trainloader, 0):\n        # 获取输入数据\n        inputs, labels &#x3D; data\n        inputs, labels &#x3D; inputs.to(device), labels.to(device)\n        # 清空梯度缓存\n        optimizer.zero_grad()\n\n        outputs &#x3D; net(inputs)\n        loss &#x3D; criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # 打印统计信息\n        running_loss +&#x3D; loss.item()\n        if i % 2000 &#x3D;&#x3D; 1999:\n            # 每 2000 次迭代打印一次信息\n            print(&#39;[%d, %5d] loss: %.3f&#39; % (epoch + 1, i+1, running_loss &#x2F; 2000))\n            running_loss &#x3D; 0.0\nprint(&#39;Finished Training! Total cost time: &#39;, time.time() - start)</code></pre>\n","text":"最近忙于浩繁的学习任务，深感知识体系庞大，而面向百度学习又免不了亦步亦趋的情况，于是特开一个板块用于记录学习历程，也顺便作为笔记，适时阶段性总结。 环境配置配置清单 硬件：联想拯救者（GTX 1050ti） 系统：Ubuntu 20.04 64位 首先，因为《优雅的使用Matla...","link":"","photos":[],"count_time":{"symbolsCount":"17k","symbolsTime":"15 mins."},"categories":[],"tags":[{"name":"深度学习","slug":"深度学习","count":9,"path":"api/tags/深度学习.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE\"><span class=\"toc-text\">环境配置</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#nvidia%E9%A9%B1%E5%8A%A8%E5%AE%89%E8%A3%85\"><span class=\"toc-text\">nvidia驱动安装</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#cuda%E5%AE%89%E8%A3%85\"><span class=\"toc-text\">cuda安装</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#pytorch\"><span class=\"toc-text\">pytorch</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#pytorch%E5%B0%8F%E8%AF%95\"><span class=\"toc-text\">pytorch小试</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%A3%B0%E6%98%8E%E5%92%8C%E5%AE%9A%E4%B9%89\"><span class=\"toc-text\">声明和定义</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%93%8D%E4%BD%9C-Operations\"><span class=\"toc-text\">操作(Operations)</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%92%8C-Numpy-%E6%95%B0%E7%BB%84%E7%9A%84%E8%BD%AC%E6%8D%A2\"><span class=\"toc-text\">和 Numpy 数组的转换</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#CUDA-%E5%BC%A0%E9%87%8F\"><span class=\"toc-text\">CUDA 张量</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C\"><span class=\"toc-text\">神经网络</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%AE%9A%E4%B9%89%E7%BD%91%E7%BB%9C\"><span class=\"toc-text\">定义网络</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E8%AE%AD%E7%BB%83%E5%88%86%E7%B1%BB%E5%99%A8\"><span class=\"toc-text\">训练分类器</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E6%A0%87%E9%A2%98%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE\"><span class=\"toc-text\">标题训练数据</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E8%AE%AD%E7%BB%83%E5%9B%BE%E7%89%87%E5%88%86%E7%B1%BB%E5%99%A8\"><span class=\"toc-text\">训练图片分类器</span></a></li></ol></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%9E%84%E5%BB%BA%E4%B8%80%E4%B8%AA%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C\"><span class=\"toc-text\">构建一个卷积神经网络</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E5%AE%9A%E4%B9%89%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%92%8C%E4%BC%98%E5%8C%96%E5%99%A8\"><span class=\"toc-text\">定义损失函数和优化器</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E8%AE%AD%E7%BB%83%E7%BD%91%E7%BB%9C\"><span class=\"toc-text\">训练网络</span></a></li><li class=\"toc-item toc-level-5\"><a class=\"toc-link\" href=\"#%E6%B5%8B%E8%AF%95%E6%A8%A1%E5%9E%8B%E6%80%A7%E8%83%BD\"><span class=\"toc-text\">测试模型性能</span></a></li></ol></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%9C%A8-GPU-%E4%B8%8A%E8%AE%AD%E7%BB%83\"><span class=\"toc-text\">在 GPU 上训练</span></a></li></ol></li></ol>","author":{"name":"Algernon","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/68c4c7d8696c482da565ab5c8ebfa2fa.png","link":"/","description":"谁也没见过风，更别说我和你了","socials":{"github":"https://github.com/Algernon98","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/Algernon98","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://space.bilibili.com/281724502"}}}},"mapped":true,"prev_post":{"title":"【电子羊的奇妙冒险】初试深度学习（2）","uid":"bfaff7f2eff3b6451015614e9ceb60e7","slug":"电子羊2","date":"2022-11-03T13:59:49.000Z","updated":"2022-11-03T15:58:01.929Z","comments":true,"path":"api/articles/电子羊2.json","keywords":null,"cover":[],"text":"这一期内容有些杂，有基础知识，也有代码实战。 卷积神经网络 该部分图片及资料来源： http://www.huaxiaozhuan.com/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/chapters/5_CNN.html 卷积定义许多神经网络库会实...","link":"","photos":[],"count_time":{"symbolsCount":"33k","symbolsTime":"30 mins."},"categories":[],"tags":[{"name":"深度学习","slug":"深度学习","count":9,"path":"api/tags/深度学习.json"}],"author":{"name":"Algernon","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/68c4c7d8696c482da565ab5c8ebfa2fa.png","link":"/","description":"谁也没见过风，更别说我和你了","socials":{"github":"https://github.com/Algernon98","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/Algernon98","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://space.bilibili.com/281724502"}}}}},"next_post":{"title":"《深度学习》 笔记（二）","uid":"e4001ef3af977cd071aff3164f892814","slug":"深度学习2","date":"2022-11-03T13:56:49.000Z","updated":"2022-11-03T13:57:08.483Z","comments":true,"path":"api/articles/深度学习2.json","keywords":null,"cover":null,"text":"第二部分 深度网络：现代实践深度前馈网络深度前馈网络，也叫做前馈神经网络或者多层感知机，是典型的深度学习模型。 这种模型被称为前向的，是因为信息流过$x$的函数，流经用于定义$f$的中间计算过程，最终到达输出$y$。在模型的输出和模型本身之间没有反馈连接。当前馈神经网络被扩展成包...","link":"","photos":[],"count_time":{"symbolsCount":"2.4k","symbolsTime":"2 mins."},"categories":[],"tags":[{"name":"深度学习","slug":"深度学习","count":9,"path":"api/tags/深度学习.json"}],"author":{"name":"Algernon","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/68c4c7d8696c482da565ab5c8ebfa2fa.png","link":"/","description":"谁也没见过风，更别说我和你了","socials":{"github":"https://github.com/Algernon98","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/Algernon98","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://space.bilibili.com/281724502"}}}}}}