{"title":"【电子羊的奇妙冒险】初试深度学习（3）","uid":"7a681ad033be663923aa1e3ac79573bb","slug":"电子羊3","date":"2022-11-03T14:50:49.000Z","updated":"2022-11-03T14:05:01.666Z","comments":true,"path":"api/articles/电子羊3.json","keywords":null,"cover":[],"content":"<h2 id=\"噪声\"><a href=\"#噪声\" class=\"headerlink\" title=\"噪声\"></a>噪声</h2><h3 id=\"高斯噪声\"><a href=\"#高斯噪声\" class=\"headerlink\" title=\"高斯噪声\"></a>高斯噪声</h3><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>高斯噪声是指它的概率密度函数服从高斯分布（即正态分布）的一类噪声。常见的高斯噪声包括起伏噪声、宇宙噪声、热噪声和散粒噪声等等。除常用抑制噪声的方法外，对高斯噪声的抑制方法常常采用数理统计方法。<br>所谓高斯噪声是指它的概率密度函数服从高斯分布（即正态分布）的一类噪声。如果一个噪声，它的幅度分布服从高斯分布，而它的功率谱密度又是均匀分布的，则称它为高斯白噪声。高斯白噪声的二阶矩不相关，一阶矩为常数，是指先后信号在时间上的相关性。高斯白噪声包括热噪声和散粒噪声。在通信信道测试和建模中，高斯噪声被用作加性白噪声以产生加性白高斯噪声。</p></blockquote>\n<h4 id=\"添加高斯噪声\"><a href=\"#添加高斯噪声\" class=\"headerlink\" title=\"添加高斯噪声\"></a>添加高斯噪声</h4><p>来源:</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><a href=\"https://blog.csdn.net/mikumiku339/article/details/109534376?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=%E9%AB%98%E6%96%AF%E5%99%AA%E5%A3%B0python&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-109534376.nonecase&amp;spm=1018.2226.3001.4187\">https://blog.csdn.net/mikumiku339/article/details/109534376?ops_request_misc=&amp;request_id=&amp;biz_id=102&amp;utm_term=%E9%AB%98%E6%96%AF%E5%99%AA%E5%A3%B0python&amp;utm_medium=distribute.pc_search_result.none-task-blog-2~all~sobaiduweb~default-0-109534376.nonecase&amp;spm=1018.2226.3001.4187</a></p>\n<p>先将原图片的像素值除以255，即将像素值区间[0,255]投射到[0,1]，再添加服从高斯分布的噪声，最后将处理后的像素矩阵乘255恢复。</p></blockquote>\n<p>代码：</p>\n<pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">import cv2\nimport numpy as np\n\ndef Gaussnoise_func(image, mean&#x3D;0, var&#x3D;0.005):\n    &#39;&#39;&#39; \n    添加高斯噪声\n    mean : 均值 \n    var : 方差\n    &#39;&#39;&#39;\n    image &#x3D; np.array(image&#x2F;255, dtype&#x3D;float)                    #将像素值归一\n    noise &#x3D; np.random.normal(mean, var ** 0.5, image.shape)     #产生高斯噪声\n    out &#x3D; image + noise                                         #直接将归一化的图片与噪声相加\n\n    &#39;&#39;&#39;\n    将值限制在(-1&#x2F;0,1)间，然后乘255恢复\n    &#39;&#39;&#39;\n    if out.min() &lt; 0:\n        low_clip &#x3D; -1.\n    else:\n        low_clip &#x3D; 0.\n\n    out &#x3D; np.clip(out, low_clip, 1.0)\n    out &#x3D; np.uint8(out*255)\n    return out\n\ndef nothing(pp):\n    pass\n\nif __name__ &#x3D;&#x3D; &#39;__main__&#39;:\n    img &#x3D; cv2.imread(&quot;apple.png&quot;)\n    #创建预览界面\n    cv2.namedWindow(&quot;Preview&quot;)\n    cv2.createTrackbar(&quot;mean&quot;,&quot;Preview&quot;,0,5,nothing)\n    cv2.createTrackbar(&quot;var&quot;,&quot;Preview&quot;,0,5,nothing)\n    while(1):\n        mean &#x3D; cv2.getTrackbarPos(&quot;mean&quot;,&quot;Preview&quot;)\n        var &#x3D; cv2.getTrackbarPos(&quot;var&quot;,&quot;Preview&quot;)\n        img_r &#x3D; Gaussnoise_func(img,mean&#x2F;10,var&#x2F;100)\n        cv2.imshow(&quot;Result&quot;,img_r)\n        k &#x3D; cv2.waitKey(1) &amp; 0xff\n        if k &#x3D;&#x3D; 27:\n            break\n    cv2.destroyAllWindows()\n</code></pre>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>高斯噪声，顾名思义是指服从高斯分布（正态分布）的一类噪声。有的时候我们需要向标准数据中加入合适的高斯噪声让数据更加符合实际。<br>python中的random库中集成了高斯正态分布，可以直接使用。<br>我们可以通过调整高斯噪声均值和方差，获取不同效果的处理数据。</p></blockquote>\n<pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">import random\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n\ndef gauss_noisy(x, y):\n    &quot;&quot;&quot;\n    对输入数据加入高斯噪声\n    :param x: x轴数据\n    :param y: y轴数据\n    :return:\n    &quot;&quot;&quot;\n    mu &#x3D; 0\n    sigma &#x3D; 0.05\n    for i in range(len(x)):\n        x[i] +&#x3D; random.gauss(mu, sigma)\n        y[i] +&#x3D; random.gauss(mu, sigma)\n\n\nif __name__ &#x3D;&#x3D; &#39;__main__&#39;:\n    # 在0-5的区间上生成50个点作为测试数据\n    xl &#x3D; np.linspace(0, 5, 50, endpoint&#x3D;True)\n    yl &#x3D; np.sin(xl)\n\n    # 加入高斯噪声\n    gauss_noisy(xl, yl)\n\n    # 画出这些点\n    plt.plot(xl, yl, linestyle&#x3D;&#39;&#39;, marker&#x3D;&#39;.&#39;)\n    plt.show()\n</code></pre>\n<h3 id=\"椒盐噪声\"><a href=\"#椒盐噪声\" class=\"headerlink\" title=\"椒盐噪声\"></a>椒盐噪声</h3><p>椒盐噪声(salt-and-pepper noise)是指两种噪声，一种是盐噪声（salt noise），另一种是胡椒噪声（pepper noise）。盐=白色(0)，椒=黑色(255)。前者是高灰度噪声，后者属于低灰度噪声。一般两种噪声同时出现，呈现在图像上就是黑白杂点。</p>\n<h4 id=\"添加噪声\"><a href=\"#添加噪声\" class=\"headerlink\" title=\"添加噪声\"></a>添加噪声</h4><p>安装skimage库</p>\n<pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">&#x2F;&#x2F;  python-numpy  \n&#x2F;&#x2F;  python-scipy  \n&#x2F;&#x2F;  python-matplotlib  \n$  sudo apt-get install python-numpy  \n$  sudo apt-get install python-scipy  \n$  sudo apt-get install python-matplotlib  \n</code></pre>\n<p>安装python-scikit-image</p>\n<pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">$  sudo apt-get install python-skimage \n</code></pre>\n<h3 id=\"实战\"><a href=\"#实战\" class=\"headerlink\" title=\"实战\"></a>实战</h3><p>$\\sigma$=0.01<br>高斯噪声分别给数据集和测试集加上高斯噪声：<br>以下四张图分别为：<br><strong>数据集——测试集</strong><br>原——原<br>高斯——原<br>原——高斯<br>高斯——高斯<br><img src=\"https://img-blog.csdnimg.cn/514935863fef4207808096c2cf7c0d0f.png#pic_center\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/346ec03ae5024d99a896b6dd5017433d.png#pic_center\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/113003ec34534b40b64dba8ccf57fa49.png#pic_center\" alt=\"在这里插入图片描述\"></p>\n<p><img src=\"https://img-blog.csdnimg.cn/3ee502d92fc447829c135aaaab4fa013.png#pic_center\" alt=\"在这里插入图片描述\"></p>\n<h2 id=\"卷积神经网络\"><a href=\"#卷积神经网络\" class=\"headerlink\" title=\"卷积神经网络\"></a>卷积神经网络</h2><h3 id=\"二维卷积层\"><a href=\"#二维卷积层\" class=\"headerlink\" title=\"二维卷积层\"></a>二维卷积层</h3><p><strong>卷积神经网络</strong>是含有<strong>卷积层</strong>的神经网络。</p>\n<p>在二维卷积层中，一个二维输入数组和一个<strong>二维核</strong>数组通过互相关运算输出一个二维数组。<br>如图，输入的是一个高和宽均为3的二维数组。<br>将该数组的形状记为3x3或（3，3）<br>核数组的高和宽分别为2.<br>该数组在卷积运算中又称<strong>卷积核</strong>或<strong>过滤器</strong>。<br><strong>卷积核窗口</strong>（又称<strong>卷积窗口</strong>）的形状取决于卷积核的高和宽，即2x2</p>\n<p><img src=\"https://img-blog.csdnimg.cn/6aba521ec558496485f5053087200a9f.png\" alt=\"在这里插入图片描述\"><br>在二维互相关运算中，卷积窗口从输入张量的左上角开始，从左到右、从上到下滑动。<br> 当卷积窗口滑动到新一个位置时，包含在该窗口中的部分张量与卷积核张量进行按元素相乘，得到的张量再求和得到一个单一的标量值，由此我们得出了这一位置的输出张量值。 </p>\n<pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">import torch\nfrom torch import nn\nfrom d2l import torch as d2l\n\ndef corr2d(X, K):  #@save\n    &quot;&quot;&quot;计算二维互相关运算&quot;&quot;&quot;\n    h, w &#x3D; K.shape\n    Y &#x3D; torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n    for i in range(Y.shape[0]):\n        for j in range(Y.shape[1]):\n            Y[i, j] &#x3D; (X[i:i + h, j:j + w] * K).sum()\n    return Y</code></pre>\n<h3 id=\"图像中物体边缘检测\"><a href=\"#图像中物体边缘检测\" class=\"headerlink\" title=\"图像中物体边缘检测\"></a>图像中物体边缘检测</h3><p>如下是卷积层的一个简单应用：通过找到像素变化的位置，来检测图像中不同颜色的边缘。 首先，我们构造一个像素的黑白图像。中间四列为黑色（0），其余像素为白色（1）。</p>\n<pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">X &#x3D; torch.ones((6, 8))\nX[:, 2:6] &#x3D; 0\nprint（X）</code></pre>\n<p>输出</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>tensor([[1., 1., 0., 0., 0., 0., 1., 1.],<br>   [1., 1., 0., 0., 0., 0., 1., 1.],<br>   [1., 1., 0., 0., 0., 0., 1., 1.],<br>   [1., 1., 0., 0., 0., 0., 1., 1.],<br>   [1., 1., 0., 0., 0., 0., 1., 1.],<br>   [1., 1., 0., 0., 0., 0., 1., 1.]])</p></blockquote>\n<p>接下来，我们构造一个高度为1、宽度为2的卷积核K。<br>当进行互相关运算时，如果水平相邻的两元素相同，则输出为0，否则输出为非0。</p>\n<pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">K &#x3D; torch.tensor([[1.0, -1.0]])</code></pre>\n<p>现在，我们对参数X（输入）和K（卷积核）执行互相关运算。 如下所示，输出Y中的1代表从白色到黑色的边缘，-1代表从黑色到白色的边缘，其他情况的输出为0。</p>\n<pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">Y &#x3D; corr2d(X, K)\nprint（Y）</code></pre>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],<br>   [ 0.,  1.,  0.,  0.,  0., -1.,  0.],<br>   [ 0.,  1.,  0.,  0.,  0., -1.,  0.],<br>   [ 0.,  1.,  0.,  0.,  0., -1.,  0.],<br>   [ 0.,  1.,  0.,  0.,  0., -1.,  0.],<br>   [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])</p></blockquote>\n<h3 id=\"LeNet\"><a href=\"#LeNet\" class=\"headerlink\" title=\"LeNet\"></a>LeNet</h3><p>总体来看，LeNet（LeNet-5）由两个部分组成：</p>\n<ul>\n<li>卷积编码器(卷积层块)：由两个卷积层组成</li>\n<li>全连接层密集块：由三个全连接层组成。</li>\n</ul>\n<p><img src=\"https://img-blog.csdnimg.cn/9c6fca70050f49a59f91a71b2d0e460f.png\" alt=\"在这里插入图片描述\"><br>卷积层快里的基本单位是卷积层后接最大池化层：卷积层用来识别图像里的空间模式，如线条和物体局部，之后的最大池化层则用来降低卷积层对位置的敏感性。<br>卷积层快由两个这样的基本单位堆叠而成。</p>\n<p>卷积层快的输出形状为（批量大小，通道，高，宽），当卷积层快的输出传入全连接层快时，全连接层快会将小批量中每个样本<strong>变平</strong>。<br>也就是说，全连接层的输入形状将变成二维，其中第一维是小批量中的样本，第二维是每个样本变平后的向量表示，且向量长度为通道、高和宽的乘积。</p>\n<pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">import torch\nfrom torch import nn\nfrom d2l import torch as d2l\n\nnet &#x3D; nn.Sequential(\n    nn.Conv2d(1, 6, kernel_size&#x3D;5, padding&#x3D;2), nn.Sigmoid(),\n    nn.AvgPool2d(kernel_size&#x3D;2, stride&#x3D;2),\n    nn.Conv2d(6, 16, kernel_size&#x3D;5), nn.Sigmoid(),\n    nn.AvgPool2d(kernel_size&#x3D;2, stride&#x3D;2),\n    nn.Flatten(),\n    nn.Linear(16 * 5 * 5, 120), nn.Sigmoid(),\n    nn.Linear(120, 84), nn.Sigmoid(),\n    nn.Linear(84, 10))</code></pre>\n<pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">X &#x3D; torch.rand(size&#x3D;(1, 1, 28, 28), dtype&#x3D;torch.float32)\nfor layer in net:\n    X &#x3D; layer(X)\n    print(layer.__class__.__name__,&#39;output shape: \\t&#39;,X.shape)\n&#96;\n\n&gt; Conv2d output shape: \t torch.Size([1, 6, 28, 28])\nSigmoid output shape: \t torch.Size([1, 6, 28, 28])\nAvgPool2d output shape: \t torch.Size([1, 6, 14, 14])\nConv2d output shape: \t torch.Size([1, 16, 10, 10])\nSigmoid output shape: \t torch.Size([1, 16, 10, 10])\nAvgPool2d output shape: \t torch.Size([1, 16, 5, 5])\nFlatten output shape: \t torch.Size([1, 400])\nLinear output shape: \t torch.Size([1, 120])\nSigmoid output shape: \t torch.Size([1, 120])\nLinear output shape: \t torch.Size([1, 84])\nSigmoid output shape: \t torch.Size([1, 84])\n\n</code></pre>\n<h2 id=\"长短期记忆网络（LSTM）\"><a href=\"#长短期记忆网络（LSTM）\" class=\"headerlink\" title=\"长短期记忆网络（LSTM）\"></a>长短期记忆网络（LSTM）</h2><p>部分代码来源：</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><a href=\"https://github.com/d2l-ai/d2l-zh\">https://github.com/d2l-ai/d2l-zh</a></p></blockquote>\n<h3 id=\"长短期记忆\"><a href=\"#长短期记忆\" class=\"headerlink\" title=\"长短期记忆\"></a>长短期记忆</h3><p><img src=\"https://img-blog.csdnimg.cn/2cf081c35aa84fd5a34aa47c6b1c1aa8.png\" alt=\"在这里插入图片描述\"><strong>长短期记忆中输入门、遗忘门和输出门的计算</strong></p>\n<p><img src=\"https://img-blog.csdnimg.cn/b9fd3da9755442db82028bbe57ea71a2.png\" alt=\"\"></p>\n<p><strong>长短期记忆中候选记忆细胞的计算</strong></p>\n<p><img src=\"https://img-blog.csdnimg.cn/bf0cb40691c9470da634ec21cc6c98e7.png\" alt=\"在这里插入图片描述\"><br><strong>长短期记忆中记忆细胞的计算</strong></p>\n<p><img src=\"https://img-blog.csdnimg.cn/937d652eda524f8aa98a9cff60ee2d89.png\" alt=\"在这里插入图片描述\"><br><strong>长短期记忆中隐藏状态的计算</strong></p>\n<h3 id=\"代码实现\"><a href=\"#代码实现\" class=\"headerlink\" title=\"代码实现\"></a>代码实现</h3><h4 id=\"加载数据集\"><a href=\"#加载数据集\" class=\"headerlink\" title=\"加载数据集\"></a>加载数据集</h4><pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">import torch\nfrom torch import nn\nfrom d2l import torch as d2l\n\nbatch_size, num_steps &#x3D; 32, 35\ntrain_iter, vocab &#x3D; d2l.load_data_time_machine(batch_size, num_steps)</code></pre>\n<h4 id=\"初始化模型参数\"><a href=\"#初始化模型参数\" class=\"headerlink\" title=\"初始化模型参数\"></a>初始化模型参数</h4><pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">def get_lstm_params(vocab_size, num_hiddens, device):\n    num_inputs &#x3D; num_outputs &#x3D; vocab_size\n\n    def normal(shape):\n        return torch.randn(size&#x3D;shape, device&#x3D;device)*0.01\n\n    def three():\n        return (normal((num_inputs, num_hiddens)),\n                normal((num_hiddens, num_hiddens)),\n                torch.zeros(num_hiddens, device&#x3D;device))\n\n    W_xi, W_hi, b_i &#x3D; three()  # 输入门参数\n    W_xf, W_hf, b_f &#x3D; three()  # 遗忘门参数\n    W_xo, W_ho, b_o &#x3D; three()  # 输出门参数\n    W_xc, W_hc, b_c &#x3D; three()  # 候选记忆元参数\n    # 输出层参数\n    W_hq &#x3D; normal((num_hiddens, num_outputs))\n    b_q &#x3D; torch.zeros(num_outputs, device&#x3D;device)\n    # 附加梯度\n    params &#x3D; [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc,\n              b_c, W_hq, b_q]\n    for param in params:\n        param.requires_grad_(True)\n    return params</code></pre>\n<h4 id=\"定义模型\"><a href=\"#定义模型\" class=\"headerlink\" title=\"定义模型\"></a>定义模型</h4><pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">def init_lstm_state(batch_size, num_hiddens, device):\n    return (torch.zeros((batch_size, num_hiddens), device&#x3D;device),\n            torch.zeros((batch_size, num_hiddens), device&#x3D;device))</code></pre>\n<pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">def lstm(inputs, state, params):\n    [W_xi, W_hi, b_i, W_xf, W_hf, b_f, W_xo, W_ho, b_o, W_xc, W_hc, b_c,\n     W_hq, b_q] &#x3D; params\n    (H, C) &#x3D; state\n    outputs &#x3D; []\n    for X in inputs:\n        I &#x3D; torch.sigmoid((X @ W_xi) + (H @ W_hi) + b_i)\n        F &#x3D; torch.sigmoid((X @ W_xf) + (H @ W_hf) + b_f)\n        O &#x3D; torch.sigmoid((X @ W_xo) + (H @ W_ho) + b_o)\n        C_tilda &#x3D; torch.tanh((X @ W_xc) + (H @ W_hc) + b_c)\n        C &#x3D; F * C + I * C_tilda\n        H &#x3D; O * torch.tanh(C)\n        Y &#x3D; (H @ W_hq) + b_q\n        outputs.append(Y)\n    return torch.cat(outputs, dim&#x3D;0), (H, C)</code></pre>\n<h4 id=\"训练模型\"><a href=\"#训练模型\" class=\"headerlink\" title=\"训练模型\"></a>训练模型</h4><pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">vocab_size, num_hiddens, device &#x3D; len(vocab), 256, d2l.try_gpu()\nnum_epochs, lr &#x3D; 500, 1\nmodel &#x3D; d2l.RNNModelScratch(len(vocab), num_hiddens, device, get_lstm_params,\n                            init_lstm_state, lstm)\nd2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)</code></pre>\n<h4 id=\"简洁实现\"><a href=\"#简洁实现\" class=\"headerlink\" title=\"简洁实现\"></a>简洁实现</h4><pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">num_inputs &#x3D; vocab_size\nlstm_layer &#x3D; nn.LSTM(num_inputs, num_hiddens)\nmodel &#x3D; d2l.RNNModel(lstm_layer, len(vocab))\nmodel &#x3D; model.to(device)\nd2l.train_ch8(model, train_iter, vocab, lr, num_epochs, device)</code></pre>\n","text":"噪声高斯噪声 高斯噪声是指它的概率密度函数服从高斯分布（即正态分布）的一类噪声。常见的高斯噪声包括起伏噪声、宇宙噪声、热噪声和散粒噪声等等。除常用抑制噪声的方法外，对高斯噪声的抑制方法常常采用数理统计方法。所谓高斯噪声是指它的概率密度函数服从高斯分布（即正态分布）的一类噪声。如果...","link":"","photos":[],"count_time":{"symbolsCount":"8.9k","symbolsTime":"8 mins."},"categories":[],"tags":[{"name":"深度学习","slug":"深度学习","count":9,"path":"api/tags/深度学习.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%99%AA%E5%A3%B0\"><span class=\"toc-text\">噪声</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E9%AB%98%E6%96%AF%E5%99%AA%E5%A3%B0\"><span class=\"toc-text\">高斯噪声</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%B7%BB%E5%8A%A0%E9%AB%98%E6%96%AF%E5%99%AA%E5%A3%B0\"><span class=\"toc-text\">添加高斯噪声</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%A4%92%E7%9B%90%E5%99%AA%E5%A3%B0\"><span class=\"toc-text\">椒盐噪声</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%B7%BB%E5%8A%A0%E5%99%AA%E5%A3%B0\"><span class=\"toc-text\">添加噪声</span></a></li></ol></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%AE%9E%E6%88%98\"><span class=\"toc-text\">实战</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C\"><span class=\"toc-text\">卷积神经网络</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%BA%8C%E7%BB%B4%E5%8D%B7%E7%A7%AF%E5%B1%82\"><span class=\"toc-text\">二维卷积层</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%9B%BE%E5%83%8F%E4%B8%AD%E7%89%A9%E4%BD%93%E8%BE%B9%E7%BC%98%E6%A3%80%E6%B5%8B\"><span class=\"toc-text\">图像中物体边缘检测</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#LeNet\"><span class=\"toc-text\">LeNet</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86%E7%BD%91%E7%BB%9C%EF%BC%88LSTM%EF%BC%89\"><span class=\"toc-text\">长短期记忆网络（LSTM）</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E9%95%BF%E7%9F%AD%E6%9C%9F%E8%AE%B0%E5%BF%86\"><span class=\"toc-text\">长短期记忆</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0\"><span class=\"toc-text\">代码实现</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86\"><span class=\"toc-text\">加载数据集</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%88%9D%E5%A7%8B%E5%8C%96%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0\"><span class=\"toc-text\">初始化模型参数</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%AE%9A%E4%B9%89%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">定义模型</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B\"><span class=\"toc-text\">训练模型</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E7%AE%80%E6%B4%81%E5%AE%9E%E7%8E%B0\"><span class=\"toc-text\">简洁实现</span></a></li></ol></li></ol></li></ol>","author":{"name":"Algernon","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/68c4c7d8696c482da565ab5c8ebfa2fa.png","link":"/","description":"谁也没见过风，更别说我和你了","socials":{"github":"https://github.com/Algernon98","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/Algernon98","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://space.bilibili.com/281724502"}}}},"mapped":true,"prev_post":{"title":"【Go语言编程】（一）","uid":"355b3b6cd1787b40c18a74c859cf58d1","slug":"GO1","date":"2022-11-03T14:50:49.000Z","updated":"2022-11-08T15:50:20.238Z","comments":true,"path":"api/articles/GO1.json","keywords":null,"cover":[],"text":"w3c环境搭建 w3cschool第一个go程序配置路径： $env:Path &#x3D; [System.Environment]::GetEnvironmentVariable(&quot;Path&quot;,&quot;Machine&quot;) package ma...","link":"","photos":[],"count_time":{"symbolsCount":"15k","symbolsTime":"14 mins."},"categories":[{"name":"编程语言","slug":"编程语言","count":13,"path":"api/categories/编程语言.json"}],"tags":[{"name":"GO","slug":"GO","count":4,"path":"api/tags/GO.json"}],"author":{"name":"Algernon","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/68c4c7d8696c482da565ab5c8ebfa2fa.png","link":"/","description":"谁也没见过风，更别说我和你了","socials":{"github":"https://github.com/Algernon98","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/Algernon98","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://space.bilibili.com/281724502"}}}}},"next_post":{"title":"《Python》计算机视觉编程","uid":"fa85e82eb0b8baa09dbfc285e5ac66bf","slug":"python计算机视觉编程","date":"2022-11-03T14:49:49.000Z","updated":"2022-11-03T14:49:54.649Z","comments":true,"path":"api/articles/python计算机视觉编程.json","keywords":null,"cover":[],"text":"基本的图像操作处理PIL目前pycharm使用的是pillow库 from PIL import Image pil_im &#x3D;Image.open(&#39;empire.jpg&#39;) 上述代码的返回值pil_im是一个PIL图像对象 图像的颜色转换可以使用con...","link":"","photos":[],"count_time":{"symbolsCount":"4.4k","symbolsTime":"4 mins."},"categories":[],"tags":[{"name":"计算机视觉","slug":"计算机视觉","count":2,"path":"api/tags/计算机视觉.json"}],"author":{"name":"Algernon","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/68c4c7d8696c482da565ab5c8ebfa2fa.png","link":"/","description":"谁也没见过风，更别说我和你了","socials":{"github":"https://github.com/Algernon98","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/Algernon98","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://space.bilibili.com/281724502"}}}}}}