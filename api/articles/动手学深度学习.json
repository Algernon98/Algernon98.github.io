{"title":"【动手学深度学习】学习笔记及代码实战","uid":"80007edef2872f36e05ae25c647138b8","slug":"动手学深度学习","date":"2022-11-03T14:48:49.000Z","updated":"2022-11-03T14:48:44.482Z","comments":true,"path":"api/articles/动手学深度学习.json","keywords":null,"cover":[],"content":"<h2 id=\"图像分类数据集\"><a href=\"#图像分类数据集\" class=\"headerlink\" title=\"图像分类数据集\"></a>图像分类数据集</h2><p>P42<br>图像分类数据集中最常用的是手写数字识别数据集MINST。但大部分模型在MINST上的分类精度都超过了95%。为了更直观地观察算法之间的差异，我们将使用一个图像内容更加复杂的Fashion-MINST数据集。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">%matplotlib inline\nimport torch\nimport torchvision\nfrom torch.utils import data\nfrom torchvision import transforms\nfrom d2l import torch as d2l\n\nd2l.use_svg_display()</code></pre>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"># 通过ToTensor实例将图像数据从PIL类型变换成32位浮点数格式，\n# 并除以255使得所有像素的数值均在0到1之间\ntrans &#x3D; transforms.ToTensor()\nmnist_train &#x3D; torchvision.datasets.FashionMNIST(\n    root&#x3D;&quot;..&#x2F;data&quot;, train&#x3D;True, transform&#x3D;trans, download&#x3D;True)\nmnist_test &#x3D; torchvision.datasets.FashionMNIST(\n    root&#x3D;&quot;..&#x2F;data&quot;, train&#x3D;False, transform&#x3D;trans, download&#x3D;True)</code></pre>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">len(mnist_train), len(mnist_test)</code></pre>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">mnist_train[0][0].shape</code></pre>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">def get_fashion_mnist_labels(labels):  #@save\n    &quot;&quot;&quot;返回Fashion-MNIST数据集的文本标签&quot;&quot;&quot;\n    text_labels &#x3D; [&#39;t-shirt&#39;, &#39;trouser&#39;, &#39;pullover&#39;, &#39;dress&#39;, &#39;coat&#39;,\n                   &#39;sandal&#39;, &#39;shirt&#39;, &#39;sneaker&#39;, &#39;bag&#39;, &#39;ankle boot&#39;]\n    return [text_labels[int(i)] for i in labels]</code></pre>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">def show_images(imgs, num_rows, num_cols, titles&#x3D;None, scale&#x3D;1.5):  #@save\n    &quot;&quot;&quot;绘制图像列表&quot;&quot;&quot;\n    figsize &#x3D; (num_cols * scale, num_rows * scale)\n    _, axes &#x3D; d2l.plt.subplots(num_rows, num_cols, figsize&#x3D;figsize)\n    axes &#x3D; axes.flatten()\n    for i, (ax, img) in enumerate(zip(axes, imgs)):\n        if torch.is_tensor(img):\n            # 图片张量\n            ax.imshow(img.numpy())\n        else:\n            # PIL图片\n            ax.imshow(img)\n        ax.axes.get_xaxis().set_visible(False)\n        ax.axes.get_yaxis().set_visible(False)\n        if titles:\n            ax.set_title(titles[i])\n    return axes</code></pre>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">X, y &#x3D; next(iter(data.DataLoader(mnist_train, batch_size&#x3D;18)))\nshow_images(X.reshape(18, 28, 28), 2, 9, titles&#x3D;get_fashion_mnist_labels(y));</code></pre>\n<p>为了使我们在读取训练集和测试集时更容易，我们使用内置的数据迭代器，而不是从零开始创建。 回顾一下，在每次迭代中，数据加载器每次都会读取一小批量数据，大小为batch_size。 通过内置数据迭代器，我们可以随机打乱了所有样本，从而无偏见地读取小批量。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">batch_size &#x3D; 256\n\ndef get_dataloader_workers():  #@save\n    &quot;&quot;&quot;使用4个进程来读取数据&quot;&quot;&quot;\n    return 4\n\ntrain_iter &#x3D; data.DataLoader(mnist_train, batch_size, shuffle&#x3D;True,\n                             num_workers&#x3D;get_dataloader_workers())</code></pre>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">timer &#x3D; d2l.Timer()\nfor X, y in train_iter:\n    continue\nprint(f&#39;&#123;timer.stop():.2f&#125; sec&#39;)</code></pre>\n<p>现在我们定义load_data_fashion_mnist函数，用于获取和读取Fashion-MNIST数据集。 这个函数返回训练集和验证集的数据迭代器。 此外，这个函数还接受一个可选参数resize，用来将图像大小调整为另一种形状。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">def load_data_fashion_mnist(batch_size, resize&#x3D;None):  #@save\n    &quot;&quot;&quot;下载Fashion-MNIST数据集，然后将其加载到内存中&quot;&quot;&quot;\n    trans &#x3D; [transforms.ToTensor()]\n    if resize:\n        trans.insert(0, transforms.Resize(resize))\n    trans &#x3D; transforms.Compose(trans)\n    mnist_train &#x3D; torchvision.datasets.FashionMNIST(\n        root&#x3D;&quot;..&#x2F;data&quot;, train&#x3D;True, transform&#x3D;trans, download&#x3D;True)\n    mnist_test &#x3D; torchvision.datasets.FashionMNIST(\n        root&#x3D;&quot;..&#x2F;data&quot;, train&#x3D;False, transform&#x3D;trans, download&#x3D;True)\n    return (data.DataLoader(mnist_train, batch_size, shuffle&#x3D;True,\n                            num_workers&#x3D;get_dataloader_workers()),\n            data.DataLoader(mnist_test, batch_size, shuffle&#x3D;False,\n                            num_workers&#x3D;get_dataloader_workers()))</code></pre>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">train_iter, test_iter &#x3D; load_data_fashion_mnist(32, resize&#x3D;64)\nfor X, y in train_iter:\n    print(X.shape, X.dtype, y.shape, y.dtype)\n    break</code></pre>\n<h2 id=\"计算机视觉\"><a href=\"#计算机视觉\" class=\"headerlink\" title=\"计算机视觉\"></a>计算机视觉</h2><h3 id=\"图像增广\"><a href=\"#图像增广\" class=\"headerlink\" title=\"图像增广\"></a>图像增广</h3><pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">import torch\nimport torchvision\nfrom torch import nn\nfrom d2l import torch as d2l\n\nd2l.set_figsize()\nimg &#x3D; d2l.Image.open(&#39;..&#x2F;img&#x2F;cat1.jpg&#39;)\nd2l.plt.imshow(img);\n\n</code></pre>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">def apply(img, aug, num_rows&#x3D;2, num_cols&#x3D;4, scale&#x3D;1.5):\n    Y &#x3D; [aug(img) for _ in range(num_rows * num_cols)]\n    d2l.show_images(Y, num_rows, num_cols, scale&#x3D;scale)</code></pre>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">apply(img, torchvision.transforms.RandomHorizontalFlip())\n\napply(img, torchvision.transforms.RandomVerticalFlip())\n\nshape_aug &#x3D; torchvision.transforms.RandomResizedCrop(\n    (200, 200), scale&#x3D;(0.1, 1), ratio&#x3D;(0.5, 2))\napply(img, shape_aug)</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/46f64102c13846279ca7a72e79f6421b.png\" alt=\"请添加图片描述\"></p>\n<p><img src=\"https://img-blog.csdnimg.cn/579ebc8001654d0999778a8e3dd101f8.png\" alt=\"请添加图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/697af3a649e74af58aa9e9d854690c97.png\" alt=\"请添加图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/2eabb4871996416f871aa6732cb8bf73.png\" alt=\"请添加图片描述\"></p>\n<h3 id=\"改变颜色\"><a href=\"#改变颜色\" class=\"headerlink\" title=\"改变颜色\"></a>改变颜色</h3><p>另一种增广方法是改变颜色。 我们可以改变图像颜色的四个方面：亮度、对比度、饱和度和色调。 在下面的示例中，我们随机更改图像的亮度，随机值为原始图像的50%（1-0.5）到150%（1+0.5）之间。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">apply(img, torchvision.transforms.ColorJitter(\n    brightness&#x3D;0.5, contrast&#x3D;0, saturation&#x3D;0, hue&#x3D;0))\napply(img, torchvision.transforms.ColorJitter(\n    brightness&#x3D;0, contrast&#x3D;0, saturation&#x3D;0, hue&#x3D;0.5))</code></pre>\n<p>我们还可以创建一个RandomColorJitter实例，并设置如何同时随机更改图像的亮度（brightness）、对比度（contrast）、饱和度（saturation）和色调（hue）。</p>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">color_aug &#x3D; torchvision.transforms.ColorJitter(\n    brightness&#x3D;0.5, contrast&#x3D;0.5, saturation&#x3D;0.5, hue&#x3D;0.5)\napply(img, color_aug)\naugs &#x3D; torchvision.transforms.Compose([\n    torchvision.transforms.RandomHorizontalFlip(), color_aug, shape_aug])\napply(img, augs)</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/e26bd7e35b7d4fe89abfdb81cad35eb8.png\" alt=\"请添加图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/4d068bb31f5849c3a45d1f3f4d43c8ee.png\" alt=\"请添加图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/3619b3de7c274f22801c9748950b4e9a.png\" alt=\"请添加图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/fdfed3c1b4154da78d750508b86b64c1.png\" alt=\"请添加图片描述\"></p>\n<h2 id=\"Kaggle实战\"><a href=\"#Kaggle实战\" class=\"headerlink\" title=\"Kaggle实战\"></a>Kaggle实战</h2><h3 id=\"房价预测\"><a href=\"#房价预测\" class=\"headerlink\" title=\"房价预测\"></a>房价预测</h3><h4 id=\"下载并访问数据集\"><a href=\"#下载并访问数据集\" class=\"headerlink\" title=\"下载并访问数据集\"></a>下载并访问数据集</h4><pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">import hashlib\nimport os\nimport tarfile\nimport zipfile\nimport requests\n\n#@save\nDATA_HUB &#x3D; dict()\nDATA_URL &#x3D; &#39;http:&#x2F;&#x2F;d2l-data.s3-accelerate.amazonaws.com&#x2F;&#39;</code></pre>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">def download(name, cache_dir&#x3D;os.path.join(&#39;..&#39;, &#39;data&#39;)):  #@save\n    &quot;&quot;&quot;下载一个DATA_HUB中的文件，返回本地文件名&quot;&quot;&quot;\n    assert name in DATA_HUB, f&quot;&#123;name&#125; 不存在于 &#123;DATA_HUB&#125;&quot;\n    url, sha1_hash &#x3D; DATA_HUB[name]\n    os.makedirs(cache_dir, exist_ok&#x3D;True)\n    fname &#x3D; os.path.join(cache_dir, url.split(&#39;&#x2F;&#39;)[-1])\n    if os.path.exists(fname):\n        sha1 &#x3D; hashlib.sha1()\n        with open(fname, &#39;rb&#39;) as f:\n            while True:\n                data &#x3D; f.read(1048576)\n                if not data:\n                    break\n                sha1.update(data)\n        if sha1.hexdigest() &#x3D;&#x3D; sha1_hash:\n            return fname  # 命中缓存\n    print(f&#39;正在从&#123;url&#125;下载&#123;fname&#125;...&#39;)\n    r &#x3D; requests.get(url, stream&#x3D;True, verify&#x3D;True)\n    with open(fname, &#39;wb&#39;) as f:\n        f.write(r.content)\n    return fname\n\ndef download_extract(name, folder&#x3D;None):  #@save\n    &quot;&quot;&quot;下载并解压zip&#x2F;tar文件&quot;&quot;&quot;\n    fname &#x3D; download(name)\n    base_dir &#x3D; os.path.dirname(fname)\n    data_dir, ext &#x3D; os.path.splitext(fname)\n    if ext &#x3D;&#x3D; &#39;.zip&#39;:\n        fp &#x3D; zipfile.ZipFile(fname, &#39;r&#39;)\n    elif ext in (&#39;.tar&#39;, &#39;.gz&#39;):\n        fp &#x3D; tarfile.open(fname, &#39;r&#39;)\n    else:\n        assert False, &#39;只有zip&#x2F;tar文件可以被解压缩&#39;\n    fp.extractall(base_dir)\n    return os.path.join(base_dir, folder) if folder else data_dir\n\ndef download_all():  #@save\n    &quot;&quot;&quot;下载DATA_HUB中的所有文件&quot;&quot;&quot;\n    for name in DATA_HUB:\n        download(name)</code></pre>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">%matplotlib inline\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn\nfrom d2l import torch as d2l\n\nDATA_HUB[&#39;kaggle_house_train&#39;] &#x3D; (  #@save\n    DATA_URL + &#39;kaggle_house_pred_train.csv&#39;,\n    &#39;585e9cc93e70b39160e7921475f9bcd7d31219ce&#39;)\n\nDATA_HUB[&#39;kaggle_house_test&#39;] &#x3D; (  #@save\n    DATA_URL + &#39;kaggle_house_pred_test.csv&#39;,\n    &#39;fa19780a7b011d9b009e8bff8e99922a8ee2eb90&#39;)\n\ntrain_data &#x3D; pd.read_csv(download(&#39;kaggle_house_train&#39;))\ntest_data &#x3D; pd.read_csv(download(&#39;kaggle_house_test&#39;))\n\nprint(train_data.shape)\nprint(test_data.shape)\n\nprint(train_data.iloc[0:4, [0, 1, 2, 3, -3, -2, -1]])\n\nall_features &#x3D; pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))</code></pre>\n<h4 id=\"数据预处理\"><a href=\"#数据预处理\" class=\"headerlink\" title=\"数据预处理\"></a>数据预处理</h4><pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"># 若无法获得测试数据，则可根据训练数据计算均值和标准差\nnumeric_features &#x3D; all_features.dtypes[all_features.dtypes !&#x3D; &#39;object&#39;].index\nall_features[numeric_features] &#x3D; all_features[numeric_features].apply(\n    lambda x: (x - x.mean()) &#x2F; (x.std()))\n# 在标准化数据之后，所有均值消失，因此我们可以将缺失值设置为0\nall_features[numeric_features] &#x3D; all_features[numeric_features].fillna(0)</code></pre>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\"># “Dummy_na&#x3D;True”将“na”（缺失值）视为有效的特征值，并为其创建指示符特征\nall_features &#x3D; pd.get_dummies(all_features, dummy_na&#x3D;True)\nall_features.shape\n\nn_train &#x3D; train_data.shape[0]\ntrain_features &#x3D; torch.tensor(all_features[:n_train].values, dtype&#x3D;torch.float32)\ntest_features &#x3D; torch.tensor(all_features[n_train:].values, dtype&#x3D;torch.float32)\ntrain_labels &#x3D; torch.tensor(\n    train_data.SalePrice.values.reshape(-1, 1), dtype&#x3D;torch.float32)</code></pre>\n<h4 id=\"训练\"><a href=\"#训练\" class=\"headerlink\" title=\"训练\"></a>训练</h4><pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">loss &#x3D; nn.MSELoss()\nin_features &#x3D; train_features.shape[1]\n\ndef get_net():\n    net &#x3D; nn.Sequential(nn.Linear(in_features,1))\n    return net\n\ndef log_rmse(net, features, labels):\n    # 为了在取对数时进一步稳定该值，将小于1的值设置为1\n    clipped_preds &#x3D; torch.clamp(net(features), 1, float(&#39;inf&#39;))\n    rmse &#x3D; torch.sqrt(loss(torch.log(clipped_preds),\n                           torch.log(labels)))\n    return rmse.item()\n\ndef train(net, train_features, train_labels, test_features, test_labels,\n          num_epochs, learning_rate, weight_decay, batch_size):\n    train_ls, test_ls &#x3D; [], []\n    train_iter &#x3D; d2l.load_array((train_features, train_labels), batch_size)\n    # 这里使用的是Adam优化算法\n    optimizer &#x3D; torch.optim.Adam(net.parameters(),\n                                 lr &#x3D; learning_rate,\n                                 weight_decay &#x3D; weight_decay)\n    for epoch in range(num_epochs):\n        for X, y in train_iter:\n            optimizer.zero_grad()\n            l &#x3D; loss(net(X), y)\n            l.backward()\n            optimizer.step()\n        train_ls.append(log_rmse(net, train_features, train_labels))\n        if test_labels is not None:\n            test_ls.append(log_rmse(net, test_features, test_labels))\n    return train_ls, test_ls</code></pre>\n<h4 id=\"K折交叉验证\"><a href=\"#K折交叉验证\" class=\"headerlink\" title=\"K折交叉验证\"></a>K折交叉验证</h4><pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">def get_k_fold_data(k, i, X, y):\n    assert k &gt; 1\n    fold_size &#x3D; X.shape[0] &#x2F;&#x2F; k\n    X_train, y_train &#x3D; None, None\n    for j in range(k):\n        idx &#x3D; slice(j * fold_size, (j + 1) * fold_size)\n        X_part, y_part &#x3D; X[idx, :], y[idx]\n        if j &#x3D;&#x3D; i:\n            X_valid, y_valid &#x3D; X_part, y_part\n        elif X_train is None:\n            X_train, y_train &#x3D; X_part, y_part\n        else:\n            X_train &#x3D; torch.cat([X_train, X_part], 0)\n            y_train &#x3D; torch.cat([y_train, y_part], 0)\n    return X_train, y_train, X_valid, y_valid\n\ndef k_fold(k, X_train, y_train, num_epochs, learning_rate, weight_decay,\n           batch_size):\n    train_l_sum, valid_l_sum &#x3D; 0, 0\n    for i in range(k):\n        data &#x3D; get_k_fold_data(k, i, X_train, y_train)\n        net &#x3D; get_net()\n        train_ls, valid_ls &#x3D; train(net, *data, num_epochs, learning_rate,\n                                   weight_decay, batch_size)\n        train_l_sum +&#x3D; train_ls[-1]\n        valid_l_sum +&#x3D; valid_ls[-1]\n        if i &#x3D;&#x3D; 0:\n            d2l.plot(list(range(1, num_epochs + 1)), [train_ls, valid_ls],\n                     xlabel&#x3D;&#39;epoch&#39;, ylabel&#x3D;&#39;rmse&#39;, xlim&#x3D;[1, num_epochs],\n                     legend&#x3D;[&#39;train&#39;, &#39;valid&#39;], yscale&#x3D;&#39;log&#39;)\n        print(f&#39;折&#123;i + 1&#125;，训练log rmse&#123;float(train_ls[-1]):f&#125;, &#39;\n              f&#39;验证log rmse&#123;float(valid_ls[-1]):f&#125;&#39;)\n    return train_l_sum &#x2F; k, valid_l_sum &#x2F; k</code></pre>\n<h4 id=\"生成文件\"><a href=\"#生成文件\" class=\"headerlink\" title=\"生成文件\"></a>生成文件</h4><pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">k, num_epochs, lr, weight_decay, batch_size &#x3D; 5, 100, 5, 0, 64\ntrain_l, valid_l &#x3D; k_fold(k, train_features, train_labels, num_epochs, lr,\n                          weight_decay, batch_size)\nprint(f&#39;&#123;k&#125;-折验证: 平均训练log rmse: &#123;float(train_l):f&#125;, &#39;\n      f&#39;平均验证log rmse: &#123;float(valid_l):f&#125;&#39;)</code></pre>\n<pre class=\"line-numbers language-bash\" data-language=\"bash\"><code class=\"language-bash\">def train_and_pred(train_features, test_features, train_labels, test_data,\n                   num_epochs, lr, weight_decay, batch_size):\n    net &#x3D; get_net()\n    train_ls, _ &#x3D; train(net, train_features, train_labels, None, None,\n                        num_epochs, lr, weight_decay, batch_size)\n    d2l.plot(np.arange(1, num_epochs + 1), [train_ls], xlabel&#x3D;&#39;epoch&#39;,\n             ylabel&#x3D;&#39;log rmse&#39;, xlim&#x3D;[1, num_epochs], yscale&#x3D;&#39;log&#39;)\n    print(f&#39;训练log rmse：&#123;float(train_ls[-1]):f&#125;&#39;)\n    # 将网络应用于测试集。\n    preds &#x3D; net(test_features).detach().numpy()\n    # 将其重新格式化以导出到Kaggle\n    test_data[&#39;SalePrice&#39;] &#x3D; pd.Series(preds.reshape(1, -1)[0])\n    submission &#x3D; pd.concat([test_data[&#39;Id&#39;], test_data[&#39;SalePrice&#39;]], axis&#x3D;1)\n    submission.to_csv(&#39;submission.csv&#39;, index&#x3D;False)\n\ntrain_and_pred(train_features, test_features, train_labels, test_data,\n               num_epochs, lr, weight_decay, batch_size)</code></pre>\n<h4 id=\"完整代码与输出\"><a href=\"#完整代码与输出\" class=\"headerlink\" title=\"完整代码与输出\"></a>完整代码与输出</h4><pre class=\"line-numbers language-none\"><code class=\"language-none\">import hashlib\nimport os\nimport tarfile\nimport zipfile\nimport requests\n\n#@save\nDATA_HUB &#x3D; dict()\nDATA_URL &#x3D; &#39;http:&#x2F;&#x2F;d2l-data.s3-accelerate.amazonaws.com&#x2F;&#39;\n\n\ndef download(name, cache_dir&#x3D;os.path.join(&#39;..&#39;, &#39;data&#39;)):  #@save\n    &quot;&quot;&quot;下载一个DATA_HUB中的文件，返回本地文件名&quot;&quot;&quot;\n    assert name in DATA_HUB, f&quot;&#123;name&#125; 不存在于 &#123;DATA_HUB&#125;&quot;\n    url, sha1_hash &#x3D; DATA_HUB[name]\n    os.makedirs(cache_dir, exist_ok&#x3D;True)\n    fname &#x3D; os.path.join(cache_dir, url.split(&#39;&#x2F;&#39;)[-1])\n    if os.path.exists(fname):\n        sha1 &#x3D; hashlib.sha1()\n        with open(fname, &#39;rb&#39;) as f:\n            while True:\n                data &#x3D; f.read(1048576)\n                if not data:\n                    break\n                sha1.update(data)\n        if sha1.hexdigest() &#x3D;&#x3D; sha1_hash:\n            return fname  # 命中缓存\n    print(f&#39;正在从&#123;url&#125;下载&#123;fname&#125;...&#39;)\n    r &#x3D; requests.get(url, stream&#x3D;True, verify&#x3D;True)\n    with open(fname, &#39;wb&#39;) as f:\n        f.write(r.content)\n    return fname\n\ndef download_extract(name, folder&#x3D;None):  #@save\n    &quot;&quot;&quot;下载并解压zip&#x2F;tar文件&quot;&quot;&quot;\n    fname &#x3D; download(name)\n    base_dir &#x3D; os.path.dirname(fname)\n    data_dir, ext &#x3D; os.path.splitext(fname)\n    if ext &#x3D;&#x3D; &#39;.zip&#39;:\n        fp &#x3D; zipfile.ZipFile(fname, &#39;r&#39;)\n    elif ext in (&#39;.tar&#39;, &#39;.gz&#39;):\n        fp &#x3D; tarfile.open(fname, &#39;r&#39;)\n    else:\n        assert False, &#39;只有zip&#x2F;tar文件可以被解压缩&#39;\n    fp.extractall(base_dir)\n    return os.path.join(base_dir, folder) if folder else data_dir\n\ndef download_all():  #@save\n    &quot;&quot;&quot;下载DATA_HUB中的所有文件&quot;&quot;&quot;\n    for name in DATA_HUB:\n        download(name)\n\n\n#%matplotlib inline\nimport  matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn\nfrom d2l import torch as d2l\n\nDATA_HUB[&#39;kaggle_house_train&#39;] &#x3D; (  #@save\n    DATA_URL + &#39;kaggle_house_pred_train.csv&#39;,\n    &#39;585e9cc93e70b39160e7921475f9bcd7d31219ce&#39;)\n\nDATA_HUB[&#39;kaggle_house_test&#39;] &#x3D; (  #@save\n    DATA_URL + &#39;kaggle_house_pred_test.csv&#39;,\n    &#39;fa19780a7b011d9b009e8bff8e99922a8ee2eb90&#39;)\n\ntrain_data &#x3D; pd.read_csv(download(&#39;kaggle_house_train&#39;))\ntest_data &#x3D; pd.read_csv(download(&#39;kaggle_house_test&#39;))\n\nprint(train_data.shape)\nprint(test_data.shape)\n\nprint(train_data.iloc[0:4, [0, 1, 2, 3, -3, -2, -1]])\n\nall_features &#x3D; pd.concat((train_data.iloc[:, 1:-1], test_data.iloc[:, 1:]))\n\n\n# 若无法获得测试数据，则可根据训练数据计算均值和标准差\nnumeric_features &#x3D; all_features.dtypes[all_features.dtypes !&#x3D; &#39;object&#39;].index\nall_features[numeric_features] &#x3D; all_features[numeric_features].apply(\n    lambda x: (x - x.mean()) &#x2F; (x.std()))\n# 在标准化数据之后，所有均值消失，因此我们可以将缺失值设置为0\nall_features[numeric_features] &#x3D; all_features[numeric_features].fillna(0)\n\n# “Dummy_na&#x3D;True”将“na”（缺失值）视为有效的特征值，并为其创建指示符特征\nall_features &#x3D; pd.get_dummies(all_features, dummy_na&#x3D;True)\nall_features.shape\n\nn_train &#x3D; train_data.shape[0]\ntrain_features &#x3D; torch.tensor(all_features[:n_train].values, dtype&#x3D;torch.float32)\ntest_features &#x3D; torch.tensor(all_features[n_train:].values, dtype&#x3D;torch.float32)\ntrain_labels &#x3D; torch.tensor(\n    train_data.SalePrice.values.reshape(-1, 1), dtype&#x3D;torch.float32)\n\n\nloss &#x3D; nn.MSELoss()\nin_features &#x3D; train_features.shape[1]\n\ndef get_net():\n    net &#x3D; nn.Sequential(nn.Linear(in_features,1))\n    return net\n\ndef log_rmse(net, features, labels):\n    # 为了在取对数时进一步稳定该值，将小于1的值设置为1\n    clipped_preds &#x3D; torch.clamp(net(features), 1, float(&#39;inf&#39;))\n    rmse &#x3D; torch.sqrt(loss(torch.log(clipped_preds),\n                           torch.log(labels)))\n    return rmse.item()\n\ndef train(net, train_features, train_labels, test_features, test_labels,\n          num_epochs, learning_rate, weight_decay, batch_size):\n    train_ls, test_ls &#x3D; [], []\n    train_iter &#x3D; d2l.load_array((train_features, train_labels), batch_size)\n    # 这里使用的是Adam优化算法\n    optimizer &#x3D; torch.optim.Adam(net.parameters(),\n                                 lr &#x3D; learning_rate,\n                                 weight_decay &#x3D; weight_decay)\n    for epoch in range(num_epochs):\n        for X, y in train_iter:\n            optimizer.zero_grad()\n            l &#x3D; loss(net(X), y)\n            l.backward()\n            optimizer.step()\n        train_ls.append(log_rmse(net, train_features, train_labels))\n        if test_labels is not None:\n            test_ls.append(log_rmse(net, test_features, test_labels))\n    return train_ls, test_ls\n\ndef get_k_fold_data(k, i, X, y):\n    assert k &gt; 1\n    fold_size &#x3D; X.shape[0] &#x2F;&#x2F; k\n    X_train, y_train &#x3D; None, None\n    for j in range(k):\n        idx &#x3D; slice(j * fold_size, (j + 1) * fold_size)\n        X_part, y_part &#x3D; X[idx, :], y[idx]\n        if j &#x3D;&#x3D; i:\n            X_valid, y_valid &#x3D; X_part, y_part\n        elif X_train is None:\n            X_train, y_train &#x3D; X_part, y_part\n        else:\n            X_train &#x3D; torch.cat([X_train, X_part], 0)\n            y_train &#x3D; torch.cat([y_train, y_part], 0)\n    return X_train, y_train, X_valid, y_valid\n\ndef k_fold(k, X_train, y_train, num_epochs, learning_rate, weight_decay,\n           batch_size):\n    train_l_sum, valid_l_sum &#x3D; 0, 0\n    for i in range(k):\n        data &#x3D; get_k_fold_data(k, i, X_train, y_train)\n        net &#x3D; get_net()\n        train_ls, valid_ls &#x3D; train(net, *data, num_epochs, learning_rate,\n                                   weight_decay, batch_size)\n        train_l_sum +&#x3D; train_ls[-1]\n        valid_l_sum +&#x3D; valid_ls[-1]\n        if i &#x3D;&#x3D; 0:\n            d2l.plot(list(range(1, num_epochs + 1)), [train_ls, valid_ls],\n                     xlabel&#x3D;&#39;epoch&#39;, ylabel&#x3D;&#39;rmse&#39;, xlim&#x3D;[1, num_epochs],\n                     legend&#x3D;[&#39;train&#39;, &#39;valid&#39;], yscale&#x3D;&#39;log&#39;)\n        print(f&#39;折&#123;i + 1&#125;，训练log rmse&#123;float(train_ls[-1]):f&#125;, &#39;\n              f&#39;验证log rmse&#123;float(valid_ls[-1]):f&#125;&#39;)\n    return train_l_sum &#x2F; k, valid_l_sum &#x2F; k\nk, num_epochs, lr, weight_decay, batch_size &#x3D; 5, 100, 5, 0, 64\ntrain_l, valid_l &#x3D; k_fold(k, train_features, train_labels, num_epochs, lr,\n                          weight_decay, batch_size)\ndef train_and_pred(train_features, test_features, train_labels, test_data,\n                   num_epochs, lr, weight_decay, batch_size):\n    net &#x3D; get_net()\n    train_ls, _ &#x3D; train(net, train_features, train_labels, None, None,\n                        num_epochs, lr, weight_decay, batch_size)\n    d2l.plot(np.arange(1, num_epochs + 1), [train_ls], xlabel&#x3D;&#39;epoch&#39;,\n             ylabel&#x3D;&#39;log rmse&#39;, xlim&#x3D;[1, num_epochs], yscale&#x3D;&#39;log&#39;)\n    print(f&#39;训练log rmse：&#123;float(train_ls[-1]):f&#125;&#39;)\n    # 将网络应用于测试集。\n    preds &#x3D; net(test_features).detach().numpy()\n    # 将其重新格式化以导出到Kaggle\n    test_data[&#39;SalePrice&#39;] &#x3D; pd.Series(preds.reshape(1, -1)[0])\n    submission &#x3D; pd.concat([test_data[&#39;Id&#39;], test_data[&#39;SalePrice&#39;]], axis&#x3D;1)\n    submission.to_csv(&#39;submission.csv&#39;, index&#x3D;False)\n\ntrain_and_pred(train_features, test_features, train_labels, test_data,\n               num_epochs, lr, weight_decay, batch_size)\n\nplt.show()</code></pre>\n<p>输出</p>\n<pre class=\"line-numbers language-none\"><code class=\"language-none\">&#x2F;home&#x2F;algernon&#x2F;anaconda3&#x2F;envs&#x2F;pythonProject1&#x2F;bin&#x2F;python &#x2F;home&#x2F;algernon&#x2F;PycharmProjects&#x2F;pythonProject1&#x2F;main.py\n(1460, 81)\n(1459, 80)\n   Id  MSSubClass MSZoning  LotFrontage SaleType SaleCondition  SalePrice\n0   1          60       RL         65.0       WD        Normal     208500\n1   2          20       RL         80.0       WD        Normal     181500\n2   3          60       RL         68.0       WD        Normal     223500\n3   4          70       RL         60.0       WD       Abnorml     140000\n折1，训练log rmse0.170750, 验证log rmse0.156827\n折2，训练log rmse0.162118, 验证log rmse0.190579\n折3，训练log rmse0.163990, 验证log rmse0.168659\n折4，训练log rmse0.167880, 验证log rmse0.154328\n折5，训练log rmse0.163059, 验证log rmse0.182734\n训练log rmse：0.162466</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/a9200845111842619b4d3f333e010e60.png\" alt=\"请添加图片描述\"></p>\n","text":"图像分类数据集P42图像分类数据集中最常用的是手写数字识别数据集MINST。但大部分模型在MINST上的分类精度都超过了95%。为了更直观地观察算法之间的差异，我们将使用一个图像内容更加复杂的Fashion-MINST数据集。 %matplotlib inline import ...","link":"","photos":[],"count_time":{"symbolsCount":"21k","symbolsTime":"19 mins."},"categories":[],"tags":[{"name":"深度学习","slug":"深度学习","count":9,"path":"api/tags/深度学习.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%9B%BE%E5%83%8F%E5%88%86%E7%B1%BB%E6%95%B0%E6%8D%AE%E9%9B%86\"><span class=\"toc-text\">图像分类数据集</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89\"><span class=\"toc-text\">计算机视觉</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%9B%BE%E5%83%8F%E5%A2%9E%E5%B9%BF\"><span class=\"toc-text\">图像增广</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%94%B9%E5%8F%98%E9%A2%9C%E8%89%B2\"><span class=\"toc-text\">改变颜色</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#Kaggle%E5%AE%9E%E6%88%98\"><span class=\"toc-text\">Kaggle实战</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E6%88%BF%E4%BB%B7%E9%A2%84%E6%B5%8B\"><span class=\"toc-text\">房价预测</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E4%B8%8B%E8%BD%BD%E5%B9%B6%E8%AE%BF%E9%97%AE%E6%95%B0%E6%8D%AE%E9%9B%86\"><span class=\"toc-text\">下载并访问数据集</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E6%95%B0%E6%8D%AE%E9%A2%84%E5%A4%84%E7%90%86\"><span class=\"toc-text\">数据预处理</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E8%AE%AD%E7%BB%83\"><span class=\"toc-text\">训练</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#K%E6%8A%98%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81\"><span class=\"toc-text\">K折交叉验证</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E7%94%9F%E6%88%90%E6%96%87%E4%BB%B6\"><span class=\"toc-text\">生成文件</span></a></li><li class=\"toc-item toc-level-4\"><a class=\"toc-link\" href=\"#%E5%AE%8C%E6%95%B4%E4%BB%A3%E7%A0%81%E4%B8%8E%E8%BE%93%E5%87%BA\"><span class=\"toc-text\">完整代码与输出</span></a></li></ol></li></ol></li></ol>","author":{"name":"Algernon","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/68c4c7d8696c482da565ab5c8ebfa2fa.png","link":"/","description":"谁也没见过风，更别说我和你了","socials":{"github":"https://github.com/Algernon98","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/Algernon98","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://space.bilibili.com/281724502"}}}},"mapped":true,"prev_post":{"title":"《Python》计算机视觉编程","uid":"fa85e82eb0b8baa09dbfc285e5ac66bf","slug":"python计算机视觉编程","date":"2022-11-03T14:49:49.000Z","updated":"2022-11-03T14:49:54.649Z","comments":true,"path":"api/articles/python计算机视觉编程.json","keywords":null,"cover":[],"text":"基本的图像操作处理PIL目前pycharm使用的是pillow库 from PIL import Image pil_im &#x3D;Image.open(&#39;empire.jpg&#39;) 上述代码的返回值pil_im是一个PIL图像对象 图像的颜色转换可以使用con...","link":"","photos":[],"count_time":{"symbolsCount":"4.4k","symbolsTime":"4 mins."},"categories":[],"tags":[{"name":"计算机视觉","slug":"计算机视觉","count":2,"path":"api/tags/计算机视觉.json"}],"author":{"name":"Algernon","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/68c4c7d8696c482da565ab5c8ebfa2fa.png","link":"/","description":"谁也没见过风，更别说我和你了","socials":{"github":"https://github.com/Algernon98","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/Algernon98","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://space.bilibili.com/281724502"}}}}},"next_post":{"title":"Java程序设计·笔记","uid":"cb28b0a44b029b9ea34f55f1b61057a9","slug":"java程序设计","date":"2022-11-03T14:47:49.000Z","updated":"2022-11-08T15:51:50.875Z","comments":true,"path":"api/articles/java程序设计.json","keywords":null,"cover":null,"text":"资料来源： 《java程序设计》《Java技术手册》 简介java与javascript比较 Java是静态型的语言，JavaScript是动态类型语言 Java提供基于类的对象，JavaScript使用基于原型的对象。 Java提供了良好的对象封装，JavaScript没有提供...","link":"","photos":[],"count_time":{"symbolsCount":"2.8k","symbolsTime":"3 mins."},"categories":[{"name":"编程语言","slug":"编程语言","count":13,"path":"api/categories/编程语言.json"}],"tags":[{"name":"Java","slug":"Java","count":1,"path":"api/tags/Java.json"}],"author":{"name":"Algernon","slug":"blog-author","avatar":"https://img-blog.csdnimg.cn/68c4c7d8696c482da565ab5c8ebfa2fa.png","link":"/","description":"谁也没见过风，更别说我和你了","socials":{"github":"https://github.com/Algernon98","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/Algernon98","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://space.bilibili.com/281724502"}}}}}}