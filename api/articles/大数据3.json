{"title":"【大数据基础】Hadoop3.1.3安装教程","uid":"78b7ddde844e9e414cf17e82e5c26627","slug":"大数据3","date":"2023-02-27T13:50:49.000Z","updated":"2023-04-04T02:33:40.265Z","comments":true,"path":"api/articles/大数据3.json","keywords":null,"cover":[],"content":"<p>来源：</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><a href=\"https://dblab.xmu.edu.cn/blog/2441/\">https://dblab.xmu.edu.cn/blog/2441/</a></p></blockquote>\n<p>前言：重装解决一切bug！事实上，问题中的绝大部分衍生问题都可以通过重装解决。</p>\n<h2 id=\"实验内容\"><a href=\"#实验内容\" class=\"headerlink\" title=\"实验内容\"></a>实验内容</h2><h3 id=\"创建Hadoop用户\"><a href=\"#创建Hadoop用户\" class=\"headerlink\" title=\"创建Hadoop用户\"></a>创建Hadoop用户</h3><p>首先按 ctrl+alt+t 打开终端窗口，输入如下命令创建新用户 :</p>\n<pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">sudo useradd -m hadoop -s &#x2F;bin&#x2F;bash</code></pre>\n<p>接着使用如下命令设置密码，可简单设置为 hadoop，按提示输入两次密码：<br><pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">sudo passwd hadoop</code></pre></p>\n<p><img src=\"https://img-blog.csdnimg.cn/03bb916dc1d448b6adc36891b6852d0a.png\" alt=\"在这里插入图片描述\"><br>可为 hadoop 用户增加管理员权限，方便部署，避免一些对新手来说比较棘手的权限问题：<br><pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">sudo adduser hadoop sudo</code></pre></p>\n<p><img src=\"https://img-blog.csdnimg.cn/c92362680a5d4221a92fc03d72f9cf44.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/4a77864487f84fb2b0c467a92996da71.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/393b098293c44264a9fc6c322ce2c969.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/92335f65c4484f52af2f728654980f0c.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/cc6e48fb0be241e18cbad5d6b573b28f.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/4a46f60b5991460fa18c66bde08a7fca.png\" alt=\"在这里插入图片描述\"><br>换源<br><img src=\"https://img-blog.csdnimg.cn/9ea8170ebb9e44389e69cf4899de2806.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/b4ffd518015e46d2863f68beec84cfc8.png\" alt=\"在这里插入图片描述\"><br>安装最强（bushi）编辑器vim<br><pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">sudo apt-get install vim</code></pre></p>\n<p><img src=\"https://img-blog.csdnimg.cn/4c1904beca6040e79ffd81fac0a88a6a.png\" alt=\"在这里插入图片描述\"><br>vim的常用模式有分为命令模式，插入模式，可视模式，正常模式。本教程中，只需要用到正常模式和插入模式。二者间的切换即可以帮助你完成本指南的学习。</p>\n<p>正常模式<br>正常模式主要用来浏览文本内容。一开始打开vim都是正常模式。在任何模式下按下Esc键就可以返回正常模式<br>插入编辑模式<br>插入编辑模式则用来向文本中添加内容的。在正常模式下，输入i键即可进入插入编辑模式<br>退出vim<br>如果有利用vim修改任何的文本，一定要记得保存。Esc键退回到正常模式中，然后输入:wq即可保存文本并退出vim</p>\n<h3 id=\"安装SSH、配置SSH无密码登陆\"><a href=\"#安装SSH、配置SSH无密码登陆\" class=\"headerlink\" title=\"安装SSH、配置SSH无密码登陆\"></a>安装SSH、配置SSH无密码登陆</h3><p>集群、单节点模式都需要用到 SSH 登陆（类似于远程登陆，你可以登录某台 Linux 主机，并且在上面运行命令），Ubuntu 默认已安装了 SSH client，此外还需要安装 SSH server：<br><pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">sudo apt-get install openssh-server</code></pre><br><img src=\"https://img-blog.csdnimg.cn/ce7ed1f1c3374f92a80bc74dc676a7aa.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/d3dbcdd3f6c2420ea2a0845e5320f116.png\" alt=\"在这里插入图片描述\"><br>安装后，可以使用如下命令登陆本机：<br><pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">ssh localhost</code></pre><br>此时会有如下提示(SSH首次登陆提示)，输入 yes 。然后按提示输入密码 hadoop，这样就登陆到本机了。<br><img src=\"https://img-blog.csdnimg.cn/74b54605f6044f5c8bac9eddde2e3a54.png\" alt=\"在这里插入图片描述\"><br>但这样登陆是需要每次输入密码的，我们需要配置成SSH无密码登陆比较方便。</p>\n<p>首先退出刚才的 ssh，就回到了我们原先的终端窗口，然后利用 ssh-keygen 生成密钥，并将密钥加入到授权中：</p>\n<pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">exit                           # 退出刚才的 ssh localhost\ncd ~&#x2F;.ssh&#x2F;                     # 若没有该目录，请先执行一次ssh localhost\nssh-keygen -t rsa              # 会有提示，都按回车就可以\ncat .&#x2F;id_rsa.pub &gt;&gt; .&#x2F;authorized_keys  # 加入授权</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/d1007905b42b4b2bac241f210f89fcce.png\" alt=\"在这里插入图片描述\"><br>~的含义: 在 Linux 系统中，~ 代表的是用户的主文件夹，即 “/home/用户名” 这个目录，如你的用户名为 hadoop，则 ~ 就代表 “/home/hadoop/“。 此外，命令中的 # 后面的文字是注释，只需要输入前面命令即可。</p>\n<p>此时再用 ssh localhost 命令，无需输入密码就可以直接登陆了，如下图所示。<br><img src=\"https://img-blog.csdnimg.cn/997718a397c7499a9c285836bae3b115.png\" alt=\"在这里插入图片描述\"></p>\n<h3 id=\"安装java环境\"><a href=\"#安装java环境\" class=\"headerlink\" title=\"安装java环境\"></a>安装java环境</h3><p>在Linux命令行界面中，执行如下Shell命令（注意：当前登录用户名是hadoop）：<br><pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">cd &#x2F;usr&#x2F;lib\nsudo mkdir jvm #创建&#x2F;usr&#x2F;lib&#x2F;jvm目录用来存放JDK文件\ncd ~ #进入hadoop用户的主目录\ncd Downloads  #注意区分大小写字母，刚才已经通过FTP软件把JDK安装包jdk-8u162-linux-x64.tar.gz上传到该目录下\nsudo tar -zxvf .&#x2F;jdk-8u162-linux-x64.tar.gz -C &#x2F;usr&#x2F;lib&#x2F;jvm  #把JDK文件解压到&#x2F;usr&#x2F;lib&#x2F;jvm目录下</code></pre></p>\n<p><img src=\"https://img-blog.csdnimg.cn/f5d5598d89264fd7af5826055c6acdbe.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/a00bf831b3df4eb3bbafd297781d5455.png\" alt=\"在这里插入图片描述\"><br>JDK文件解压缩以后，可以执行如下命令到/usr/lib/jvm目录查看一下：<br><pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">cd &#x2F;usr&#x2F;lib&#x2F;jvm\nls</code></pre></p>\n<p><img src=\"https://img-blog.csdnimg.cn/74798b078c0445569228db83e76ae196.png\" alt=\"在这里插入图片描述\"><br>可以看到，在/usr/lib/jvm目录下有个jdk1.8.0_162目录。<br>下面继续执行如下命令，设置环境变量：</p>\n<pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">cd ~\nvim ~&#x2F;.bashrc</code></pre>\n<p>用vim打开了hadoop这个用户的环境变量配置文件，请在这个文件的开头位置，添加如下几行内容：<br><pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">export JAVA_HOME&#x3D;&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;jdk1.8.0_162\nexport JRE_HOME&#x3D;$&#123;JAVA_HOME&#125;&#x2F;jre\nexport CLASSPATH&#x3D;.:$&#123;JAVA_HOME&#125;&#x2F;lib:$&#123;JRE_HOME&#125;&#x2F;lib\nexport PATH&#x3D;$&#123;JAVA_HOME&#125;&#x2F;bin:$PATH</code></pre></p>\n<p><img src=\"https://img-blog.csdnimg.cn/232d9ed15985487880f55f98c68582b1.png\" alt=\"在这里插入图片描述\"><br>保存.bashrc文件并退出vim编辑器。然后，继续执行如下命令让.bashrc文件的配置立即生效：<br><pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">source ~&#x2F;.bashrc</code></pre><br>这时，可以使用如下命令查看是否安装成功：<br><pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">java -version</code></pre><br><img src=\"https://img-blog.csdnimg.cn/ee83293b40e84c6e8af538cfd99727a6.png\" alt=\"在这里插入图片描述\"><br>至此，就成功安装了Java环境。下面就可以进入Hadoop的安装。</p>\n<h3 id=\"安装-Hadoop3-1-3\"><a href=\"#安装-Hadoop3-1-3\" class=\"headerlink\" title=\"安装 Hadoop3.1.3\"></a>安装 Hadoop3.1.3</h3><p>在这里最好将hadoop解压出的文件备份，这样如果后续安装出了问题便于重新配置。<br><pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">sudo tar -zxf ~&#x2F;下载&#x2F;hadoop-3.1.3.tar.gz -C &#x2F;usr&#x2F;local    # 解压到&#x2F;usr&#x2F;local中\ncd &#x2F;usr&#x2F;local&#x2F;\nsudo mv .&#x2F;hadoop-3.1.3&#x2F; .&#x2F;hadoop            # 将文件夹名改为hadoop\nsudo chown -R hadoop .&#x2F;hadoop       # 修改文件权限</code></pre><br>Hadoop 解压后即可使用。输入如下命令来检查 Hadoop 是否可用，成功则会显示 Hadoop 版本信息：<br><pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">cd &#x2F;usr&#x2F;local&#x2F;hadoop\n.&#x2F;bin&#x2F;hadoop version</code></pre></p>\n<p><img src=\"https://img-blog.csdnimg.cn/38e33e0b1e5b472ebbecc4aa372429fd.png\" alt=\"在这里插入图片描述\"></p>\n<h3 id=\"Hadoop单机配置-非分布式\"><a href=\"#Hadoop单机配置-非分布式\" class=\"headerlink\" title=\"Hadoop单机配置(非分布式)\"></a>Hadoop单机配置(非分布式)</h3><p>Hadoop 默认模式为非分布式模式（本地模式），无需进行其他配置即可运行。非分布式即单 Java 进程，方便进行调试。</p>\n<p>现在我们可以执行例子来感受下 Hadoop 的运行。Hadoop 附带了丰富的例子（运行 ./bin/hadoop jar ./share/hadoop/mapreduce/hadoop-mapreduce-examples-3.1.3.jar 可以看到所有例子），包括 wordcount、terasort、join、grep 等。</p>\n<p>在此我们选择运行 grep 例子，我们将 input 文件夹中的所有文件作为输入，筛选当中符合正则表达式 dfs[a-z.]+ 的单词并统计出现的次数，最后输出结果到 output 文件夹中。<br><pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">cd &#x2F;usr&#x2F;local&#x2F;hadoop\nmkdir .&#x2F;input\ncp .&#x2F;etc&#x2F;hadoop&#x2F;*.xml .&#x2F;input   # 将配置文件作为输入文件\n.&#x2F;bin&#x2F;hadoop jar .&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-3.1.3.jar grep .&#x2F;input .&#x2F;output &#39;dfs[a-z.]+&#39;\ncat .&#x2F;output&#x2F;*          # 查看运行结果</code></pre><br><img src=\"https://img-blog.csdnimg.cn/aabd5935cbf345eea8e29e65351e6ca4.png\" alt=\"在这里插入图片描述\"><br>执行成功后如下所示，输出了作业的相关信息，输出的结果是符合正则的单词 dfsadmin 出现了1次<br><strong>重装解决一切烦恼：</strong><br><img src=\"https://img-blog.csdnimg.cn/372168c2787f46c588d73e28c0a6fe7d.png\" alt=\"在这里插入图片描述\"><br>注意，Hadoop 默认不会覆盖结果文件，因此再次运行上面实例会提示出错，需要先将 ./output 删除。</p>\n<pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">rm -r .&#x2F;output</code></pre>\n<h3 id=\"Hadoop伪分布式配置\"><a href=\"#Hadoop伪分布式配置\" class=\"headerlink\" title=\"Hadoop伪分布式配置\"></a>Hadoop伪分布式配置</h3><p>Hadoop 可以在单节点上以伪分布式的方式运行，Hadoop 进程以分离的 Java 进程来运行，节点既作为 NameNode 也作为 DataNode，同时，读取的是 HDFS 中的文件。</p>\n<p>Hadoop 的配置文件位于 /usr/local/hadoop/etc/hadoop/ 中，伪分布式需要修改2个配置文件 core-site.xml 和 hdfs-site.xml 。Hadoop的配置文件是 xml 格式，每个配置以声明 property 的 name 和 value 的方式来实现。</p>\n<p>修改配置文件 core-site.xml (通过 gedit 编辑会比较方便: gedit ./etc/hadoop/core-site.xml)，将当中的</p>\n<pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">&lt;configuration&gt;\n&lt;&#x2F;configuration&gt;</code></pre>\n<p>修改为：</p>\n<pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;hadoop.tmp.dir&lt;&#x2F;name&gt;\n        &lt;value&gt;file:&#x2F;usr&#x2F;local&#x2F;hadoop&#x2F;tmp&lt;&#x2F;value&gt;\n        &lt;description&gt;Abase for other temporary directories.&lt;&#x2F;description&gt;\n    &lt;&#x2F;property&gt;\n    &lt;property&gt;\n        &lt;name&gt;fs.defaultFS&lt;&#x2F;name&gt;\n        &lt;value&gt;hdfs:&#x2F;&#x2F;localhost:9000&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;</code></pre>\n<pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">gedit .&#x2F;etc&#x2F;hadoop&#x2F;core-site.xml</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/204590daff7a40f09baead1635678a20.png\" alt=\"在这里插入图片描述\"></p>\n<pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;hadoop.tmp.dir&lt;&#x2F;name&gt;\n        &lt;value&gt;file:&#x2F;usr&#x2F;local&#x2F;hadoop&#x2F;tmp&lt;&#x2F;value&gt;\n        &lt;description&gt;Abase for other temporary directories.&lt;&#x2F;description&gt;\n    &lt;&#x2F;property&gt;\n    &lt;property&gt;\n        &lt;name&gt;fs.defaultFS&lt;&#x2F;name&gt;\n        &lt;value&gt;hdfs:&#x2F;&#x2F;localhost:9000&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/0f9746fed44549b4ac7aa4d0eab743a3.png\" alt=\"在这里插入图片描述\"><br>同样的，修改配置文件 hdfs-site.xml：<br><pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">gedit .&#x2F;etc&#x2F;hadoop&#x2F;hdfs-site.xml</code></pre><br><img src=\"https://img-blog.csdnimg.cn/e5d89905f3c846e180b582d13372c1c8.png\" alt=\"在这里插入图片描述\"></p>\n<pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.replication&lt;&#x2F;name&gt;\n        &lt;value&gt;1&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.namenode.name.dir&lt;&#x2F;name&gt;\n        &lt;value&gt;file:&#x2F;usr&#x2F;local&#x2F;hadoop&#x2F;tmp&#x2F;dfs&#x2F;name&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.datanode.data.dir&lt;&#x2F;name&gt;\n        &lt;value&gt;file:&#x2F;usr&#x2F;local&#x2F;hadoop&#x2F;tmp&#x2F;dfs&#x2F;data&lt;&#x2F;value&gt;\n    &lt;&#x2F;property&gt;\n&lt;&#x2F;configuration&gt;</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/e1f868d2edb647359217ac60f5c46088.png\" alt=\"在这里插入图片描述\"><br>Hadoop配置文件说明:</p>\n<p>Hadoop 的运行方式是由配置文件决定的（运行 Hadoop 时会读取配置文件），因此如果需要从伪分布式模式切换回非分布式模式，需要删除 core-site.xml 中的配置项。</p>\n<p>此外，伪分布式虽然只需要配置 fs.defaultFS 和 dfs.replication 就可以运行（官方教程如此），不过若没有配置 hadoop.tmp.dir 参数，则默认使用的临时目录为 /tmp/hadoo-hadoop，而这个目录在重启时有可能被系统清理掉，导致必须重新执行 format 才行。所以我们进行了设置，同时也指定 dfs.namenode.name.dir 和 dfs.datanode.data.dir，否则在接下来的步骤中可能会出错。</p>\n<p>配置完成后，执行 NameNode 的格式化:<br><pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">cd &#x2F;usr&#x2F;local&#x2F;hadoop\n.&#x2F;bin&#x2F;hdfs namenode -format</code></pre><br><img src=\"https://img-blog.csdnimg.cn/4ac2415f635a43e88ba1a84c471a7bec.png\" alt=\"在这里插入图片描述\"></p>\n<p><img src=\"https://img-blog.csdnimg.cn/d1f9358cfc534daea60839b56137e5a4.png\" alt=\"在这里插入图片描述\"><br>接着开启 NameNode 和 DataNode 守护进程。<br><pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">cd &#x2F;usr&#x2F;local&#x2F;hadoop\n.&#x2F;sbin&#x2F;start-dfs.sh  #start-dfs.sh是个完整的可执行文件，中间没有空格</code></pre><br>启动时可能会出现如下 WARN 提示：WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform… using builtin-java classes where applicable WARN 提示可以忽略，并不会影响正常使用。<br>在这一步可能遇到千奇百怪的问题，请移步“问题”目录。<br><img src=\"https://img-blog.csdnimg.cn/e79a647f7a444c51b7c0f13ec6698875.png\" alt=\"在这里插入图片描述\"><br>启动完成后，可以通过命令 jps 来判断是否成功启动，若成功启动则会列出如下进程: “NameNode”、”DataNode” 和 “SecondaryNameNode”（如果 SecondaryNameNode 没有启动，请运行 sbin/stop-dfs.sh 关闭进程，然后再次尝试启动尝试）。如果没有 NameNode 或 DataNode ，那就是配置不成功，请仔细检查之前步骤，或通过查看启动日志排查原因。<br><img src=\"https://img-blog.csdnimg.cn/78456d338e4a4717ac3618002eef22b9.png\" alt=\"\"><br>成功启动后，可以访问 Web 界面 <a href=\"http://localhost:9870\">http://localhost:9870</a> 查看 NameNode 和 Datanode 信息，还可以在线查看 HDFS 中的文件。<br><img src=\"https://img-blog.csdnimg.cn/2bb842c482724d8187845f05941bf876.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/fe55558239d041b2ace699c9e8d34fc0.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/52ab861c5f7f4690b9dd531e412cc0a7.png\" alt=\"在这里插入图片描述\"></p>\n<h3 id=\"运行Hadoop伪分布式实例\"><a href=\"#运行Hadoop伪分布式实例\" class=\"headerlink\" title=\"运行Hadoop伪分布式实例\"></a>运行Hadoop伪分布式实例</h3><p>上面的单机模式，grep 例子读取的是本地数据，伪分布式读取的则是 HDFS 上的数据。要使用 HDFS，首先需要在 HDFS 中创建用户目录：</p>\n<pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">.&#x2F;bin&#x2F;hdfs dfs -mkdir -p &#x2F;user&#x2F;hadoop</code></pre>\n<p>注意: 教材《大数据技术原理与应用》的命令是以”./bin/hadoop dfs”开头的Shell命令方式，实际上有三种shell命令方式。</p>\n<ol>\n<li>hadoop fs</li>\n<li>hadoop dfs</li>\n<li>hdfs dfs</li>\n</ol>\n<p>hadoop fs适用于任何不同的文件系统，比如本地文件系统和HDFS文件系统<br>hadoop dfs只能适用于HDFS文件系统<br>hdfs dfs跟hadoop dfs的命令作用一样，也只能适用于HDFS文件系统</p>\n<p>接着将 ./etc/hadoop 中的 xml 文件作为输入文件复制到分布式文件系统中，即将 /usr/local/hadoop/etc/hadoop 复制到分布式文件系统中的 /user/hadoop/input 中。我们使用的是 hadoop 用户，并且已创建相应的用户目录 /user/hadoop ，因此在命令中就可以使用相对路径如 input，其对应的绝对路径就是 /user/hadoop/input:</p>\n<pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">.&#x2F;bin&#x2F;hdfs dfs -mkdir input\n.&#x2F;bin&#x2F;hdfs dfs -put .&#x2F;etc&#x2F;hadoop&#x2F;*.xml input</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/b9b5f85814ec4433a0f8d0356822a3b7.png\" alt=\"在这里插入图片描述\"><br>复制完成后，可以通过如下命令查看文件列表：</p>\n<pre class=\"line-numbers language-cpp\" data-language=\"cpp\"><code class=\"language-cpp\">.&#x2F;bin&#x2F;hdfs dfs -ls input</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/4d0d8fdb48a04ea195306c584eb36bee.png\" alt=\"在这里插入图片描述\"><br>伪分布式运行 MapReduce 作业的方式跟单机模式相同，区别在于伪分布式读取的是HDFS中的文件（可以将单机步骤中创建的本地 input 文件夹，输出结果 output 文件夹都删掉来验证这一点）。</p>\n<pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">.&#x2F;bin&#x2F;hadoop jar .&#x2F;share&#x2F;hadoop&#x2F;mapreduce&#x2F;hadoop-mapreduce-examples-3.1.3.jar grep input output &#39;dfs[a-z.]+&#39;</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/46593f5c0f04483aabc04c0df7740fe2.png\" alt=\"在这里插入图片描述\"><br>查看运行结果的命令（查看的是位于 HDFS 中的输出结果）：<br><pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">.&#x2F;bin&#x2F;hdfs dfs -cat output&#x2F;*</code></pre><br>结果如下，注意到刚才我们已经更改了配置文件，所以运行结果不同。<br><img src=\"https://img-blog.csdnimg.cn/28b3c317ca134e7dbf95e71cb905a465.png\" alt=\"在这里插入图片描述\"><br>我们也可以将运行结果取回到本地：<br><pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">rm -r .&#x2F;output    # 先删除本地的 output 文件夹（如果存在）\n.&#x2F;bin&#x2F;hdfs dfs -get output .&#x2F;output     # 将 HDFS 上的 output 文件夹拷贝到本机\ncat .&#x2F;output&#x2F;*</code></pre></p>\n<p><img src=\"https://img-blog.csdnimg.cn/63bf53562d65490caf95f0634d9dfe53.png\" alt=\"在这里插入图片描述\"><br>Hadoop 运行程序时，输出目录不能存在，否则会提示错误 “org.apache.hadoop.mapred.FileAlreadyExistsException: Output directory hdfs://localhost:9000/user/hadoop/output already exists” ，因此若要再次执行，需要执行如下命令删除 output 文件夹:<br><pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">.&#x2F;bin&#x2F;hdfs dfs -rm -r output    # 删除 output 文件夹</code></pre></p>\n<p><img src=\"https://img-blog.csdnimg.cn/1cde9212d0e64ee6b7dbc3d1a12e28b6.png\" alt=\"在这里插入图片描述\"><br>若要关闭 Hadoop，则运行<br><pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">.&#x2F;sbin&#x2F;stop-dfs.sh</code></pre><br><img src=\"https://img-blog.csdnimg.cn/88a5b5a994694751b49b7012c4c01917.png\" alt=\"在这里插入图片描述\"><br>下次启动 hadoop 时，无需进行 NameNode 的初始化，只需要运行 ./sbin/start-dfs.sh 即可。</p>\n<h2 id=\"问题与处理\"><a href=\"#问题与处理\" class=\"headerlink\" title=\"问题与处理\"></a>问题与处理</h2><p>注意：问题2~5有一个一劳永逸的方法：重装。<br>事实上，2~5中的许多问题都是来自于一个bug，只是越改越多越改越杂，在查询资料的过程中可以学到许多相关知识，加深了解，但如果只是想把结果跑出来的话，不如像亚历山大那样，抽出宝剑，斩断复杂的绳结。简单，粗暴，但是有效。<br>如果想加深对技术和底层的了解，请移步问题2~5：</p>\n<h3 id=\"1-java安装失败\"><a href=\"#1-java安装失败\" class=\"headerlink\" title=\"1.java安装失败\"></a>1.java安装失败</h3><p><img src=\"https://img-blog.csdnimg.cn/16302c828c1a4ee096bb73827538e36e.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/c66a23570e9e4fccbae7c4d677356b94.png\" alt=\"在这里插入图片描述\"></p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>ERROR: JAVA_HOME is not set and could not be found.</p>\n<p>参考文档：<br><a href=\"https://blog.csdn.net/qq_44081582/article/details/104640421\">https://blog.csdn.net/qq_44081582/article/details/104640421</a></p></blockquote>\n<ol>\n<li>切到 [hadoop]/etc/hadoop目录<ol>\n<li>执行：vim hadoop-env.sh</li>\n<li>修改java_home路径和hadoop_conf_dir路径为具体的安装路径<br>例如：</li>\n</ol>\n</li>\n</ol>\n<pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">export JAVA_HOME&#x3D;&#x2F;usr&#x2F;lib&#x2F;jvm&#x2F;jdk1.8.0_162\nexport HADOOP_CONF_DIR&#x3D;&#x2F;usr&#x2F;local&#x2F;hadoop\n</code></pre>\n<p><img src=\"https://img-blog.csdnimg.cn/631a3e27954b464082895a399ada4f46.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/4cf0a723bf54443c9480f97950d0faef.png\" alt=\"在这里插入图片描述\"><br>这样就配置好了。</p>\n<h3 id=\"2-ERROR-Attempting-to-operate-on-hdfs-namenode-as-root\"><a href=\"#2-ERROR-Attempting-to-operate-on-hdfs-namenode-as-root\" class=\"headerlink\" title=\"2.ERROR: Attempting to operate on hdfs namenode as root\"></a>2.ERROR: Attempting to operate on hdfs namenode as root</h3><p><img src=\"https://img-blog.csdnimg.cn/53cde68b6d554ac2aafb79e1b326015a.png\" alt=\"在这里插入图片描述\"><br>这是万恶之源，虽然命令行加sudo可以避免许多权限问题，但这次尽量不要加sudo。<br>参考文档：</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p><a href=\"https://blog.csdn.net/weixin_49736959/article/details/108897129、\">https://blog.csdn.net/weixin_49736959/article/details/108897129、</a></p>\n<p>使用vim配置：<br><img src=\"https://img-blog.csdnimg.cn/0ed89cc2ef954527897caf3f1d2d7bed.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/d64076100bf44c86abab6efc7cee6c3b.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/94e443fda16845168f6c376072e96944.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/3f1c27df15b1478794994784dda0284f.png\" alt=\"在这里插入图片描述\"></p></blockquote>\n<p><img src=\"https://img-blog.csdnimg.cn/f1a99eed333a4ce1bcbcecfd80188ba9.png\" alt=\"在这里插入图片描述\"></p>\n<h3 id=\"3-host-9000-failed-on-connection-exception-java-net-ConnectException-拒绝连接\"><a href=\"#3-host-9000-failed-on-connection-exception-java-net-ConnectException-拒绝连接\" class=\"headerlink\" title=\"3.host:9000 failed on connection exception: java.net.ConnectException: 拒绝连接;\"></a>3.host:9000 failed on connection exception: java.net.ConnectException: 拒绝连接;</h3><p>问题描述：<br><img src=\"https://img-blog.csdnimg.cn/e06d40c83c5d43ce86e25cb0cb7f1240.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/3a198abd5f5a4c9e8498e288f77d6f0c.png\" alt=\"在这里插入图片描述\"><br><img src=\"https://img-blog.csdnimg.cn/324a6aea95ed4e318545e90518cc449e.png\" alt=\"在这里插入图片描述\"><br>事实上是端口占用，我打开防火墙，把9000改成8020就解决了。</p>\n<h3 id=\"4-localhost-ERROR-Cannot-set-priority-of-datanode-process-6374\"><a href=\"#4-localhost-ERROR-Cannot-set-priority-of-datanode-process-6374\" class=\"headerlink\" title=\"4.localhost: ERROR: Cannot set priority of datanode process 6374\"></a>4.localhost: ERROR: Cannot set priority of datanode process 6374</h3><p>问题描述：<br><img src=\"https://img-blog.csdnimg.cn/9591be0cd883446b969253aac3a0a34c.png\" alt=\"在这里插入图片描述\"><br>这个问题是真正的复杂，意味着你对配置文件的修改程度已经很大了，这个问题我查到的资料都没有很好的解决，这个时候重装为时未晚。<br>最终效果如下：<br><pre class=\"line-numbers language-c\" data-language=\"c\"><code class=\"language-c\">jps</code></pre></p>\n<p><img src=\"https://img-blog.csdnimg.cn/b64e493505f741708f9088ca47a7acdb.png\" alt=\"在这里插入图片描述\"></p>\n<h3 id=\"5-mkdir-Call-From-algernon-virtual-machine-127-0-1-1-to-localhost-9000-failed-on-connection-exception-java-net-ConnectException-拒绝连接\"><a href=\"#5-mkdir-Call-From-algernon-virtual-machine-127-0-1-1-to-localhost-9000-failed-on-connection-exception-java-net-ConnectException-拒绝连接\" class=\"headerlink\" title=\"5.mkdir: Call From algernon-virtual-machine/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: 拒绝连接;\"></a>5.mkdir: Call From algernon-virtual-machine/127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: 拒绝连接;</h3><p><img src=\"https://img-blog.csdnimg.cn/707d00c986c44291bfd951a6e62d1bbc.png\" alt=\"在这里插入图片描述\"><br>这个问题同问题3，修改9000为8020，完工。<br><img src=\"https://img-blog.csdnimg.cn/04ad274e7ea5407c90f8f67fe88e967e.png\" alt=\"在这里插入图片描述\"></p>\n<h2 id=\"成功结果\"><a href=\"#成功结果\" class=\"headerlink\" title=\"成功结果\"></a>成功结果</h2><p>localhost可查询：<br><img src=\"https://img-blog.csdnimg.cn/fe55558239d041b2ace699c9e8d34fc0.png\" alt=\"在这里插入图片描述\"><br>伪分布式输出结果：<br><img src=\"https://img-blog.csdnimg.cn/28b3c317ca134e7dbf95e71cb905a465.png\" alt=\"在这里插入图片描述\"><br>事实上，这个实验最后就这两张图 ，每一张图的结果代表了一个实验的成功结果。linux配置操作的关键是，如果前一个步骤没有完成，后一个步骤自然也会被卡住。一条路通了，那之后就会一往无前；一旦卡住，短则一两分钟，长则一两周。<br>所谓“台上一分钟，台下十年功”，整个实验报告的含金量就在这两张图中，但为此不知重新配置了多少文件，甚至还重装了一次。</p>\n<h2 id=\"心得与体会\"><a href=\"#心得与体会\" class=\"headerlink\" title=\"心得与体会\"></a>心得与体会</h2><blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>据说亚历山大大帝曾经解决了戈尔迪乌姆首都佛里吉亚的一个难题。<br>他在进城的时候发现了一辆旧战车，车轭上有许多绳结紧紧地系在一起，根本看不出它们原先是怎么被系上去的。神谕说，谁解开这些结，谁就能统治亚细亚。<br>亚历山大在这团粗糙的绳结前研究了一会儿，然后后退了两步，说神谕并不在意这个结是怎么解开的，接着他拔剑砍向绳结，被劈成两半的绳结就此解开了。</p></blockquote>\n<p>如果认真看了问题2~5的解决方式，会发现这些文档中有的解决方法是矛盾的，有的要把文件设为root，然后报错之后继续找，方法是把文件改为hadoop——然后又查，发现解决方法是使用root用户——这不又绕回去了嘛！但我今天在实验课的时候是这样的，不仅如此，网上的答案千奇百怪，有的治标不治本，如果看一篇博客就对自己的配置文件加以修改，到最后只能收获一堆自相矛盾的bug文件。当然，还有一些硬核知识。</p>\n<p>事实上，计算机问题三板斧：<strong>重启、重装、重买</strong>，的确粗暴而有效。<br>但我们遇到问题是不是就要重装呢？<br>我一直认为：重装是最后手段。<br>如果只是跟着教程懵懵懂懂把流程跑一遍，如果一次成功还行，如果卡住就难受了。这时选择重装，老老实实按照教程来，根据经验规则，“那么多人都做出来了”，那跟着教材走总会没问题；<br>但学到什么了呢？在linux上配置环境做实验的过程犹如蒙眼于迷宫中寻找出路，被别人牵着绕啊绕，走到出口，实际上和在平地上并无区别，但如果自己去碰壁，找到经验、方法、教训，当没有人给予指引的时候，才会更容易找到方向。<br>所以说不要怕折腾，折腾着就熟练了。<br>等到系统被改的像忒修斯之船那样，在重装，从零开始也不迟。<br>不过，这对备份要求挺高，平时常备快照，软件记得备份。<br>同样，文件夹的分配，环境配置以及配置文件中的路径，一直都是bug高发地，在进行实验的过程中注意规范，也可以避免绝大多数问题。<br>亚历山大有着斩断绳结的魄力，也有横亘一切困难的毅力。</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>活跃于公元前4世纪的马其顿国王。他在远征波斯领地吕底亚的时候，神殿里供奉着一辆战车。战车是曾经的国王格尔迪奥斯捆在神殿支柱上的。当地流传着这样一个传说：“解开这个绳结的人就会成为亚细亚之王。”这是一个很多技艺高超的挑战者都没有解开的绳结。</p></blockquote>\n<p>&gt;</p>\n<blockquote><span class=\"custom-blockquote-svg\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" fill=\"\" xmlns=\"http://www.w3.org/2000/svg\" data-reactroot=\"\">\n<path fill=\"\" d=\"M22 12C22 6.5 17.5 2 12 2C6.5 2 2 6.5 2 12C2 17.5 6.5 22 12 22C13.8 22 15.5 21.5 17 20.6L22 22L20.7 17C21.5 15.5 22 13.8 22 12Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\" undefined=\"1\"></path>\n<path fill=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\" undefined=\"1\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M17 8.5C15.23 8.97 14.07 10.84 14.01 13.27C14 13.33 14 13.4 14 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M9 8.5C7.23 8.97 6.07 10.84 6.01 13.27C6 13.33 6 13.4 6 13.47V13.5\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M15.97 11.5H16.04C17.12 11.5 18 12.38 18 13.47V13.53C18 14.62 17.12 15.5 16.03 15.5H15.96C14.88 15.5 14 14.62 14 13.53V13.46C14 12.38 14.88 11.5 15.97 11.5Z\"></path>\n<path stroke-linejoin=\"round\" stroke-linecap=\"round\" stroke-miterlimit=\"10\" stroke-width=\"2\" stroke=\"\" d=\"M7.97 11.5H8.04C9.12 11.5 10 12.38 10 13.47V13.53C10 14.62 9.12 15.5 8.03 15.5H7.97C6.88 15.5 6 14.62 6 13.53V13.46C6 12.38 6.88 11.5 7.97 11.5Z\"></path>\n</svg>\n</span><p>哲人：那么，你认为面对那个绳结的亚历山大大帝会怎么做呢？</p>\n<p>青年：是非常巧妙地解开了绳结，不久便成了亚细亚之王吧？</p>\n<p>哲人：不，并非如此。亚历山大大帝一看绳结非常牢固，于是便立即取出短剑将其一刀两断。</p>\n<p>青年：什么？！</p>\n<p>哲人：据传，当时他接着说道：“<strong>命运不是靠传说决定而要靠自己的剑开拓出来。我不需要传说的力量而要靠自己的剑去开创命运。</strong>”</p></blockquote>\n","text":"来源： https://dblab.xmu.edu.cn/blog/2441/ 前言：重装解决一切bug！事实上，问题中的绝大部分衍生问题都可以通过重装解决。 实验内容创建Hadoop用户首先按 ctrl+alt+t 打开终端窗口，输入如下命令创建新用户 : sudo usera...","link":"","photos":[],"count_time":{"symbolsCount":"11k","symbolsTime":"10 mins."},"categories":[{"name":"信管","slug":"信管","count":19,"path":"api/categories/信管.json"}],"tags":[{"name":"大数据","slug":"大数据","count":7,"path":"api/tags/大数据.json"}],"toc":"<ol class=\"toc\"><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%AE%9E%E9%AA%8C%E5%86%85%E5%AE%B9\"><span class=\"toc-text\">实验内容</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%88%9B%E5%BB%BAHadoop%E7%94%A8%E6%88%B7\"><span class=\"toc-text\">创建Hadoop用户</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%AE%89%E8%A3%85SSH%E3%80%81%E9%85%8D%E7%BD%AESSH%E6%97%A0%E5%AF%86%E7%A0%81%E7%99%BB%E9%99%86\"><span class=\"toc-text\">安装SSH、配置SSH无密码登陆</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%AE%89%E8%A3%85java%E7%8E%AF%E5%A2%83\"><span class=\"toc-text\">安装java环境</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E5%AE%89%E8%A3%85-Hadoop3-1-3\"><span class=\"toc-text\">安装 Hadoop3.1.3</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Hadoop%E5%8D%95%E6%9C%BA%E9%85%8D%E7%BD%AE-%E9%9D%9E%E5%88%86%E5%B8%83%E5%BC%8F\"><span class=\"toc-text\">Hadoop单机配置(非分布式)</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#Hadoop%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E9%85%8D%E7%BD%AE\"><span class=\"toc-text\">Hadoop伪分布式配置</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#%E8%BF%90%E8%A1%8CHadoop%E4%BC%AA%E5%88%86%E5%B8%83%E5%BC%8F%E5%AE%9E%E4%BE%8B\"><span class=\"toc-text\">运行Hadoop伪分布式实例</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E9%97%AE%E9%A2%98%E4%B8%8E%E5%A4%84%E7%90%86\"><span class=\"toc-text\">问题与处理</span></a><ol class=\"toc-child\"><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#1-java%E5%AE%89%E8%A3%85%E5%A4%B1%E8%B4%A5\"><span class=\"toc-text\">1.java安装失败</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#2-ERROR-Attempting-to-operate-on-hdfs-namenode-as-root\"><span class=\"toc-text\">2.ERROR: Attempting to operate on hdfs namenode as root</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#3-host-9000-failed-on-connection-exception-java-net-ConnectException-%E6%8B%92%E7%BB%9D%E8%BF%9E%E6%8E%A5\"><span class=\"toc-text\">3.host:9000 failed on connection exception: java.net.ConnectException: 拒绝连接;</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#4-localhost-ERROR-Cannot-set-priority-of-datanode-process-6374\"><span class=\"toc-text\">4.localhost: ERROR: Cannot set priority of datanode process 6374</span></a></li><li class=\"toc-item toc-level-3\"><a class=\"toc-link\" href=\"#5-mkdir-Call-From-algernon-virtual-machine-127-0-1-1-to-localhost-9000-failed-on-connection-exception-java-net-ConnectException-%E6%8B%92%E7%BB%9D%E8%BF%9E%E6%8E%A5\"><span class=\"toc-text\">5.mkdir: Call From algernon-virtual-machine&#x2F;127.0.1.1 to localhost:9000 failed on connection exception: java.net.ConnectException: 拒绝连接;</span></a></li></ol></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E6%88%90%E5%8A%9F%E7%BB%93%E6%9E%9C\"><span class=\"toc-text\">成功结果</span></a></li><li class=\"toc-item toc-level-2\"><a class=\"toc-link\" href=\"#%E5%BF%83%E5%BE%97%E4%B8%8E%E4%BD%93%E4%BC%9A\"><span class=\"toc-text\">心得与体会</span></a></li></ol>","author":{"name":"Algernon","slug":"blog-author","avatar":"https://user-images.githubusercontent.com/54904760/224857900-b2e8457c-43d2-46b7-901c-6c770f24bbad.png","link":"/","description":"谁也没见过风，更别说我和你了","socials":{"github":"https://github.com/Algernon98","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/Algernon98","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://space.bilibili.com/281724502"}}}},"mapped":true,"prev_post":{"title":"【大数据基础】分布式文件系统HDFS","uid":"9296c150b4eff59f49b0a87274d9be9a","slug":"大数据4","date":"2023-03-07T13:50:49.000Z","updated":"2023-04-04T02:35:07.720Z","comments":true,"path":"api/articles/大数据4.json","keywords":null,"cover":[],"text":"来源： https://dblab.xmu.edu.cn/blog/290/ 首先回顾上一节 https://blog.csdn.net/Algernon98/article/details/129232375?spm=1001.2014.3001.5501 我们已经得到了如下配...","link":"","photos":[],"count_time":{"symbolsCount":"11k","symbolsTime":"10 mins."},"categories":[{"name":"信管","slug":"信管","count":19,"path":"api/categories/信管.json"}],"tags":[{"name":"大数据","slug":"大数据","count":7,"path":"api/tags/大数据.json"}],"author":{"name":"Algernon","slug":"blog-author","avatar":"https://user-images.githubusercontent.com/54904760/224857900-b2e8457c-43d2-46b7-901c-6c770f24bbad.png","link":"/","description":"谁也没见过风，更别说我和你了","socials":{"github":"https://github.com/Algernon98","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/Algernon98","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://space.bilibili.com/281724502"}}}}},"next_post":{"title":"【大数据基础】Linux常用命令","uid":"6b74fce8d05b74231edb685307366d2f","slug":"大数据2","date":"2023-02-20T13:50:49.000Z","updated":"2023-04-04T02:32:55.003Z","comments":true,"path":"api/articles/大数据2.json","keywords":null,"cover":[],"text":"参考资料： https://www.runoob.com/w3cnote/linux-common-command-2.html 1、ls命令就是 list 的缩写，通过 ls 命令不仅可以查看 linux 文件夹包含的文件，而且可以查看文件权限(包括目录、文件夹、文件权限)查...","link":"","photos":[],"count_time":{"symbolsCount":"18k","symbolsTime":"16 mins."},"categories":[{"name":"信管","slug":"信管","count":19,"path":"api/categories/信管.json"}],"tags":[{"name":"大数据","slug":"大数据","count":7,"path":"api/tags/大数据.json"}],"author":{"name":"Algernon","slug":"blog-author","avatar":"https://user-images.githubusercontent.com/54904760/224857900-b2e8457c-43d2-46b7-901c-6c770f24bbad.png","link":"/","description":"谁也没见过风，更别说我和你了","socials":{"github":"https://github.com/Algernon98","twitter":"","stackoverflow":"","wechat":"","qq":"","weibo":"","zhihu":"","csdn":"https://blog.csdn.net/Algernon98","juejin":"","customs":{"bilibili":{"icon":"/svg/bilibili-line.svg","link":"https://space.bilibili.com/281724502"}}}}}}